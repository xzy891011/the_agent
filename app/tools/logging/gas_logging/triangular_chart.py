"""
ä¸‰è§’å›¾ç‰ˆæ³•è§£é‡Šå«æ²¹æ°”æ€§è´¨å·¥å…·

è¯¥å·¥å…·åŸºäºQå€¼è®¡ç®—è¿›è¡Œå«æ²¹æ°”æ€§è´¨åˆ¤åˆ«ï¼š
Q=1âˆ’(C2+C3+nC4)/(0.2âˆ‘C)

è¯„ä»·æ ‡å‡†ï¼š
Qå€¼èŒƒå›´        å†…ä¸‰è§’å½¢å½¢çŠ¶    å«æ²¹æ°”æ€§è´¨
75%ï½100%     å¤§æ­£ä¸‰è§’å½¢      æ°´æˆ–æ°”å±‚
25%ï½75%      ä¸­æ­£ä¸‰è§’å½¢      æ²¹æ°”å±‚æˆ–å«æ²¹æ°´å±‚
0%ï½25%       å°æ­£ä¸‰è§’å½¢      æ²¹æ°”è½¬åŒ–å¸¦
-25%ï½0%      å°å€’ä¸‰è§’å½¢      æ²¹æ°”è½¬åŒ–å¸¦
-25%ï½-75%    ä¸­å€’ä¸‰è§’å½¢      æ²¹å±‚ï¼ˆé«˜æ°”æ²¹æ¯”ï¼‰
-75%ï½-100%   å¤§å€’ä¸‰è§’å½¢      æ²¹å±‚ï¼ˆé«˜æ°”æ²¹æ¯”ï¼‰
"""

import os
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from typing import Dict, List, Optional, Union, Any, Tuple
import io
import base64
from pathlib import Path
import uuid
import platform

from app.core.file_manager import file_manager
from app.tools.registry import register_tool
from langgraph.config import get_stream_writer

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# é…ç½®ä¸­æ–‡å­—ä½“
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    try:
        if platform.system() == 'Windows':
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
        elif platform.system() == 'Darwin':  # macOS
            plt.rcParams['font.sans-serif'] = ['Hei', 'Arial Unicode MS']
        else:  # Linux
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei']
        plt.rcParams['axes.unicode_minus'] = False
    except Exception as e:
        logger.warning(f"è®¾ç½®ä¸­æ–‡å­—ä½“å¤±è´¥: {e}")

def calculate_q_value(row: pd.Series) -> float:
    """è®¡ç®—Qå€¼
    
    Q=1âˆ’(C2+C3+nC4)/(0.2âˆ‘C)
    
    Args:
        row: åŒ…å«æ°”ä½“ç»„åˆ†æ•°æ®çš„è¡Œ
        
    Returns:
        è®¡ç®—å¾—åˆ°çš„Qå€¼
    """
    try:
        # æå–æ°”ä½“ç»„åˆ†æ•°æ®
        c1 = float(row.get('C1', 0) or 0)  # ç”²çƒ·
        c2 = float(row.get('C2', 0) or 0)  # ä¹™çƒ·
        c3 = float(row.get('C3', 0) or 0)  # ä¸™çƒ·
        ic4 = float(row.get('iC4', 0) or 0)  # å¼‚ä¸çƒ·
        nc4 = float(row.get('nC4', 0) or 0)  # æ­£ä¸çƒ·
        ic5 = float(row.get('iC5', 0) or 0)  # å¼‚æˆŠçƒ·
        nc5 = float(row.get('nC5', 0) or 0)  # æ­£æˆŠçƒ·
        
        # è®¡ç®—æ€»ç¢³æ°¢åŒ–åˆç‰©å«é‡ âˆ‘C
        total_c = c1 + c2 + c3 + ic4 + nc4 + ic5 + nc5
        
        # å¦‚æœæ€»ç¢³æ°¢åŒ–åˆç‰©å«é‡ä¸º0ï¼Œè¿”å›None
        if total_c == 0:
            return None
            
        # è®¡ç®—Qå€¼ï¼šQ=1âˆ’(C2+C3+nC4)/(0.2âˆ‘C)
        q_value = 1 - (c2 + c3 + nc4) / (0.2 * total_c)
        
        return q_value
        
    except Exception as e:
        logger.warning(f"è®¡ç®—Qå€¼æ—¶å‡ºé”™: {e}")
        return None

def classify_oil_gas_nature(q_value: float) -> Dict[str, str]:
    """æ ¹æ®Qå€¼èŒƒå›´è¯„ä»·å«æ²¹æ°”æ€§è´¨
    
    Args:
        q_value: Qå€¼
        
    Returns:
        åŒ…å«åˆ†ç±»ç»“æœçš„å­—å…¸
    """
    if q_value is None:
        return {
            "q_range": "æ— æ•ˆæ•°æ®",
            "triangle_shape": "æ— æ³•åˆ¤æ–­", 
            "oil_gas_nature": "æ— æ³•åˆ¤æ–­"
        }
    
    # è½¬æ¢ä¸ºç™¾åˆ†æ¯”è¿›è¡Œåˆ¤æ–­
    q_percent = q_value * 100
    
    if 75 <= q_percent <= 100:
        return {
            "q_range": "75%ï½100%",
            "triangle_shape": "å¤§æ­£ä¸‰è§’å½¢",
            "oil_gas_nature": "æ°´æˆ–æ°”å±‚"
        }
    elif 25 <= q_percent < 75:
        return {
            "q_range": "25%ï½75%", 
            "triangle_shape": "ä¸­æ­£ä¸‰è§’å½¢",
            "oil_gas_nature": "æ²¹æ°”å±‚æˆ–å«æ²¹æ°´å±‚"
        }
    elif 0 <= q_percent < 25:
        return {
            "q_range": "0%ï½25%",
            "triangle_shape": "å°æ­£ä¸‰è§’å½¢", 
            "oil_gas_nature": "æ²¹æ°”è½¬åŒ–å¸¦"
        }
    elif -25 <= q_percent < 0:
        return {
            "q_range": "-25%ï½0%",
            "triangle_shape": "å°å€’ä¸‰è§’å½¢",
            "oil_gas_nature": "æ²¹æ°”è½¬åŒ–å¸¦"
        }
    elif -75 <= q_percent < -25:
        return {
            "q_range": "-25%ï½-75%",
            "triangle_shape": "ä¸­å€’ä¸‰è§’å½¢",
            "oil_gas_nature": "æ²¹å±‚ï¼ˆé«˜æ°”æ²¹æ¯”ï¼‰"
        }
    elif -100 <= q_percent < -75:
        return {
            "q_range": "-75%ï½-100%",
            "triangle_shape": "å¤§å€’ä¸‰è§’å½¢", 
            "oil_gas_nature": "æ²¹å±‚ï¼ˆé«˜æ°”æ²¹æ¯”ï¼‰"
        }
    else:
        return {
            "q_range": f"{q_percent:.1f}%",
            "triangle_shape": "å¼‚å¸¸å€¼",
            "oil_gas_nature": "å¼‚å¸¸å€¼"
        }

def create_triangular_chart_visualization(df: pd.DataFrame, output_path: str) -> str:
    """åˆ›å»ºä¸‰è§’å›¾ç‰ˆæ³•å¯è§†åŒ–å›¾è¡¨
    
    Args:
        df: åŒ…å«Qå€¼å’Œåˆ†ç±»ç»“æœçš„æ•°æ®æ¡†
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        
    Returns:
        å›¾ç‰‡æ–‡ä»¶è·¯å¾„
    """
    try:
        # è®¾ç½®matplotlibä½¿ç”¨Aggåç«¯ï¼Œé¿å…æ˜¾ç¤ºé—®é¢˜
        import matplotlib
        matplotlib.use('Agg')
        
        setup_chinese_font()
        
        # åˆ›å»ºå›¾è¡¨
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
        
        # å·¦å›¾ï¼šQå€¼æ·±åº¦å‰–é¢å›¾
        depths = df['Depth'].values
        q_values = df['Qå€¼'].values
        
        # è¿‡æ»¤æœ‰æ•ˆçš„Qå€¼
        valid_mask = pd.notna(q_values) & pd.notna(depths)
        valid_depths = depths[valid_mask]
        valid_q_values = q_values[valid_mask]
        
        if len(valid_q_values) > 0:
            ax1.plot(valid_q_values, valid_depths, 'bo-', linewidth=2, markersize=4)
            ax1.invert_yaxis()  # æ·±åº¦è½´åå‘
            ax1.set_xlabel('Qå€¼', fontsize=12)
            ax1.set_ylabel('æ·±åº¦ (m)', fontsize=12)
            ax1.set_title('Qå€¼æ·±åº¦å‰–é¢å›¾', fontsize=14, fontweight='bold')
            ax1.grid(True, alpha=0.3)
            
            # æ·»åŠ Qå€¼åˆ†åŒºçº¿
            x_min, x_max = ax1.get_xlim()
            for q_threshold in [1.0, 0.75, 0.25, 0, -0.25, -0.75, -1.0]:
                if x_min <= q_threshold <= x_max:
                    ax1.axvline(x=q_threshold, color='red', linestyle='--', alpha=0.7)
                    # æ·»åŠ æ ‡ç­¾
                    y_pos = (valid_depths.min() + valid_depths.max()) / 2
                    ax1.text(q_threshold, y_pos, f'{q_threshold}', rotation=90, 
                            fontsize=8, color='red', ha='center')
        else:
            ax1.text(0.5, 0.5, 'æ— æœ‰æ•ˆæ•°æ®', transform=ax1.transAxes, 
                    ha='center', va='center', fontsize=12)
        
        # å³å›¾ï¼šå«æ²¹æ°”æ€§è´¨ç»Ÿè®¡é¥¼å›¾
        nature_counts = df['å«æ²¹æ°”æ€§è´¨'].value_counts()
        
        if len(nature_counts) > 0:
            colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#ff99cc', '#c2c2f0']
            ax2.pie(nature_counts.values, labels=nature_counts.index, autopct='%1.1f%%',
                   colors=colors[:len(nature_counts)], startangle=90)
            ax2.set_title('å«æ²¹æ°”æ€§è´¨åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        else:
            ax2.text(0.5, 0.5, 'æ— åˆ†ç±»æ•°æ®', transform=ax2.transAxes, 
                    ha='center', va='center', fontsize=12)
        
        plt.tight_layout()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        logger.info(f"ä¸‰è§’å›¾ç‰ˆæ³•å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {output_path}")
        return output_path
        
    except Exception as e:
        logger.error(f"åˆ›å»ºå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        if 'fig' in locals():
            plt.close(fig)
        return ""

def is_interpreted_file(filename: str) -> bool:
    """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºå·²è§£é‡Šçš„æ–‡ä»¶
    
    Args:
        filename: æ–‡ä»¶å
        
    Returns:
        æ˜¯å¦ä¸ºå·²è§£é‡Šçš„æ–‡ä»¶
    """
    return "interpreted" in filename.lower() or "è§£é‡Š" in filename

def remove_file_id_prefix(filename: str) -> str:
    """å»æ‰æ–‡ä»¶åä¸­çš„IDå‰ç¼€
    
    Args:
        filename: åŸå§‹æ–‡ä»¶åï¼ˆå¯èƒ½åŒ…å«IDå‰ç¼€ï¼‰
        
    Returns:
        å»æ‰IDå‰ç¼€åçš„æ–‡ä»¶å
    """
    import re
    # åŒ¹é…ç±»ä¼¼ "u-abc123_" æˆ– "g-abc123_" è¿™æ ·çš„å‰ç¼€
    pattern = r'^[a-z]-[a-z0-9]+_'
    clean_filename = re.sub(pattern, '', filename)
    return clean_filename

def process_excel_file(file_path: str) -> Tuple[pd.DataFrame, str]:
    """å¤„ç†Excelæ–‡ä»¶ï¼Œè®¡ç®—Qå€¼å’Œåˆ†ç±»ç»“æœ
    
    Args:
        file_path: Excelæ–‡ä»¶è·¯å¾„
        
    Returns:
        å¤„ç†åçš„æ•°æ®æ¡†å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    try:
        # è¯»å–å®Œæ•´çš„Excelæ–‡ä»¶åŒ…æ‹¬è¡¨å¤´
        full_df = pd.read_excel(file_path)
        
        # å…ˆè·å–åŸå§‹è¡¨å¤´ï¼Œåˆ¤æ–­è¡¨å¤´ç»“æ„
        header_df = pd.read_excel(file_path, nrows=2)
        logger.info(f"åŸå§‹è¡¨å¤´ç»“æ„: {header_df.shape}")
        
        # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯è¡¨å¤´ï¼Œç¬¬äºŒè¡Œæ˜¯å¦æ˜¯æ•°æ®
        first_row = header_df.iloc[0].tolist()
        second_row = header_df.iloc[1].tolist() if len(header_df) > 1 else []
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºä¸­æ–‡è¡¨å¤´
        chinese_headers = ['äº•å', 'äº•æ·±', 'é’»æ—¶', 'å…¨é‡', 'ç”²çƒ·', 'ä¹™çƒ·', 'ä¸™çƒ·', 'å¼‚ä¸çƒ·', 'æ­£ä¸çƒ·', 'å¼‚æˆŠçƒ·', 'æ­£æˆŠçƒ·', 'äºŒæ°§åŒ–ç¢³', 'å…¶å®ƒéçƒƒ']
        is_chinese_header = any(str(cell) in chinese_headers for cell in first_row if not pd.isna(cell))
        
        # åˆ¤æ–­ç¬¬äºŒè¡Œæ˜¯å¦æ˜¯æ•°æ®ï¼ˆä¸»è¦åŒ…å«æ•°å€¼ï¼‰
        second_row_is_data = len(second_row) > 0 and sum(1 for cell in second_row if isinstance(cell, (int, float)) and not pd.isna(cell)) > len(second_row) / 2
        
        if is_chinese_header and second_row_is_data:
            # å•è¡Œè¡¨å¤´ï¼Œç¬¬äºŒè¡Œå¼€å§‹æ˜¯æ•°æ®
            skip_rows = 1
            logger.info("æ£€æµ‹åˆ°å•è¡Œä¸­æ–‡è¡¨å¤´ï¼Œè·³è¿‡1è¡Œè¯»å–æ•°æ®")
        else:
            # åŒè¡Œè¡¨å¤´æˆ–å…¶ä»–æ ¼å¼
            skip_rows = 2
            logger.info("ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼Œè·³è¿‡2è¡Œè¯»å–æ•°æ®")
        
        # è¯»å–æ•°æ®éƒ¨åˆ†
        data_df = pd.read_excel(file_path, skiprows=skip_rows)
        logger.info(f"æˆåŠŸè¯»å–Excelæ–‡ä»¶ï¼Œè·³è¿‡{skip_rows}è¡Œè¡¨å¤´ï¼Œå…±{len(data_df)}è¡Œæ•°æ®")
        logger.info(f"ç¬¬ä¸€è¡Œå†…å®¹: {first_row}")
        if second_row:
            logger.info(f"ç¬¬äºŒè¡Œå†…å®¹: {second_row}")
        
        # ä¸­æ–‡åˆ°è‹±æ–‡çš„åˆ—åæ˜ å°„
        chinese_to_english = {
            'äº•å': 'Well', 'äº•æ·±': 'Depth', 'é’»æ—¶': 'Rop', 'å…¨é‡': 'Tg',
            'ç”²çƒ·': 'C1', 'ä¹™çƒ·': 'C2', 'ä¸™çƒ·': 'C3', 'å¼‚ä¸çƒ·': 'iC4', 'æ­£ä¸çƒ·': 'nC4',
            'å¼‚æˆŠçƒ·': 'iC5', 'æ­£æˆŠçƒ·': 'nC5', 'äºŒæ°§åŒ–ç¢³': 'CO2', 'å…¶å®ƒéçƒƒ': 'Other'
        }
        
        # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯ä¸­æ–‡è¡¨å¤´ï¼ˆç”¨äºåˆ—åè½¬æ¢ï¼‰
        is_chinese_header_for_columns = any(str(cell) in chinese_to_english for cell in first_row if not pd.isna(cell))
        
        if is_chinese_header_for_columns:
            # ç¬¬ä¸€è¡Œæ˜¯ä¸­æ–‡è¡¨å¤´ï¼Œè½¬æ¢ä¸ºè‹±æ–‡åˆ—å
            logger.info("æ£€æµ‹åˆ°ä¸­æ–‡è¡¨å¤´ï¼Œè½¬æ¢ä¸ºè‹±æ–‡åˆ—å")
            english_headers = []
            chinese_headers_list = []
            
            for i, cell in enumerate(first_row):
                if pd.isna(cell) or str(cell).strip() == '':
                    english_headers.append(f"Col{i}")
                    chinese_headers_list.append(f"åˆ—{i}")
                else:
                    cell_str = str(cell).strip()
                    if cell_str in chinese_to_english:
                        english_headers.append(chinese_to_english[cell_str])
                        chinese_headers_list.append(cell_str)
                    else:
                        english_headers.append(f"Col{i}")
                        chinese_headers_list.append(cell_str)
            
            # ä½¿ç”¨è‹±æ–‡åˆ—åè®¾ç½®DataFrame
            if len(english_headers) >= len(data_df.columns):
                data_df.columns = english_headers[:len(data_df.columns)]
                logger.info(f"ä½¿ç”¨è½¬æ¢åçš„è‹±æ–‡åˆ—å: {list(data_df.columns)}")
            else:
                # è¡¥å……åˆ—å
                final_columns = english_headers + [f"Col{i}" for i in range(len(english_headers), len(data_df.columns))]
                data_df.columns = final_columns
                logger.info(f"è¡¥å……åˆ—ååä½¿ç”¨: {list(data_df.columns)}")
                
            # ä¿å­˜åŸå§‹è¡¨å¤´ç”¨äºé‡å»º
            original_chinese_headers = chinese_headers_list[:len(data_df.columns)]
            original_english_headers = english_headers[:len(data_df.columns)]
            
        else:
            # å¯èƒ½æ˜¯è‹±æ–‡è¡¨å¤´æˆ–å…¶ä»–æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†
            logger.info("æœªæ£€æµ‹åˆ°æ ‡å‡†ä¸­æ–‡è¡¨å¤´ï¼Œä½¿ç”¨é»˜è®¤åˆ—å")
            default_columns = ["Well", "Depth", "Rop", "Tg", "C1", "C2", "C3", "iC4", "nC4", "iC5", "nC5", "CO2", "Other"]
            data_df.columns = default_columns[:len(data_df.columns)]
            logger.info(f"ä½¿ç”¨é»˜è®¤è‹±æ–‡åˆ—å: {list(data_df.columns)}")
            
            # åˆ›å»ºé»˜è®¤çš„ä¸­è‹±æ–‡è¡¨å¤´
            original_english_headers = list(data_df.columns)
            original_chinese_headers = ['äº•å', 'äº•æ·±', 'é’»æ—¶', 'å…¨é‡', 'ç”²çƒ·', 'ä¹™çƒ·', 'ä¸™çƒ·', 'å¼‚ä¸çƒ·', 'æ­£ä¸çƒ·', 'å¼‚æˆŠçƒ·', 'æ­£æˆŠçƒ·', 'äºŒæ°§åŒ–ç¢³', 'å…¶å®ƒéçƒƒ'][:len(data_df.columns)]
        
        # æ¸…ç†æ•°æ®ï¼šåˆ é™¤ç©ºè¡Œå’Œæ— æ•ˆæ•°æ®
        data_df = data_df.dropna(subset=['Well', 'Depth'])
        
        # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        numeric_columns = ['Depth', 'Rop', 'Tg', 'C1', 'C2', 'C3', 'iC4', 'nC4', 'iC5', 'nC5', 'CO2', 'Other']
        for col in numeric_columns:
            if col in data_df.columns:
                data_df[col] = pd.to_numeric(data_df[col], errors='coerce')
        
        # å†æ¬¡åˆ é™¤è½¬æ¢åçš„æ— æ•ˆè¡Œ
        data_df = data_df.dropna(subset=['C1', 'C2', 'C3', 'nC4'])
        
        logger.info(f"æ•°æ®æ¸…ç†åï¼Œå…±{len(data_df)}è¡Œæœ‰æ•ˆæ•°æ®")
        
        # æ£€æŸ¥å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['Well', 'Depth', 'C1', 'C2', 'C3', 'nC4']
        missing_columns = [col for col in required_columns if col not in data_df.columns]
        
        if missing_columns:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_columns}")
        
        # è®¡ç®—Qå€¼
        logger.info("å¼€å§‹è®¡ç®—Qå€¼...")
        data_df['Qå€¼'] = data_df.apply(calculate_q_value, axis=1)
        
        # è®¡ç®—åˆ†ç±»ç»“æœ
        logger.info("å¼€å§‹è¿›è¡Œå«æ²¹æ°”æ€§è´¨åˆ†ç±»...")
        classification_results = data_df['Qå€¼'].apply(classify_oil_gas_nature)
        
        # å±•å¼€åˆ†ç±»ç»“æœåˆ°å•ç‹¬çš„åˆ—
        data_df['Qå€¼èŒƒå›´'] = [result['q_range'] for result in classification_results]
        data_df['å†…ä¸‰è§’å½¢å½¢çŠ¶'] = [result['triangle_shape'] for result in classification_results]
        data_df['å«æ²¹æ°”æ€§è´¨'] = [result['oil_gas_nature'] for result in classification_results]
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºå·²è§£é‡Šçš„æ–‡ä»¶
        input_filename = Path(file_path).name
        is_interpreted = is_interpreted_file(input_filename)
        
        # é‡å»ºå®Œæ•´çš„Excelæ–‡ä»¶ç»“æ„ï¼Œä¿æŒåŸå§‹åŒè¡Œè¡¨å¤´æ ¼å¼
        logger.info("å¼€å§‹é‡å»ºExcelæ–‡ä»¶ç»“æ„...")
        
        # 1. ä½¿ç”¨ä¹‹å‰ä¿å­˜çš„åŸå§‹è¡¨å¤´æ•°æ®
        # original_english_headerså’Œoriginal_chinese_headerså·²ç»åœ¨ä¸Šé¢å®šä¹‰
        
        # 2. æ¸…ç†åŸå§‹è¡¨å¤´ï¼Œç¡®ä¿æ•°é‡åŒ¹é…åŸå§‹æ•°æ®åˆ—æ•°
        original_data_columns = len(data_df.columns) - 4  # å‡å»æ–°å¢çš„4åˆ—
        clean_english_headers = original_english_headers[:original_data_columns]
        clean_chinese_headers = original_chinese_headers[:original_data_columns]
        
        # ç¡®ä¿é•¿åº¦è¶³å¤Ÿ
        while len(clean_english_headers) < original_data_columns:
            clean_english_headers.append(f"Col{len(clean_english_headers)+1}")
        while len(clean_chinese_headers) < original_data_columns:
            clean_chinese_headers.append(f"åˆ—{len(clean_chinese_headers)+1}")
        
        # 3. ä¸ºæ–°å¢åˆ—æ·»åŠ è¡¨å¤´
        new_english_headers = ['Q_value', 'Q_range', 'Triangle_shape', 'Oil_gas_nature']
        new_chinese_headers = ['Qå€¼', 'Qå€¼èŒƒå›´', 'å†…ä¸‰è§’å½¢å½¢çŠ¶', 'å«æ²¹æ°”æ€§è´¨']
        
        # 4. åˆå¹¶è¡¨å¤´ï¼ˆåŸå§‹è¡¨å¤´ + æ–°å¢è¡¨å¤´ï¼‰
        full_english_headers = clean_english_headers + new_english_headers
        full_chinese_headers = clean_chinese_headers + new_chinese_headers
        
        logger.info(f"æœ€ç»ˆè¡¨å¤´é•¿åº¦ - è‹±æ–‡: {len(full_english_headers)}, ä¸­æ–‡: {len(full_chinese_headers)}, æ•°æ®åˆ—: {len(data_df.columns)}")
        
        # 5. æ„å»ºæœ€ç»ˆçš„DataFrame
        # åˆ›å»ºè¡¨å¤´è¡Œï¼ˆä¿æŒåŸå§‹æ ¼å¼ï¼šç¬¬ä¸€è¡Œè‹±æ–‡ï¼Œç¬¬äºŒè¡Œä¸­æ–‡ï¼‰
        row1_data = [full_english_headers[i] if i < len(full_english_headers) else '' for i in range(len(data_df.columns))]
        row2_data = [full_chinese_headers[i] if i < len(full_chinese_headers) else '' for i in range(len(data_df.columns))]
        
        # åˆ›å»ºå®Œæ•´çš„DataFrameï¼ŒåŒ…å«è¡¨å¤´å’Œæ•°æ®
        all_data = []
        all_data.append(row1_data)  # ç¬¬ä¸€è¡Œï¼šè‹±æ–‡è¡¨å¤´
        all_data.append(row2_data)  # ç¬¬äºŒè¡Œï¼šä¸­æ–‡è¡¨å¤´
        
        # æ·»åŠ æ‰€æœ‰æ•°æ®è¡Œï¼ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²é¿å…ç±»å‹é—®é¢˜ï¼‰
        for _, row in data_df.iterrows():
            all_data.append([str(val) if not pd.isna(val) else '' for val in row])
        
        # æ„å»ºæœ€ç»ˆDataFrame
        final_df = pd.DataFrame(all_data)
        logger.info(f"æœ€ç»ˆDataFrameå½¢çŠ¶: {final_df.shape}")
        
        if is_interpreted:
            # å·²è§£é‡Šæ–‡ä»¶ï¼Œä¿æŒåŸæ–‡ä»¶åå’Œè·¯å¾„
            output_path = file_path
            logger.info("æ£€æµ‹åˆ°å·²è§£é‡Šæ–‡ä»¶ï¼Œå°†åœ¨åŸæ–‡ä»¶åŸºç¡€ä¸Šæ›´æ–°")
            
            # ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ°Excelæ–‡ä»¶
            with pd.ExcelWriter(output_path, engine='openpyxl') as excel_writer:
                final_df.to_excel(excel_writer, sheet_name='Sheet1', index=False, header=False)
        else:
            # åŸå§‹æ–‡ä»¶ï¼Œç”Ÿæˆæ–°çš„è§£é‡Šæ–‡ä»¶ï¼Œä½¿ç”¨file_manageræ¥ä¿å­˜
            original_filename = Path(file_path).name
            # å»æ‰åŸå§‹æ–‡ä»¶çš„IDå‰ç¼€ï¼Œåªä¿ç•™å®é™…æ–‡ä»¶å
            clean_filename = remove_file_id_prefix(original_filename)
            # å»æ‰æ‰©å±•ååæ·»åŠ _interpreted
            stem = Path(clean_filename).stem
            new_filename = f"{stem}_interpreted.xlsx"
            logger.info(f"æ£€æµ‹åˆ°åŸå§‹æ–‡ä»¶ï¼Œå°†ç”Ÿæˆæ–°çš„è§£é‡Šæ–‡ä»¶: {new_filename}")
            
            # å…ˆå°†DataFrameä¿å­˜åˆ°å­—èŠ‚æµ
            import io
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as excel_writer:
                final_df.to_excel(excel_writer, sheet_name='Sheet1', index=False, header=False)
            excel_data = excel_buffer.getvalue()
            
            # ä½¿ç”¨file_managerä¿å­˜æ–‡ä»¶
            file_id = file_manager.save_file(
                file_data=excel_data,
                file_name=new_filename,
                file_type="xlsx",
                source="generated"
            )
            
            # è·å–ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
            file_info = file_manager.get_file_info(file_id)
            output_path = file_info.get("file_path")
        
        logger.info(f"å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return data_df, output_path
        
    except Exception as e:
        logger.error(f"å¤„ç†Excelæ–‡ä»¶å¤±è´¥: {e}")
        raise

@register_tool(category="gas_logging")
def triangular_chart_analysis(file_id: str) -> str:
    """æ°”æµ‹å½•äº•åˆ†æç¬¬äºŒæ­¥-ä¸‰è§’å›¾ç‰ˆæ³•è§£é‡Šå«æ²¹æ°”æ€§è´¨å·¥å…·
    
    åŸºäºQå€¼è®¡ç®—è¿›è¡Œå«æ²¹æ°”æ€§è´¨åˆ¤åˆ«ã€‚Qå€¼è®¡ç®—å…¬å¼ï¼šQ=1âˆ’(C2+C3+nC4)/(0.2âˆ‘C)
    
    æ ¹æ®Qå€¼èŒƒå›´è¯„ä»·å«æ²¹æ°”æ€§è´¨ï¼š
    - 75%ï½100%ï¼šæ°´æˆ–æ°”å±‚ï¼ˆå¤§æ­£ä¸‰è§’å½¢ï¼‰
    - 25%ï½75%ï¼šæ²¹æ°”å±‚æˆ–å«æ²¹æ°´å±‚ï¼ˆä¸­æ­£ä¸‰è§’å½¢ï¼‰  
    - 0%ï½25%ï¼šæ²¹æ°”è½¬åŒ–å¸¦ï¼ˆå°æ­£ä¸‰è§’å½¢ï¼‰
    - -25%ï½0%ï¼šæ²¹æ°”è½¬åŒ–å¸¦ï¼ˆå°å€’ä¸‰è§’å½¢ï¼‰
    - -25%ï½-75%ï¼šæ²¹å±‚ï¼ˆé«˜æ°”æ²¹æ¯”ï¼‰ï¼ˆä¸­å€’ä¸‰è§’å½¢ï¼‰
    - -75%ï½-100%ï¼šæ²¹å±‚ï¼ˆé«˜æ°”æ²¹æ¯”ï¼‰ï¼ˆå¤§å€’ä¸‰è§’å½¢ï¼‰
    
    Args:
        file_id: Excelæ–‡ä»¶IDï¼Œå¯ä»¥æ˜¯åŸå§‹ä¸Šä¼ æ–‡ä»¶æˆ–å‰ä¸€å·¥å…·ç”Ÿæˆçš„è§£é‡Šæ–‡ä»¶ã€‚
                å¦‚æœæ˜¯åœ¨å…¶ä»–å½•äº•å·¥å…·ä¹‹åæ‰§è¡Œï¼Œåº”ä½¿ç”¨å‰ä¸€å·¥å…·è¿”å›ä¿¡æ¯ä¸­çš„NEXT_FILE_IDï¼Œ
                ä»¥åœ¨å·²æœ‰è§£é‡Šç»“æœåŸºç¡€ä¸Šè¿½åŠ æ–°çš„åˆ†æåˆ—ã€‚
                æ–‡ä»¶åº”åŒ…å«Wellã€Depthã€C1ã€C2ã€C3ã€nC4ç­‰åˆ—ã€‚
        
    Returns:
        åˆ†æç»“æœæŠ¥å‘Šï¼ŒåŒ…å«æ–°ç”Ÿæˆæ–‡ä»¶çš„NEXT_FILE_IDä¾›åç»­å·¥å…·ä½¿ç”¨
    """
    writer = get_stream_writer()
    
    try:
        if writer:
            writer({"custom_step": "å¼€å§‹ä¸‰è§’å›¾ç‰ˆæ³•å«æ²¹æ°”æ€§è´¨åˆ†æ..."})
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = file_manager.get_file_info(file_id)
        if not file_info:
            error_msg = f"æ‰¾ä¸åˆ°IDä¸º {file_id} çš„æ–‡ä»¶"
            logger.error(error_msg)
            return error_msg
        
        file_path = file_info.get("file_path")
        file_name = file_info.get("file_name", "")
        
        if writer:
            writer({"custom_step": f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_name}"})
        
        # å¤„ç†Excelæ–‡ä»¶
        df, output_excel_path = process_excel_file(file_path)
        
        if writer:
            writer({"custom_step": f"æˆåŠŸå¤„ç†{len(df)}è¡Œæ•°æ®ï¼Œè®¡ç®—Qå€¼å¹¶è¿›è¡Œåˆ†ç±»"})
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        # å»æ‰æ–‡ä»¶åä¸­çš„IDå‰ç¼€ï¼Œç”Ÿæˆæ¸…æ´çš„å›¾ç‰‡æ–‡ä»¶å
        clean_filename = remove_file_id_prefix(file_name)
        base_name = Path(clean_filename).stem
        # ä½¿ç”¨æ›´ç›´è§‚çš„æ–‡ä»¶å
        image_filename = f"ä¸‰è§’å›¾ç‰ˆæ³•è§£é‡Šå›¾è¡¨_{base_name}.png"
        
        # ä¸´æ—¶è·¯å¾„ç”¨äºç”Ÿæˆå›¾ç‰‡
        temp_image_path = os.path.join(file_manager.temp_path, f"temp_{image_filename}")
        chart_path = create_triangular_chart_visualization(df, temp_image_path)
        
        # å¦‚æœå›¾ç‰‡ç”ŸæˆæˆåŠŸï¼Œä½¿ç”¨file_managerä¿å­˜
        if chart_path and os.path.exists(chart_path):
            # è¯»å–å›¾ç‰‡æ•°æ®
            with open(chart_path, 'rb') as f:
                image_data = f.read()
            
            # ä½¿ç”¨file_managerä¿å­˜å›¾ç‰‡
            image_file_id = file_manager.save_file(
                file_data=image_data,
                file_name=image_filename,
                file_type="png",
                source="generated"
            )
            
            # è·å–ä¿å­˜åçš„å›¾ç‰‡è·¯å¾„
            image_file_info = file_manager.get_file_info(image_file_id)
            final_image_path = image_file_info.get("file_path")
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_image_path)
            except:
                pass
        else:
            final_image_path = None
        
        # ç»Ÿè®¡åˆ†æç»“æœ
        total_samples = len(df)
        valid_samples = df['Qå€¼'].notna().sum()
        
        # ç»Ÿè®¡å„ç±»å‹çš„æ ·å“æ•°é‡
        nature_stats = df['å«æ²¹æ°”æ€§è´¨'].value_counts()
        
        if writer:
            writer({"custom_step": f"ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨: {image_filename}"})
        
        # æ¨é€å›¾ç‰‡åˆ°UI
        if final_image_path and os.path.exists(final_image_path):
            image_message = {
                "image_path": final_image_path,
                "title": "ä¸‰è§’å›¾ç‰ˆæ³•è§£é‡Šå›¾è¡¨"
            }
            if writer:
                writer({"image_message": image_message})
        
        # æ¨é€Excelæ–‡ä»¶åˆ°UI
        file_message = {
            "file_path": output_excel_path,
            "file_name": Path(output_excel_path).name,
            "file_type": "xlsx"
        }
        if writer:
            writer({"file_message": file_message})
        
        # ç”Ÿæˆç®€æ´çš„æ‰§è¡Œç»“æœä¿¡æ¯
        if len(nature_stats) > 0:
            main_nature = nature_stats.index[0]
            main_percentage = (nature_stats.iloc[0] / total_samples) * 100
            nature_summary = f"ä¸»è¦å±‚å‹ï¼š{main_nature}({main_percentage:.1f}%)"
        else:
            nature_summary = "æ— æœ‰æ•ˆåˆ†ç±»ç»“æœ"
        
        result_message = f"""âœ… ä¸‰è§’å›¾ç‰ˆæ³•åˆ†æå®Œæˆ
ğŸ†” **NEXT_FILE_ID: {file_id}** (åç»­å·¥å…·è¯·ä½¿ç”¨æ­¤file_id)
ğŸ“Š å¤„ç†æ ·å“: {total_samples}ä¸ª (æœ‰æ•ˆ: {valid_samples}ä¸ª)
ğŸ¯ {nature_summary}
ğŸ“ è§£é‡Šç»“æœæ–‡ä»¶: {Path(output_excel_path).name}
ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨: {image_filename}

âš ï¸ é‡è¦: åç»­å·¥å…·å¿…é¡»ä½¿ç”¨file_id: {file_id} ä»¥åœ¨æ­¤ç»“æœåŸºç¡€ä¸Šè¿½åŠ åˆ†æ"""
        
        if writer:
            writer({"custom_step": "ä¸‰è§’å›¾ç‰ˆæ³•åˆ†æå®Œæˆ"})
        
        logger.info("ä¸‰è§’å›¾ç‰ˆæ³•å«æ²¹æ°”æ€§è´¨åˆ†æå®Œæˆ")
        return result_message
        
    except Exception as e:
        error_msg = f"ä¸‰è§’å›¾ç‰ˆæ³•åˆ†æå¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        
        if writer:
            writer({"custom_step": f"âŒ {error_msg}"})
        
        return error_msg 