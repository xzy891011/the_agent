"""
å…¨çƒƒTGè¯„ä»·æ²¹æ°”æ°´å±‚å·¥å…·

è¯¥å·¥å…·åŸºäºå…¨çƒƒå«é‡ï¼ˆTGï¼‰è¿›è¡Œæ²¹æ°”æ°´å±‚è¯„ä»·ï¼Œç»¼åˆè€ƒè™‘ï¼š
1. TGç»å¯¹å€¼å¤§å°
2. ç›¸å¯¹äºèƒŒæ™¯å€¼çš„å¼‚å¸¸å€æ•°  
3. éšæ·±åº¦çš„å˜åŒ–è¶‹åŠ¿
4. å¼‚å¸¸çš„è¿ç»­æ€§å’Œåšåº¦

è¯„ä»·æ ‡å‡†ï¼š
å±‚å‹         TGç»å¯¹å€¼    ç›¸å¯¹å¼‚å¸¸å€æ•°    è¶‹åŠ¿ç‰¹å¾              è¿ç»­æ€§
æ°´å±‚         < 2%       < 2å€èƒŒæ™¯å€¼     å¹³ç¨³ï¼Œæ— æ˜æ˜¾å˜åŒ–       -
å¼±æ˜¾ç¤ºå±‚     2-5%       2-3å€èƒŒæ™¯å€¼     è½»å¾®ä¸Šå‡              â‰¥ 0.5m
æ²¹å±‚         5-15%      3-8å€èƒŒæ™¯å€¼     æŒç»­ä¸Šå‡æˆ–ç¨³å®šé«˜å€¼     â‰¥ 1.0m  
æ°”å±‚         15-30%     8-20å€èƒŒæ™¯å€¼    å¿«é€Ÿä¸Šå‡ï¼Œå³°å€¼æ˜æ˜¾     â‰¥ 0.5m
å¼ºæ°”å±‚       > 30%      > 20å€èƒŒæ™¯å€¼    æ€¥å‰§ä¸Šå‡ï¼Œæé«˜å³°å€¼     â‰¥ 0.5m
"""

import os
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from scipy.ndimage import uniform_filter1d
from typing import Dict, List, Optional, Union, Any, Tuple
import io
import base64
from pathlib import Path
import uuid
import platform

from app.core.file_manager import file_manager
from app.tools.registry import register_tool
from langgraph.config import get_stream_writer

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# é…ç½®ä¸­æ–‡å­—ä½“
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    try:
        if platform.system() == 'Windows':
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
        elif platform.system() == 'Darwin':  # macOS
            plt.rcParams['font.sans-serif'] = ['Hei', 'Arial Unicode MS']
        else:  # Linux
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei']
        plt.rcParams['axes.unicode_minus'] = False
    except Exception as e:
        logger.warning(f"è®¾ç½®ä¸­æ–‡å­—ä½“å¤±è´¥: {e}")

def calculate_background_tg(tg_values: np.ndarray, window_size: int = 10) -> np.ndarray:
    """è®¡ç®—TGèƒŒæ™¯å€¼
    
    ä½¿ç”¨ç§»åŠ¨çª—å£çš„ä¸­ä½æ•°æ¥è®¡ç®—èƒŒæ™¯å€¼ï¼Œé¿å…å¼‚å¸¸é«˜å€¼çš„å½±å“
    
    Args:
        tg_values: TGå€¼æ•°ç»„
        window_size: ç§»åŠ¨çª—å£å¤§å°
        
    Returns:
        èƒŒæ™¯TGå€¼æ•°ç»„
    """
    # ä½¿ç”¨æ»šåŠ¨ä¸­ä½æ•°è®¡ç®—èƒŒæ™¯å€¼
    background = np.zeros_like(tg_values)
    half_window = window_size // 2
    
    for i in range(len(tg_values)):
        start_idx = max(0, i - half_window)
        end_idx = min(len(tg_values), i + half_window + 1)
        window_data = tg_values[start_idx:end_idx]
        
        # å»é™¤å¼‚å¸¸é«˜å€¼åè®¡ç®—ä¸­ä½æ•°
        q75 = np.percentile(window_data, 75)
        q25 = np.percentile(window_data, 25)
        iqr = q75 - q25
        upper_bound = q75 + 1.5 * iqr
        
        # åªä½¿ç”¨ä¸è¶…è¿‡ä¸Šç•Œçš„æ•°æ®è®¡ç®—èƒŒæ™¯å€¼
        filtered_data = window_data[window_data <= upper_bound]
        if len(filtered_data) > 0:
            background[i] = np.median(filtered_data)
        else:
            background[i] = np.median(window_data)
    
    return background

def calculate_tg_anomaly_ratio(tg_values: np.ndarray, background_values: np.ndarray) -> np.ndarray:
    """è®¡ç®—TGå¼‚å¸¸å€æ•°
    
    Args:
        tg_values: TGå€¼æ•°ç»„
        background_values: èƒŒæ™¯TGå€¼æ•°ç»„
        
    Returns:
        å¼‚å¸¸å€æ•°æ•°ç»„
    """
    # é¿å…é™¤é›¶é”™è¯¯ï¼Œè®¾ç½®æœ€å°èƒŒæ™¯å€¼
    min_background = 0.1
    safe_background = np.maximum(background_values, min_background)
    
    anomaly_ratio = tg_values / safe_background
    return anomaly_ratio

def classify_layer_type(tg_value: float, anomaly_ratio: float, depth_trend: str = 'stable') -> Dict[str, str]:
    """æ ¹æ®TGå€¼å’Œå¼‚å¸¸å€æ•°åˆ†ç±»å±‚å‹
    
    Args:
        tg_value: TGç»å¯¹å€¼
        anomaly_ratio: ç›¸å¯¹å¼‚å¸¸å€æ•°
        depth_trend: æ·±åº¦è¶‹åŠ¿ ('rising', 'stable', 'falling')
        
    Returns:
        åŒ…å«åˆ†ç±»ç»“æœçš„å­—å…¸
    """
    if pd.isna(tg_value) or tg_value < 0:
        return {
            "layer_type": "æ— æ•ˆæ•°æ®",
            "confidence": "ä½",
            "description": "æ•°æ®æ— æ•ˆ"
        }
    
    # åŸºäºTGç»å¯¹å€¼å’Œå¼‚å¸¸å€æ•°çš„åˆ†ç±»
    if tg_value < 2 and anomaly_ratio < 2:
        layer_type = "æ°´å±‚"
        confidence = "é«˜"
        description = "TGå€¼ä½ï¼Œæ— æ˜æ˜¾å¼‚å¸¸"
    elif 2 <= tg_value < 5 and 2 <= anomaly_ratio < 3:
        layer_type = "å¼±æ˜¾ç¤ºå±‚"
        confidence = "ä¸­"
        description = "TGå€¼è½»å¾®å¼‚å¸¸"
    elif 5 <= tg_value < 15 and 3 <= anomaly_ratio < 8:
        if depth_trend == 'rising':
            layer_type = "æ²¹å±‚"
            confidence = "é«˜"
            description = "TGå€¼æŒç»­ä¸Šå‡ï¼Œæ²¹å±‚ç‰¹å¾æ˜æ˜¾"
        else:
            layer_type = "æ²¹å±‚"
            confidence = "ä¸­"
            description = "TGå€¼å¼‚å¸¸ï¼Œå¯èƒ½ä¸ºæ²¹å±‚"
    elif 15 <= tg_value < 30 and 8 <= anomaly_ratio < 20:
        layer_type = "æ°”å±‚"
        confidence = "é«˜"
        description = "TGå€¼æ˜¾è‘—å¼‚å¸¸ï¼Œæ°”å±‚ç‰¹å¾æ˜æ˜¾"
    elif tg_value >= 30 and anomaly_ratio >= 20:
        layer_type = "å¼ºæ°”å±‚"
        confidence = "é«˜"
        description = "TGå€¼æé«˜å¼‚å¸¸ï¼Œå¼ºæ°”å±‚ç‰¹å¾"
    else:
        # è¾¹ç•Œæƒ…å†µçš„ç»¼åˆåˆ¤æ–­
        if tg_value >= 15:
            layer_type = "æ°”å±‚"
            confidence = "ä¸­"
            description = "TGå€¼é«˜ï¼Œç–‘ä¼¼æ°”å±‚"
        elif tg_value >= 5:
            layer_type = "æ²¹å±‚"
            confidence = "ä¸­"
            description = "TGå€¼ä¸­ç­‰å¼‚å¸¸ï¼Œç–‘ä¼¼æ²¹å±‚"
        elif tg_value >= 2:
            layer_type = "å¼±æ˜¾ç¤ºå±‚"
            confidence = "ä½"
            description = "TGå€¼è½»å¾®å¼‚å¸¸"
        else:
            layer_type = "æ°´å±‚"
            confidence = "ä¸­"
            description = "TGå€¼è¾ƒä½"
    
    return {
        "layer_type": layer_type,
        "confidence": confidence,
        "description": description
    }

def analyze_depth_trend(depths: np.ndarray, tg_values: np.ndarray, window_size: int = 5) -> np.ndarray:
    """åˆ†æTGå€¼éšæ·±åº¦çš„å˜åŒ–è¶‹åŠ¿
    
    Args:
        depths: æ·±åº¦æ•°ç»„
        tg_values: TGå€¼æ•°ç»„
        window_size: è¶‹åŠ¿åˆ†æçª—å£å¤§å°
        
    Returns:
        è¶‹åŠ¿æ•°ç»„ ('rising', 'stable', 'falling')
    """
    trends = np.full(len(tg_values), 'stable', dtype=object)
    half_window = window_size // 2
    
    for i in range(len(tg_values)):
        start_idx = max(0, i - half_window)
        end_idx = min(len(tg_values), i + half_window + 1)
        
        if end_idx - start_idx >= 3:  # è‡³å°‘éœ€è¦3ä¸ªç‚¹è®¡ç®—è¶‹åŠ¿
            window_depths = depths[start_idx:end_idx]
            window_tg = tg_values[start_idx:end_idx]
            
            # è®¡ç®—çº¿æ€§å›å½’æ–œç‡
            try:
                slope, _, r_value, _, _ = stats.linregress(window_depths, window_tg)
                
                # æ ¹æ®æ–œç‡å’Œç›¸å…³æ€§åˆ¤æ–­è¶‹åŠ¿
                if abs(r_value) > 0.5:  # ç›¸å…³æ€§è¶³å¤Ÿå¼º
                    if slope > 0.1:  # æ–œç‡é˜ˆå€¼å¯è°ƒæ•´
                        trends[i] = 'rising'
                    elif slope < -0.1:
                        trends[i] = 'falling'
                    else:
                        trends[i] = 'stable'
                else:
                    trends[i] = 'stable'
            except:
                trends[i] = 'stable'
    
    return trends

def check_layer_continuity(layer_types: np.ndarray, depths: np.ndarray, min_thickness: float = 0.5) -> np.ndarray:
    """æ£€æŸ¥å±‚å‹çš„è¿ç»­æ€§
    
    Args:
        layer_types: å±‚å‹æ•°ç»„
        depths: æ·±åº¦æ•°ç»„
        min_thickness: æœ€å°åšåº¦è¦æ±‚
        
    Returns:
        è¿ç»­æ€§æ ¡æ­£åçš„å±‚å‹æ•°ç»„
    """
    corrected_types = layer_types.copy()
    
    # å¯¹äºéæ°´å±‚çš„ç±»å‹ï¼Œæ£€æŸ¥è¿ç»­æ€§
    for layer_type in ['å¼±æ˜¾ç¤ºå±‚', 'æ²¹å±‚', 'æ°”å±‚', 'å¼ºæ°”å±‚']:
        # æ‰¾åˆ°è¯¥ç±»å‹çš„æ‰€æœ‰ä½ç½®
        type_mask = layer_types == layer_type
        
        if not np.any(type_mask):
            continue
        
        # æ‰¾åˆ°è¿ç»­æ®µ
        diff = np.diff(np.concatenate(([False], type_mask, [False])).astype(int))
        starts = np.where(diff == 1)[0]
        ends = np.where(diff == -1)[0]
        
        for start, end in zip(starts, ends):
            segment_thickness = depths[end-1] - depths[start]
            
            # æ ¹æ®å±‚å‹è¦æ±‚çš„æœ€å°åšåº¦è¿›è¡Œåˆ¤æ–­
            required_thickness = min_thickness
            if layer_type == 'æ²¹å±‚':
                required_thickness = 1.0  # æ²¹å±‚è¦æ±‚æ›´åšçš„è¿ç»­æ€§
            
            if segment_thickness < required_thickness:
                # åšåº¦ä¸è¶³ï¼Œé™çº§å¤„ç†
                if layer_type in ['æ°”å±‚', 'å¼ºæ°”å±‚']:
                    corrected_types[start:end] = 'å¼±æ˜¾ç¤ºå±‚'
                elif layer_type == 'æ²¹å±‚':
                    corrected_types[start:end] = 'å¼±æ˜¾ç¤ºå±‚'
                else:
                    corrected_types[start:end] = 'æ°´å±‚'
    
    return corrected_types

def create_tg_evaluation_visualization(df: pd.DataFrame, output_path: str) -> str:
    """åˆ›å»ºTGè¯„ä»·å¯è§†åŒ–å›¾è¡¨
    
    Args:
        df: åŒ…å«TGè¯„ä»·ç»“æœçš„æ•°æ®æ¡†
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        
    Returns:
        å›¾ç‰‡æ–‡ä»¶è·¯å¾„
    """
    try:
        # è®¾ç½®matplotlibä½¿ç”¨Aggåç«¯ï¼Œé¿å…æ˜¾ç¤ºé—®é¢˜
        import matplotlib
        matplotlib.use('Agg')
        
        setup_chinese_font()
        
        # æ¸…ç†æ‰€æœ‰matplotlibçŠ¶æ€
        plt.clf()
        plt.close('all')
        
        # è®°å½•åŸå§‹æ•°æ®ä¿¡æ¯
        logger.info(f"å¼€å§‹åˆ›å»ºTGå¯è§†åŒ–å›¾è¡¨")
        logger.info(f"åŸå§‹æ•°æ®è¡Œæ•°: {len(df)}, åˆ—å: {list(df.columns)}")
        
        # æ•°æ®é¢„å¤„ç†
        logger.info("å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        depths = pd.to_numeric(df['Depth'], errors='coerce') if 'Depth' in df.columns else None
        tg_values = pd.to_numeric(df['Tg'], errors='coerce') if 'Tg' in df.columns else None
        background_values = pd.to_numeric(df['TGèƒŒæ™¯å€¼'], errors='coerce') if 'TGèƒŒæ™¯å€¼' in df.columns else None
        anomaly_ratios = pd.to_numeric(df['å¼‚å¸¸å€æ•°'], errors='coerce') if 'å¼‚å¸¸å€æ•°' in df.columns else None
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        if depths is not None and tg_values is not None:
            valid_mask = pd.notna(tg_values) & pd.notna(depths) & (tg_values >= 0) & (depths > 0)
            valid_depths = depths[valid_mask]
            valid_tg = tg_values[valid_mask]
            valid_background = background_values[valid_mask] if background_values is not None else None
            valid_anomaly = anomaly_ratios[valid_mask] if anomaly_ratios is not None else None
            
            logger.info(f"æœ‰æ•ˆæ•°æ®ç‚¹æ•°: {len(valid_depths)}")
            logger.info(f"æ·±åº¦èŒƒå›´: {valid_depths.min():.1f} - {valid_depths.max():.1f} m")
            logger.info(f"TGå€¼èŒƒå›´: {valid_tg.min():.3f} - {valid_tg.max():.3f} %")
            logger.info(f"éé›¶TGå€¼æ•°é‡: {(valid_tg > 0).sum()}")
        else:
            logger.error("ç¼ºå°‘æ·±åº¦æˆ–TGæ•°æ®ï¼Œæ— æ³•åˆ›å»ºå›¾è¡¨")
            return ""
        
        # åˆ›å»ºå­å›¾
        logger.info("åˆ›å»ºå­å›¾...")
        ax1 = plt.subplot(2, 2, 1)
        ax2 = plt.subplot(2, 2, 2)
        ax3 = plt.subplot(2, 2, 3)
        ax4 = plt.subplot(2, 2, 4)
        
        # å›¾1ï¼šTGå€¼æ·±åº¦å‰–é¢å›¾
        logger.info("ç»˜åˆ¶å›¾1ï¼šTGå€¼æ·±åº¦å‰–é¢å›¾")
        try:
            ax1.plot(valid_tg, valid_depths, linewidth=1, label='TGå®æµ‹å€¼', color='blue')
            if valid_background is not None and len(valid_background) > 0:
                ax1.plot(valid_background, valid_depths, linewidth=1, label='TGèƒŒæ™¯å€¼', color='red', linestyle='--')
                # å¡«å……å¼‚å¸¸åŒº
                anomaly_mask = valid_tg > valid_background
                if anomaly_mask.any():
                    ax1.fill_betweenx(valid_depths, valid_background, valid_tg, 
                                     where=anomaly_mask, alpha=0.3, color='orange', label='å¼‚å¸¸åŒº')
            
            ax1.invert_yaxis()
            ax1.set_xlabel('TGå€¼ (%)', fontsize=12, color='black')
            ax1.set_ylabel('æ·±åº¦ (m)', fontsize=12, color='black')
            ax1.set_title('TGå€¼æ·±åº¦å‰–é¢å›¾', fontsize=14, fontweight='bold', color='black')
            ax1.legend(fontsize=10)
            ax1.grid(True, alpha=0.3)
            ax1.set_facecolor('white')
            
            # è®¾ç½®Xè½´èŒƒå›´
            tg_max = valid_tg.max()
            ax1.set_xlim(0, max(5, tg_max + 1))
            
            # æ·»åŠ å‚è€ƒçº¿
            for threshold in [2, 5, 15]:
                if threshold <= ax1.get_xlim()[1]:
                    ax1.axvline(x=threshold, color='red', linestyle=':', alpha=0.7, linewidth=1)
            
            logger.info(f"å›¾1ç»˜åˆ¶å®Œæˆï¼Œæ•°æ®ç‚¹æ•°: {len(valid_tg)}")
        except Exception as e:
            logger.error(f"ç»˜åˆ¶å›¾1å¤±è´¥: {e}")
            ax1.text(0.5, 0.5, f'å›¾1ç»˜åˆ¶å¤±è´¥: {str(e)}', transform=ax1.transAxes, 
                    ha='center', va='center', fontsize=12, color='red')
        
        # å›¾2ï¼šå¼‚å¸¸å€æ•°æ·±åº¦å‰–é¢å›¾
        logger.info("ç»˜åˆ¶å›¾2ï¼šå¼‚å¸¸å€æ•°æ·±åº¦å‰–é¢å›¾")
        try:
            if valid_anomaly is not None and len(valid_anomaly) > 0:
                ax2.plot(valid_anomaly, valid_depths, linewidth=1, color='green')
                ax2.invert_yaxis()
                ax2.set_xlabel('å¼‚å¸¸å€æ•°', fontsize=12, color='black')
                ax2.set_ylabel('æ·±åº¦ (m)', fontsize=12, color='black')
                ax2.set_title('TGå¼‚å¸¸å€æ•°æ·±åº¦å‰–é¢å›¾', fontsize=14, fontweight='bold', color='black')
                ax2.grid(True, alpha=0.3)
                ax2.set_facecolor('white')
                logger.info(f"å›¾2ç»˜åˆ¶å®Œæˆï¼Œæ•°æ®ç‚¹æ•°: {len(valid_anomaly)}")
            else:
                ax2.text(0.5, 0.5, 'æ— å¼‚å¸¸å€æ•°æ•°æ®', transform=ax2.transAxes, 
                        ha='center', va='center', fontsize=14, color='red')
                ax2.set_title('TGå¼‚å¸¸å€æ•°æ·±åº¦å‰–é¢å›¾', fontsize=14, fontweight='bold', color='black')
        except Exception as e:
            logger.error(f"ç»˜åˆ¶å›¾2å¤±è´¥: {e}")
            ax2.text(0.5, 0.5, f'å›¾2ç»˜åˆ¶å¤±è´¥: {str(e)}', transform=ax2.transAxes, 
                    ha='center', va='center', fontsize=12, color='red')
        
        # å›¾3ï¼šå±‚å‹åˆ†å¸ƒç»Ÿè®¡é¥¼å›¾
        logger.info("ç»˜åˆ¶å›¾3ï¼šå±‚å‹åˆ†å¸ƒç»Ÿè®¡é¥¼å›¾")
        try:
            if 'å±‚å‹' in df.columns:
                layer_counts = df['å±‚å‹'].value_counts()
                logger.info(f"å±‚å‹ç»Ÿè®¡: {dict(layer_counts)}")
                
                if len(layer_counts) > 0:
                    colors = {'æ°´å±‚': '#87CEEB', 'å¼±æ˜¾ç¤ºå±‚': '#FFE4B5', 'æ²¹å±‚': '#90EE90', 
                             'æ°”å±‚': '#FFA07A', 'å¼ºæ°”å±‚': '#FF6347', 'æ— æ•ˆæ•°æ®': '#D3D3D3'}
                    pie_colors = [colors.get(layer, '#D3D3D3') for layer in layer_counts.index]
                    
                    # è®¡ç®—ç™¾åˆ†æ¯”ï¼Œç”¨äºå†³å®šæ˜¯å¦æ˜¾ç¤ºå°æ‰‡å½¢çš„æ ‡ç­¾
                    total = layer_counts.sum()
                    percentages = (layer_counts / total * 100).round(1)
                    
                    # è‡ªå®šä¹‰autopctå‡½æ•°ï¼Œå°äº1%çš„ä¸æ˜¾ç¤ºç™¾åˆ†æ¯”
                    def autopct_format(pct):
                        return f'{pct:.1f}%' if pct >= 1.0 else ''
                    
                    # ä¸ºå°æ‰‡å½¢è°ƒæ•´æ ‡ç­¾æ˜¾ç¤º
                    labels = []
                    for i, (layer, count) in enumerate(layer_counts.items()):
                        pct = percentages.iloc[i]
                        if pct >= 2.0:  # å¤§äº2%æ˜¾ç¤ºå®Œæ•´æ ‡ç­¾
                            labels.append(layer)
                        elif pct >= 0.5:  # 0.5%-2%æ˜¾ç¤ºç®€åŒ–æ ‡ç­¾
                            labels.append(layer[:2])  # åªæ˜¾ç¤ºå‰ä¸¤ä¸ªå­—
                        else:  # å°äº0.5%ä¸æ˜¾ç¤ºæ ‡ç­¾
                            labels.append('')
                    
                    # ç»˜åˆ¶é¥¼å›¾ï¼Œè°ƒæ•´å‚æ•°é¿å…æ ‡ç­¾é‡å 
                    wedges, texts, autotexts = ax3.pie(
                        layer_counts.values, 
                        labels=labels,
                        autopct=autopct_format,
                        colors=pie_colors, 
                        startangle=45,  # è°ƒæ•´èµ·å§‹è§’åº¦ï¼Œä¼˜åŒ–æ ‡ç­¾åˆ†å¸ƒ
                        labeldistance=1.15,  # æ ‡ç­¾è·ç¦»åœ†å¿ƒçš„å€æ•°
                        pctdistance=0.85,    # ç™¾åˆ†æ¯”æ ‡ç­¾è·ç¦»åœ†å¿ƒçš„å€æ•°
                        wedgeprops=dict(edgecolor='white', linewidth=1)  # æ·»åŠ ç™½è‰²è¾¹æ¡†åˆ†éš”
                    )
                    
                    # è®¾ç½®æ–‡å­—é¢œè‰²å’Œå¤§å°
                    for text in texts:
                        text.set_color('black')
                        text.set_fontsize(9)  # ç¨å¾®å‡å°å­—ä½“
                        text.set_weight('normal')
                    for autotext in autotexts:
                        autotext.set_color('black')
                        autotext.set_fontsize(8)  # ç™¾åˆ†æ¯”å­—ä½“æ›´å°
                        autotext.set_weight('bold')
                    
                    # ä¸ºå°æ‰‡å½¢æ·»åŠ å›¾ä¾‹ï¼Œæ”¾åœ¨é¥¼å›¾ä¸‹æ–¹
                    if any(percentages < 2.0):
                        legend_labels = []
                        for i, (layer, count) in enumerate(layer_counts.items()):
                            pct = percentages.iloc[i]
                            legend_labels.append(f'{layer}: {pct:.1f}%')
                        
                        ax3.legend(wedges, legend_labels, 
                                  loc='upper center', bbox_to_anchor=(0.5, -0.05),
                                  ncol=2, fontsize=7)
                    
                    ax3.set_title('å±‚å‹åˆ†å¸ƒç»Ÿè®¡', fontsize=14, fontweight='bold', color='black')
                    logger.info(f"å›¾3ç»˜åˆ¶å®Œæˆï¼Œå±‚å‹æ•°é‡: {len(layer_counts)}, ç™¾åˆ†æ¯”: {dict(percentages)}")
                else:
                    ax3.text(0.5, 0.5, 'æ— å±‚å‹æ•°æ®', transform=ax3.transAxes, 
                            ha='center', va='center', fontsize=14, color='red')
                    ax3.set_title('å±‚å‹åˆ†å¸ƒç»Ÿè®¡', fontsize=14, fontweight='bold', color='black')
            else:
                ax3.text(0.5, 0.5, 'ç¼ºå°‘å±‚å‹åˆ—', transform=ax3.transAxes, 
                        ha='center', va='center', fontsize=14, color='red')
                ax3.set_title('å±‚å‹åˆ†å¸ƒç»Ÿè®¡', fontsize=14, fontweight='bold', color='black')
        except Exception as e:
            logger.error(f"ç»˜åˆ¶å›¾3å¤±è´¥: {e}")
            ax3.text(0.5, 0.5, f'å›¾3ç»˜åˆ¶å¤±è´¥: {str(e)}', transform=ax3.transAxes, 
                    ha='center', va='center', fontsize=12, color='red')
        
        # å›¾4ï¼šTGå€¼ç›´æ–¹å›¾åˆ†å¸ƒ
        logger.info("ç»˜åˆ¶å›¾4ï¼šTGå€¼ç›´æ–¹å›¾åˆ†å¸ƒ")
        try:
            n, bins, patches = ax4.hist(valid_tg, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
            
            # æ·»åŠ å‚è€ƒçº¿
            ax4.axvline(x=2, color='red', linestyle='--', alpha=0.8, linewidth=2, label='2%')
            ax4.axvline(x=5, color='orange', linestyle='--', alpha=0.8, linewidth=2, label='5%')
            ax4.axvline(x=15, color='green', linestyle='--', alpha=0.8, linewidth=2, label='15%')
            
            ax4.set_xlabel('TGå€¼ (%)', fontsize=12, color='black')
            ax4.set_ylabel('æ ·å“æ•°é‡', fontsize=12, color='black')
            ax4.set_title('TGå€¼åˆ†å¸ƒç›´æ–¹å›¾', fontsize=14, fontweight='bold', color='black')
            ax4.legend(fontsize=10)
            ax4.grid(True, alpha=0.3)
            ax4.set_facecolor('white')
            
            logger.info(f"å›¾4ç»˜åˆ¶å®Œæˆï¼Œæœ€å¤§é¢‘æ•°: {n.max()}")
        except Exception as e:
            logger.error(f"ç»˜åˆ¶å›¾4å¤±è´¥: {e}")
            ax4.text(0.5, 0.5, f'å›¾4ç»˜åˆ¶å¤±è´¥: {str(e)}', transform=ax4.transAxes, 
                    ha='center', va='center', fontsize=12, color='red')
        
        # è°ƒæ•´å¸ƒå±€å¹¶ä¿å­˜
        logger.info("è°ƒæ•´å¸ƒå±€å¹¶ä¿å­˜å›¾ç‰‡...")
        plt.tight_layout(rect=[0, 0.02, 1, 0.96])  # ä¸ºå›¾ä¾‹ç•™å‡ºç©ºé—´
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white', 
                   edgecolor='none', format='png', transparent=False)
        
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦æˆåŠŸç”Ÿæˆ
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path)
            logger.info(f"TGè¯„ä»·å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {output_path}, æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        else:
            logger.error(f"å›¾ç‰‡ä¿å­˜å¤±è´¥: {output_path}")
            
        plt.close('all')
        return output_path
        
    except Exception as e:
        logger.error(f"åˆ›å»ºå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        plt.close('all')
        return ""

def is_interpreted_file(filename: str) -> bool:
    """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºå·²è§£é‡Šçš„æ–‡ä»¶
    
    Args:
        filename: æ–‡ä»¶å
        
    Returns:
        æ˜¯å¦ä¸ºå·²è§£é‡Šçš„æ–‡ä»¶
    """
    return "interpreted" in filename.lower() or "è§£é‡Š" in filename

def remove_file_id_prefix(filename: str) -> str:
    """å»æ‰æ–‡ä»¶åä¸­çš„IDå‰ç¼€
    
    Args:
        filename: åŸå§‹æ–‡ä»¶åï¼ˆå¯èƒ½åŒ…å«IDå‰ç¼€ï¼‰
        
    Returns:
        å»æ‰IDå‰ç¼€åçš„æ–‡ä»¶å
    """
    import re
    # åŒ¹é…ç±»ä¼¼ "u-abc123_" æˆ– "g-abc123_" è¿™æ ·çš„å‰ç¼€
    pattern = r'^[a-z]-[a-z0-9]+_'
    clean_filename = re.sub(pattern, '', filename)
    return clean_filename

def process_tg_excel_file(file_path: str) -> Tuple[pd.DataFrame, str]:
    """å¤„ç†Excelæ–‡ä»¶ï¼Œè¿›è¡ŒTGè¯„ä»·åˆ†æ
    
    Args:
        file_path: Excelæ–‡ä»¶è·¯å¾„
        
    Returns:
        å¤„ç†åçš„æ•°æ®æ¡†å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    try:
        # å…ˆè·å–åŸå§‹è¡¨å¤´ï¼Œåˆ¤æ–­è¡¨å¤´ç»“æ„
        header_df = pd.read_excel(file_path, nrows=2)
        logger.info(f"åŸå§‹è¡¨å¤´ç»“æ„: {header_df.shape}")
        
        # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯è¡¨å¤´ï¼Œç¬¬äºŒè¡Œæ˜¯å¦æ˜¯æ•°æ®
        first_row = header_df.iloc[0].tolist()
        second_row = header_df.iloc[1].tolist() if len(header_df) > 1 else []
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºä¸­æ–‡è¡¨å¤´
        chinese_headers = ['äº•å', 'äº•æ·±', 'é’»æ—¶', 'å…¨é‡', 'ç”²çƒ·', 'ä¹™çƒ·', 'ä¸™çƒ·', 'å¼‚ä¸çƒ·', 'æ­£ä¸çƒ·', 'å¼‚æˆŠçƒ·', 'æ­£æˆŠçƒ·', 'äºŒæ°§åŒ–ç¢³', 'å…¶å®ƒéçƒƒ']
        is_chinese_header = any(str(cell) in chinese_headers for cell in first_row if not pd.isna(cell))
        
        # åˆ¤æ–­ç¬¬äºŒè¡Œæ˜¯å¦æ˜¯æ•°æ®ï¼ˆä¸»è¦åŒ…å«æ•°å€¼ï¼‰
        second_row_is_data = len(second_row) > 0 and sum(1 for cell in second_row if isinstance(cell, (int, float)) and not pd.isna(cell)) > len(second_row) / 2
        
        if is_chinese_header and second_row_is_data:
            # å•è¡Œè¡¨å¤´ï¼Œç¬¬äºŒè¡Œå¼€å§‹æ˜¯æ•°æ®
            skip_rows = 1
            logger.info("æ£€æµ‹åˆ°å•è¡Œä¸­æ–‡è¡¨å¤´ï¼Œè·³è¿‡1è¡Œè¯»å–æ•°æ®")
        else:
            # åŒè¡Œè¡¨å¤´æˆ–å…¶ä»–æ ¼å¼
            skip_rows = 2
            logger.info("ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼Œè·³è¿‡2è¡Œè¯»å–æ•°æ®")
        
        # è¯»å–æ•°æ®éƒ¨åˆ†
        df = pd.read_excel(file_path, skiprows=skip_rows)
        logger.info(f"æˆåŠŸè¯»å–Excelæ–‡ä»¶ï¼Œè·³è¿‡{skip_rows}è¡Œè¡¨å¤´ï¼Œå…±{len(df)}è¡Œæ•°æ®")
        logger.info(f"ç¬¬ä¸€è¡Œå†…å®¹: {first_row}")
        if second_row:
            logger.info(f"ç¬¬äºŒè¡Œå†…å®¹: {second_row}")
        
        # ä¸­æ–‡åˆ°è‹±æ–‡çš„åˆ—åæ˜ å°„
        chinese_to_english = {
            'äº•å': 'Well', 'äº•æ·±': 'Depth', 'é’»æ—¶': 'Rop', 'å…¨é‡': 'Tg',
            'ç”²çƒ·': 'C1', 'ä¹™çƒ·': 'C2', 'ä¸™çƒ·': 'C3', 'å¼‚ä¸çƒ·': 'iC4', 'æ­£ä¸çƒ·': 'nC4',
            'å¼‚æˆŠçƒ·': 'iC5', 'æ­£æˆŠçƒ·': 'nC5', 'äºŒæ°§åŒ–ç¢³': 'CO2', 'å…¶å®ƒéçƒƒ': 'Other'
        }
        
        # é‡æ–°æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯ä¸­æ–‡è¡¨å¤´ï¼ˆç”¨äºåˆ—åè½¬æ¢ï¼‰
        is_chinese_header_for_columns = any(str(cell) in chinese_to_english for cell in first_row if not pd.isna(cell))
        
        if is_chinese_header_for_columns:
            # ç¬¬ä¸€è¡Œæ˜¯ä¸­æ–‡è¡¨å¤´ï¼Œè½¬æ¢ä¸ºè‹±æ–‡åˆ—å
            logger.info("æ£€æµ‹åˆ°ä¸­æ–‡è¡¨å¤´ï¼Œè½¬æ¢ä¸ºè‹±æ–‡åˆ—å")
            english_headers = []
            chinese_headers = []
            
            for i, cell in enumerate(first_row):
                if pd.isna(cell) or str(cell).strip() == '':
                    english_headers.append(f"Col{i}")
                    chinese_headers.append(f"åˆ—{i}")
                else:
                    cell_str = str(cell).strip()
                    if cell_str in chinese_to_english:
                        english_headers.append(chinese_to_english[cell_str])
                        chinese_headers.append(cell_str)
                    else:
                        english_headers.append(f"Col{i}")
                        chinese_headers.append(cell_str)
            
            # ä½¿ç”¨è‹±æ–‡åˆ—åè®¾ç½®DataFrame
            if len(english_headers) >= len(df.columns):
                df.columns = english_headers[:len(df.columns)]
                logger.info(f"ä½¿ç”¨è½¬æ¢åçš„è‹±æ–‡åˆ—å: {list(df.columns)}")
            else:
                # è¡¥å……åˆ—å
                final_columns = english_headers + [f"Col{i}" for i in range(len(english_headers), len(df.columns))]
                df.columns = final_columns
                logger.info(f"è¡¥å……åˆ—ååä½¿ç”¨: {list(df.columns)}")
                
            # ä¿å­˜åŸå§‹è¡¨å¤´ç”¨äºé‡å»º
            original_chinese_headers = chinese_headers[:len(df.columns)]
            original_english_headers = english_headers[:len(df.columns)]
            
        else:
            # å¯èƒ½æ˜¯è‹±æ–‡è¡¨å¤´æˆ–å…¶ä»–æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†
            logger.info("æœªæ£€æµ‹åˆ°æ ‡å‡†ä¸­æ–‡è¡¨å¤´ï¼Œä½¿ç”¨é»˜è®¤åˆ—å")
            default_columns = ["Well", "Depth", "Rop", "Tg", "C1", "C2", "C3", "iC4", "nC4", "iC5", "nC5", "CO2", "Other"]
            df.columns = default_columns[:len(df.columns)]
            logger.info(f"ä½¿ç”¨é»˜è®¤è‹±æ–‡åˆ—å: {list(df.columns)}")
            
            # åˆ›å»ºé»˜è®¤çš„ä¸­è‹±æ–‡è¡¨å¤´
            original_english_headers = list(df.columns)
            original_chinese_headers = ['äº•å', 'äº•æ·±', 'é’»æ—¶', 'å…¨é‡', 'ç”²çƒ·', 'ä¹™çƒ·', 'ä¸™çƒ·', 'å¼‚ä¸çƒ·', 'æ­£ä¸çƒ·', 'å¼‚æˆŠçƒ·', 'æ­£æˆŠçƒ·', 'äºŒæ°§åŒ–ç¢³', 'å…¶å®ƒéçƒƒ'][:len(df.columns)]
        
        # ç»Ÿä¸€åˆ—åï¼ˆTgæˆ–TGéƒ½è½¬æ¢ä¸ºTgï¼‰
        if 'TG' in df.columns and 'Tg' not in df.columns:
            df = df.rename(columns={'TG': 'Tg'})
        
        # æ¸…ç†æ•°æ®ï¼šåˆ é™¤ç©ºè¡Œå’Œæ— æ•ˆæ•°æ®
        df = df.dropna(subset=['Well', 'Depth'])
        
        # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        numeric_columns = ['Depth', 'Rop', 'Tg']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # å†æ¬¡åˆ é™¤è½¬æ¢åçš„æ— æ•ˆè¡Œ
        df = df.dropna(subset=['Depth', 'Tg'])
        
        logger.info(f"æ•°æ®æ¸…ç†åï¼Œå…±{len(df)}è¡Œæœ‰æ•ˆæ•°æ®")
        
        # æ£€æŸ¥å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['Well', 'Depth', 'Tg']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_columns}")
        
        # æŒ‰æ·±åº¦æ’åº
        df = df.sort_values('Depth').reset_index(drop=True)
        
        # è®¡ç®—TGèƒŒæ™¯å€¼
        logger.info("å¼€å§‹è®¡ç®—TGèƒŒæ™¯å€¼...")
        tg_values = df['Tg'].values
        background_values = calculate_background_tg(tg_values)
        df['TGèƒŒæ™¯å€¼'] = background_values
        
        # è®¡ç®—å¼‚å¸¸å€æ•°
        logger.info("å¼€å§‹è®¡ç®—å¼‚å¸¸å€æ•°...")
        anomaly_ratios = calculate_tg_anomaly_ratio(tg_values, background_values)
        df['å¼‚å¸¸å€æ•°'] = anomaly_ratios
        
        # åˆ†ææ·±åº¦è¶‹åŠ¿
        logger.info("å¼€å§‹åˆ†ææ·±åº¦è¶‹åŠ¿...")
        depths = df['Depth'].values
        trends = analyze_depth_trend(depths, tg_values)
        df['æ·±åº¦è¶‹åŠ¿'] = trends
        
        # è¿›è¡Œå±‚å‹åˆ†ç±»
        logger.info("å¼€å§‹è¿›è¡Œå±‚å‹åˆ†ç±»...")
        classifications = []
        for _, row in df.iterrows():
            classification = classify_layer_type(
                tg_value=row['Tg'],
                anomaly_ratio=row['å¼‚å¸¸å€æ•°'],
                depth_trend=row['æ·±åº¦è¶‹åŠ¿']
            )
            classifications.append(classification)
        
        # å±•å¼€åˆ†ç±»ç»“æœåˆ°å•ç‹¬çš„åˆ—
        df['å±‚å‹'] = [result['layer_type'] for result in classifications]
        df['å¯ä¿¡åº¦'] = [result['confidence'] for result in classifications]
        df['æè¿°'] = [result['description'] for result in classifications]
        
        # è¿ç»­æ€§æ ¡æ­£
        logger.info("å¼€å§‹è¿ç»­æ€§æ ¡æ­£...")
        layer_types = df['å±‚å‹'].values
        corrected_types = check_layer_continuity(layer_types, depths)
        df['è¿ç»­æ€§æ ¡æ­£åå±‚å‹'] = corrected_types
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºå·²è§£é‡Šçš„æ–‡ä»¶
        input_filename = Path(file_path).name
        is_interpreted = is_interpreted_file(input_filename)
        
        # é‡å»ºå®Œæ•´çš„Excelæ–‡ä»¶ç»“æ„ï¼Œä¿æŒåŸå§‹åŒè¡Œè¡¨å¤´æ ¼å¼
        logger.info("å¼€å§‹é‡å»ºExcelæ–‡ä»¶ç»“æ„...")
        
        # 1. ä½¿ç”¨ä¹‹å‰ä¿å­˜çš„åŸå§‹è¡¨å¤´æ•°æ®
        # original_english_headerså’Œoriginal_chinese_headerså·²ç»åœ¨ä¸Šé¢å®šä¹‰
        
        # 2. æ¸…ç†åŸå§‹è¡¨å¤´ï¼Œç¡®ä¿æ•°é‡åŒ¹é…åŸå§‹æ•°æ®åˆ—æ•°
        original_data_columns = len(df.columns) - 7  # å‡å»æ–°å¢çš„7åˆ—
        clean_english_headers = original_english_headers[:original_data_columns]
        clean_chinese_headers = original_chinese_headers[:original_data_columns]
        
        # ç¡®ä¿é•¿åº¦è¶³å¤Ÿ
        while len(clean_english_headers) < original_data_columns:
            clean_english_headers.append(f"Col{len(clean_english_headers)+1}")
        while len(clean_chinese_headers) < original_data_columns:
            clean_chinese_headers.append(f"åˆ—{len(clean_chinese_headers)+1}")
        
        # 3. ä¸ºæ–°å¢åˆ—æ·»åŠ è¡¨å¤´
        new_english_headers = ['TG_background', 'Anomaly_ratio', 'Depth_trend', 'Layer_type', 'Confidence', 'Description', 'Corrected_layer_type']
        new_chinese_headers = ['TGèƒŒæ™¯å€¼', 'å¼‚å¸¸å€æ•°', 'æ·±åº¦è¶‹åŠ¿', 'å±‚å‹', 'å¯ä¿¡åº¦', 'æè¿°', 'è¿ç»­æ€§æ ¡æ­£åå±‚å‹']
        
        # 4. åˆå¹¶è¡¨å¤´ï¼ˆåŸå§‹è¡¨å¤´ + æ–°å¢è¡¨å¤´ï¼‰
        full_english_headers = clean_english_headers + new_english_headers
        full_chinese_headers = clean_chinese_headers + new_chinese_headers
        
        logger.info(f"æœ€ç»ˆè¡¨å¤´é•¿åº¦ - è‹±æ–‡: {len(full_english_headers)}, ä¸­æ–‡: {len(full_chinese_headers)}, æ•°æ®åˆ—: {len(df.columns)}")
        
        # 5. æ„å»ºæœ€ç»ˆçš„DataFrame
        # åˆ›å»ºè¡¨å¤´è¡Œï¼ˆä¿æŒåŸå§‹æ ¼å¼ï¼šç¬¬ä¸€è¡Œè‹±æ–‡ï¼Œç¬¬äºŒè¡Œä¸­æ–‡ï¼‰
        row1_data = [full_english_headers[i] if i < len(full_english_headers) else '' for i in range(len(df.columns))]
        row2_data = [full_chinese_headers[i] if i < len(full_chinese_headers) else '' for i in range(len(df.columns))]
        
        # åˆ›å»ºå®Œæ•´çš„DataFrameï¼ŒåŒ…å«è¡¨å¤´å’Œæ•°æ®
        all_data = []
        all_data.append(row1_data)  # ç¬¬ä¸€è¡Œï¼šè‹±æ–‡è¡¨å¤´
        all_data.append(row2_data)  # ç¬¬äºŒè¡Œï¼šä¸­æ–‡è¡¨å¤´
        
        # æ·»åŠ æ‰€æœ‰æ•°æ®è¡Œï¼ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²é¿å…ç±»å‹é—®é¢˜ï¼‰
        for _, row in df.iterrows():
            all_data.append([str(val) if not pd.isna(val) else '' for val in row])
        
        # æ„å»ºæœ€ç»ˆDataFrame
        final_df = pd.DataFrame(all_data)
        logger.info(f"æœ€ç»ˆDataFrameå½¢çŠ¶: {final_df.shape}")
        
        if is_interpreted:
            # å·²è§£é‡Šæ–‡ä»¶ï¼Œä¿æŒåŸæ–‡ä»¶åå’Œè·¯å¾„
            output_path = file_path
            logger.info("æ£€æµ‹åˆ°å·²è§£é‡Šæ–‡ä»¶ï¼Œå°†åœ¨åŸæ–‡ä»¶åŸºç¡€ä¸Šæ›´æ–°")
            
            # ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ°Excelæ–‡ä»¶
            with pd.ExcelWriter(output_path, engine='openpyxl') as excel_writer:
                final_df.to_excel(excel_writer, sheet_name='Sheet1', index=False, header=False)
        else:
            # åŸå§‹æ–‡ä»¶ï¼Œç”Ÿæˆæ–°çš„è§£é‡Šæ–‡ä»¶ï¼Œä½¿ç”¨file_manageræ¥ä¿å­˜
            original_filename = Path(file_path).name
            # å»æ‰åŸå§‹æ–‡ä»¶çš„IDå‰ç¼€ï¼Œåªä¿ç•™å®é™…æ–‡ä»¶å
            clean_filename = remove_file_id_prefix(original_filename)
            # å»æ‰æ‰©å±•ååæ·»åŠ _interpreted
            stem = Path(clean_filename).stem
            new_filename = f"{stem}_interpreted.xlsx"
            logger.info(f"æ£€æµ‹åˆ°åŸå§‹æ–‡ä»¶ï¼Œå°†ç”Ÿæˆæ–°çš„è§£é‡Šæ–‡ä»¶: {new_filename}")
            
            # å…ˆå°†DataFrameä¿å­˜åˆ°å­—èŠ‚æµ
            import io
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as excel_writer:
                final_df.to_excel(excel_writer, sheet_name='Sheet1', index=False, header=False)
            excel_data = excel_buffer.getvalue()
            
            # ä½¿ç”¨file_managerä¿å­˜æ–‡ä»¶
            file_id = file_manager.save_file(
                file_data=excel_data,
                file_name=new_filename,
                file_type="xlsx",
                source="generated"
            )
            
            # è·å–ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
            file_info = file_manager.get_file_info(file_id)
            output_path = file_info.get("file_path")
        logger.info(f"å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return df, output_path,file_id
        
    except Exception as e:
        logger.error(f"å¤„ç†Excelæ–‡ä»¶å¤±è´¥: {e}")
        raise

@register_tool(category="gas_logging")
def tg_layer_evaluation(file_id: str) -> str:
    """æ°”æµ‹å½•äº•åˆ†æçš„ç¬¬ä¸€æ­¥-å…¨çƒƒTGè¯„ä»·æ²¹æ°”æ°´å±‚å·¥å…·
    
    åŸºäºå…¨çƒƒå«é‡ï¼ˆTGï¼‰è¿›è¡Œæ²¹æ°”æ°´å±‚ç»¼åˆè¯„ä»·ï¼Œè€ƒè™‘ï¼š
    1. TGç»å¯¹å€¼å¤§å°
    2. ç›¸å¯¹äºèƒŒæ™¯å€¼çš„å¼‚å¸¸å€æ•°
    3. éšæ·±åº¦çš„å˜åŒ–è¶‹åŠ¿  
    4. å¼‚å¸¸çš„è¿ç»­æ€§å’Œåšåº¦
    
    è¯„ä»·æ ‡å‡†ï¼š
    - æ°´å±‚ï¼šTG < 2%ï¼Œå¼‚å¸¸å€æ•° < 2å€ï¼Œå¹³ç¨³æ— å¼‚å¸¸
    - å¼±æ˜¾ç¤ºå±‚ï¼šTG 2-5%ï¼Œå¼‚å¸¸å€æ•° 2-3å€ï¼Œè½»å¾®å¼‚å¸¸
    - æ²¹å±‚ï¼šTG 5-15%ï¼Œå¼‚å¸¸å€æ•° 3-8å€ï¼ŒæŒç»­å¼‚å¸¸
    - æ°”å±‚ï¼šTG 15-30%ï¼Œå¼‚å¸¸å€æ•° 8-20å€ï¼Œæ˜¾è‘—å¼‚å¸¸
    - å¼ºæ°”å±‚ï¼šTG > 30%ï¼Œå¼‚å¸¸å€æ•° > 20å€ï¼Œæå¼ºå¼‚å¸¸
    
    Args:
        file_id: Excelæ–‡ä»¶IDï¼Œå¯ä»¥æ˜¯åŸå§‹ä¸Šä¼ æ–‡ä»¶æˆ–å‰ä¸€å·¥å…·ç”Ÿæˆçš„è§£é‡Šæ–‡ä»¶ã€‚
                å¦‚æœæ˜¯åœ¨å…¶ä»–å½•äº•å·¥å…·ä¹‹åæ‰§è¡Œï¼Œåº”ä½¿ç”¨å‰ä¸€å·¥å…·è¿”å›ä¿¡æ¯ä¸­çš„NEXT_FILE_IDï¼Œ
                ä»¥åœ¨å·²æœ‰è§£é‡Šç»“æœåŸºç¡€ä¸Šè¿½åŠ æ–°çš„åˆ†æåˆ—ã€‚
                æ–‡ä»¶åº”åŒ…å«Wellã€Depthã€Tgç­‰åˆ—ã€‚
        
    Returns:
        åˆ†æç»“æœæŠ¥å‘Šï¼ŒåŒ…å«æ–°ç”Ÿæˆæ–‡ä»¶çš„NEXT_FILE_IDä¾›åç»­å·¥å…·ä½¿ç”¨
    """
    writer = get_stream_writer()
    
    try:
        if writer:
            writer({"custom_step": "å¼€å§‹TGæ²¹æ°”æ°´å±‚è¯„ä»·åˆ†æ..."})
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = file_manager.get_file_info(file_id)
        if not file_info:
            error_msg = f"æ‰¾ä¸åˆ°IDä¸º {file_id} çš„æ–‡ä»¶"
            logger.error(error_msg)
            return error_msg
        
        file_path = file_info.get("file_path")
        file_name = file_info.get("file_name", "")
        
        if writer:
            writer({"custom_step": f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_name}"})
        
        # å¤„ç†Excelæ–‡ä»¶
        df, output_excel_path,new_file_id = process_tg_excel_file(file_path)
        
        if writer:
            writer({"custom_step": f"æˆåŠŸå¤„ç†{len(df)}è¡Œæ•°æ®ï¼Œå®ŒæˆTGè¯„ä»·åˆ†æ"})
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        # å»æ‰æ–‡ä»¶åä¸­çš„IDå‰ç¼€ï¼Œç”Ÿæˆæ¸…æ´çš„å›¾ç‰‡æ–‡ä»¶å
        clean_filename = remove_file_id_prefix(file_name)
        base_name = Path(clean_filename).stem
        # ä½¿ç”¨æ›´ç›´è§‚çš„æ–‡ä»¶å
        image_filename = f"TGå…¨çƒƒç»¼åˆè§£é‡Šå›¾è¡¨_{base_name}.png"
        
        # ä¸´æ—¶è·¯å¾„ç”¨äºç”Ÿæˆå›¾ç‰‡
        temp_image_path = os.path.join(file_manager.temp_path, f"temp_{image_filename}")
        chart_path = create_tg_evaluation_visualization(df, temp_image_path)
        
        # å¦‚æœå›¾ç‰‡ç”ŸæˆæˆåŠŸï¼Œä½¿ç”¨file_managerä¿å­˜
        if chart_path and os.path.exists(chart_path):
            # è¯»å–å›¾ç‰‡æ•°æ®
            with open(chart_path, 'rb') as f:
                image_data = f.read()
            
            # ä½¿ç”¨file_managerä¿å­˜å›¾ç‰‡
            image_file_id = file_manager.save_file(
                file_data=image_data,
                file_name=image_filename,
                file_type="png",
                source="generated"
            )
            
            # è·å–ä¿å­˜åçš„å›¾ç‰‡è·¯å¾„
            image_file_info = file_manager.get_file_info(image_file_id)
            final_image_path = image_file_info.get("file_path")
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_image_path)
            except:
                pass
        else:
            final_image_path = None
        
        # ç»Ÿè®¡åˆ†æç»“æœ
        total_samples = len(df)
        
        # ç»Ÿè®¡å„å±‚å‹çš„æ ·å“æ•°é‡ï¼ˆä½¿ç”¨æ ¡æ­£åçš„ç»“æœï¼‰
        layer_stats = df['è¿ç»­æ€§æ ¡æ­£åå±‚å‹'].value_counts()
        
        # è®¡ç®—åšåº¦ç»Ÿè®¡
        depth_range = df['Depth'].max() - df['Depth'].min()
        
        if writer:
            writer({"custom_step": f"ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨: {image_filename}"})
        
        # æ¨é€å›¾ç‰‡åˆ°UI
        if final_image_path and os.path.exists(final_image_path):
            image_message = {
                "image_path": final_image_path,
                "title": "TGå…¨çƒƒç»¼åˆè§£é‡Šå›¾è¡¨"
            }
            if writer:
                writer({"image_message": image_message})
        
        # æ¨é€Excelæ–‡ä»¶åˆ°UI
        file_message = {
            "file_path": output_excel_path,
            "file_name": Path(output_excel_path).name,
            "file_type": "xlsx"
        }
        if writer:
            writer({"file_message": file_message})
        
        # ç”Ÿæˆç®€æ´çš„æ‰§è¡Œç»“æœä¿¡æ¯
        depth_range_str = f"{df['Depth'].min():.1f}-{df['Depth'].max():.1f}m"
        
        if len(layer_stats) > 0:
            main_layer = layer_stats.index[0]
            main_percentage = (layer_stats.iloc[0] / total_samples) * 100
            layer_summary = f"ä¸»è¦å±‚å‹ï¼š{main_layer}({main_percentage:.1f}%)"
        else:
            layer_summary = "æ— æœ‰æ•ˆåˆ†ç±»ç»“æœ"
        
        # ç»Ÿè®¡æ²¹æ°”å±‚æ¯”ä¾‹
        oil_gas_count = layer_stats.get('æ²¹å±‚', 0) + layer_stats.get('æ°”å±‚', 0) + layer_stats.get('å¼ºæ°”å±‚', 0)
        oil_gas_percentage = (oil_gas_count / total_samples) * 100 if total_samples > 0 else 0
        
        result_message = f"""âœ… TGæ²¹æ°”æ°´å±‚è¯„ä»·å®Œæˆ
ğŸ†” **NEXT_FILE_ID: {new_file_id}** (åç»­å·¥å…·è¯·ä½¿ç”¨æ­¤file_id)
ğŸ“ åˆ†æäº•æ®µ: {depth_range_str} ({total_samples}ä¸ªæ ·å“)
ğŸ¯ {layer_summary}
â›½ æ²¹æ°”å±‚æ¯”ä¾‹: {oil_gas_percentage:.1f}%
ğŸ“ è§£é‡Šç»“æœæ–‡ä»¶: {Path(output_excel_path).name}
ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨: {image_filename}

âš ï¸ é‡è¦: åç»­å·¥å…·å¿…é¡»ä½¿ç”¨file_id: {new_file_id} ä»¥åœ¨æ­¤ç»“æœåŸºç¡€ä¸Šè¿½åŠ åˆ†æ"""
        
        if writer:
            writer({"custom_step": result_message})
        
        logger.info("TGæ²¹æ°”æ°´å±‚è¯„ä»·åˆ†æå®Œæˆ")
        return result_message
        
    except Exception as e:
        error_msg = f"TGè¯„ä»·åˆ†æå¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        
        if writer:
            writer({"custom_step": f"âŒ {error_msg}"})
        
        return error_msg