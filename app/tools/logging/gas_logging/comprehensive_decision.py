#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç»¼åˆåˆ†æåˆ¤å®šå·¥å…·ï¼ˆæ°”æµ‹å½•äº•ï¼‰

èåˆå…¨çƒƒTGã€ä¸‰è§’å›¾ç‰ˆæ³•ã€3Hæ¯”å€¼æ³•ä¸‰ç±»è§£é‡Šç»“æœï¼Œå¯¹æ¯ä¸ªæ·±åº¦æ ·å“ç»™å‡ºç»¼åˆå±‚å‹ä¸ç»¼åˆç½®ä¿¡åº¦ï¼Œ
å¹¶å°†ç»“æœä»¥è¿½åŠ åˆ—çš„æ–¹å¼å†™å›ç°æœ‰è§£é‡Šæ–‡ä»¶ï¼Œä¿æŒåŸå§‹ä¸¤è¡Œè¡¨å¤´æ ¼å¼ã€‚åŒæ—¶ç”Ÿæˆç»¼åˆå¯è§†åŒ–å›¾è¡¨ã€‚
"""

import os
import re
import platform
from io import BytesIO
from pathlib import Path
from typing import Dict, Tuple

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import logging

from langgraph.config import get_stream_writer
from app.tools.registry import register_tool
from app.core.file_manager import file_manager

logger = logging.getLogger(__name__)


def setup_chinese_font() -> None:
    try:
        if platform.system() == 'Windows':
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
        elif platform.system() == 'Darwin':
            plt.rcParams['font.sans-serif'] = ['Hei', 'Arial Unicode MS']
        else:
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei']
        plt.rcParams['axes.unicode_minus'] = False
    except Exception as e:
        logger.warning(f"è®¾ç½®ä¸­æ–‡å­—ä½“å¤±è´¥: {e}")


def is_interpreted_file(filename: str) -> bool:
    return "interpreted" in filename.lower() or "è§£é‡Š" in filename


def remove_file_id_prefix(filename: str) -> str:
    pattern = r'^[a-z]-[a-z0-9]+_'
    return re.sub(pattern, '', filename)


def _map_tg_layer(layer: str) -> str:
    if not isinstance(layer, str):
        return "æ— æ•ˆæ•°æ®"
    layer = layer.strip()
    mapping = {
        "æ°´å±‚": "æ°´å±‚",
        "å¼±æ˜¾ç¤ºå±‚": "å¼±æ˜¾ç¤ºå±‚",
        "æ²¹å±‚": "æ²¹å±‚",
        "æ°”å±‚": "æ°”å±‚",
        "å¼ºæ°”å±‚": "å¼ºæ°”å±‚",
        "æ— æ•ˆæ•°æ®": "æ— æ•ˆæ•°æ®",
    }
    return mapping.get(layer, layer)


def _map_tri_nature(nature: str) -> Dict[str, float]:
    """å°†ä¸‰è§’å›¾ç‰ˆæ³•çš„å«æ²¹æ°”æ€§è´¨æ˜ å°„ä¸ºç±»åˆ«å¾—åˆ†åˆ†é…ã€‚è¿”å›ç±»åˆ«->æƒé‡çš„å­—å…¸ã€‚"""
    if not isinstance(nature, str):
        return {}
    nature = nature.strip()
    if nature == "æ°´æˆ–æ°”å±‚":
        return {"æ°´å±‚": 0.5, "æ°”å±‚": 0.5}
    if nature == "æ²¹æ°”å±‚æˆ–å«æ²¹æ°´å±‚":
        return {"æ²¹å±‚": 0.5, "æ°”å±‚": 0.3, "æ°´å±‚": 0.2}
    if "æ²¹å±‚" in nature:
        return {"æ²¹å±‚": 1.0}
    if "è½¬åŒ–å¸¦" in nature:
        return {"è¿‡æ¸¡å±‚": 1.0}
    return {}


def _map_3h_result(res: str) -> str:
    if not isinstance(res, str):
        return "æ— æ•ˆæ•°æ®"
    res = res.strip()
    if res in ["å¹²å±‚", "ç–‘ä¼¼å¹²å±‚"]:
        return "å¹²å±‚"
    if res in ["å¹²æ°”å±‚", "æ¹¿æ°”å±‚", "å‡ææ°”å±‚"]:
        return "æ°”å±‚"
    if res in ["æ²¹å±‚", "è½»è´¨æ²¹å±‚"]:
        return "æ²¹å±‚"
    if res == "è¿‡æ¸¡å±‚":
        return "è¿‡æ¸¡å±‚"
    return "æ— æ•ˆæ•°æ®"


def _tg_conf_to_num(conf: str) -> float:
    if not isinstance(conf, str):
        return 0.6
    conf = conf.strip()
    if conf == "é«˜":
        return 0.9
    if conf == "ä¸­":
        return 0.75
    if conf == "ä½":
        return 0.6
    return 0.6


def _decide_row(tg_layer: str, tg_conf_str: str, tri_nature: str, res_3h: str, res_3h_conf: float,
                weights: Tuple[float, float, float] = (0.5, 0.2, 0.3)) -> Tuple[str, float, str]:
    wt_tg, wt_tri, wt_3h = weights
    scores: Dict[str, float] = {k: 0.0 for k in ["æ°´å±‚", "å¼±æ˜¾ç¤ºå±‚", "æ²¹å±‚", "æ°”å±‚", "å¼ºæ°”å±‚", "å¹²å±‚", "è¿‡æ¸¡å±‚", "æ— æ•ˆæ•°æ®"]}

    # TG æŠ•ç¥¨
    tg_cat = _map_tg_layer(tg_layer)
    tg_conf = _tg_conf_to_num(tg_conf_str)
    if tg_cat in scores:
        scores[tg_cat] += wt_tg * tg_conf

    # ä¸‰è§’å›¾æŠ•ç¥¨ï¼ˆåˆ†é…ï¼‰
    tri_dist = _map_tri_nature(tri_nature)
    if tri_dist:
        for cat, frac in tri_dist.items():
            if cat in scores:
                scores[cat] += wt_tri * 0.6 * frac  # ä¸‰è§’å›¾åŸºçº¿ç½®ä¿¡åº¦0.6

    # 3H æŠ•ç¥¨
    h3_cat = _map_3h_result(res_3h)
    h3_conf = float(res_3h_conf) / 100.0 if pd.notna(res_3h_conf) else 0.7
    if h3_cat in scores:
        scores[h3_cat] += wt_3h * max(0.5, min(1.0, h3_conf))

    # å†³ç­–
    # åˆå¹¶åŒç±»ï¼šå°†â€œæ— æ•ˆæ•°æ®â€ä»…åœ¨å…¶ä»–å…¨ä¸º0æ—¶ç”Ÿæ•ˆ
    best_cat = max((k for k in scores if k != "æ— æ•ˆæ•°æ®"), key=lambda k: scores[k])
    best_score = scores[best_cat]
    total_w = wt_tg + wt_tri + wt_3h
    base_conf = (best_score / total_w) if total_w > 0 else 0

    # å†²çªæƒ©ç½šï¼šæ¬¡ä¼˜æ¥è¿‘åˆ™é™ä½ç½®ä¿¡åº¦
    sorted_scores = sorted([(k, v) for k, v in scores.items() if k != "æ— æ•ˆæ•°æ®"], key=lambda x: x[1], reverse=True)
    if len(sorted_scores) > 1:
        gap = sorted_scores[0][1] - sorted_scores[1][1]
        if gap < 0.05:
            base_conf *= 0.85
        elif gap < 0.10:
            base_conf *= 0.9

    final_conf_pct = float(np.clip(round(base_conf * 100, 1), 0, 100))

    # å†³ç­–ä¾æ®æ‘˜è¦
    reason_parts = []
    if isinstance(tg_layer, str) and tg_layer:
        reason_parts.append(f"TG={tg_layer}({tg_conf_str or 'ä¸­'})")
    if isinstance(tri_nature, str) and tri_nature:
        reason_parts.append(f"ä¸‰è§’å›¾={tri_nature}")
    if isinstance(res_3h, str) and res_3h:
        reason_parts.append(f"3H={res_3h}({int(round(h3_conf*100))}%)")
    reason = "; ".join(reason_parts)

    return best_cat, final_conf_pct, reason


def _create_visualization(df: pd.DataFrame, output_path: str) -> str:
    try:
        setup_chinese_font()
        plt.clf(); plt.close('all')

        plt.rcParams['figure.facecolor'] = 'white'
        plt.rcParams['axes.facecolor'] = 'white'
        plt.rcParams['text.color'] = 'black'
        plt.rcParams['axes.labelcolor'] = 'black'
        plt.rcParams['xtick.color'] = 'black'
        plt.rcParams['ytick.color'] = 'black'

        fig = plt.figure(figsize=(16, 10), facecolor='white')
        fig.suptitle('ç»¼åˆè§£é‡Šç»“æœ', fontsize=16, fontweight='bold', color='black')

        # å›¾1ï¼šç»¼åˆå±‚å‹æ·±åº¦å‰–é¢
        ax1 = plt.subplot(2, 2, 1)
        ax1.set_facecolor('white')
        depths = pd.to_numeric(df['Depth'], errors='coerce')
        final_layers = df['ç»¼åˆå±‚å‹']
        color_map = {"æ°´å±‚": '#87CEEB', "å¼±æ˜¾ç¤ºå±‚": '#FFE4B5', "æ²¹å±‚": '#90EE90', "æ°”å±‚": '#FFA07A',
                     "å¼ºæ°”å±‚": '#FF6347', "å¹²å±‚": '#D3D3D3', "è¿‡æ¸¡å±‚": '#DDA0DD', "æ— æ•ˆæ•°æ®": '#696969'}
        try:
            for cat, color in color_map.items():
                m = (final_layers == cat) & pd.notna(depths)
                if m.any():
                    ax1.scatter(np.full(m.sum(), 1), depths[m], s=8, c=color, label=cat, alpha=0.8, edgecolors='black', linewidths=0.2)
            ax1.invert_yaxis()
            ax1.set_xlim(0.5, 1.5)
            ax1.set_xticks([])
            ax1.set_ylabel('æ·±åº¦ (m)', fontsize=12)
            ax1.set_title('ç»¼åˆå±‚å‹æ·±åº¦å‰–é¢', fontsize=14, fontweight='bold')
            ax1.grid(True, alpha=0.2)
            ax1.legend(fontsize=8, loc='center left', bbox_to_anchor=(1.02, 0.5))
        except Exception as e:
            logger.error(f"ç»˜åˆ¶å›¾1å¤±è´¥: {e}")
            ax1.text(0.5, 0.5, f'å›¾1å¤±è´¥: {str(e)}', transform=ax1.transAxes, ha='center', va='center', fontsize=12, color='red')

        # å›¾2ï¼šç»¼åˆå±‚å‹åˆ†å¸ƒé¥¼å›¾
        ax2 = plt.subplot(2, 2, 2)
        ax2.set_facecolor('white')
        try:
            dist = final_layers.value_counts()
            if len(dist) > 0:
                pie_colors = [color_map.get(k, '#CCCCCC') for k in dist.index]
                total = dist.sum()
                def autopct(p):
                    return f'{p:.1f}%' if p >= 1 else ''
                wedges, texts, autotexts = ax2.pie(dist.values, labels=[k if (v/total*100) >= 2 else '' for k, v in dist.items()],
                                                   autopct=autopct, colors=pie_colors, startangle=45,
                                                   labeldistance=1.15, pctdistance=0.85,
                                                   wedgeprops=dict(edgecolor='white', linewidth=1))
                for t in texts: t.set_color('black'); t.set_fontsize(9)
                for at in autotexts: at.set_color('black'); at.set_fontsize(8); at.set_weight('bold')
                ax2.set_title('ç»¼åˆå±‚å‹åˆ†å¸ƒ', fontsize=14, fontweight='bold', color='black')
            else:
                ax2.text(0.5, 0.5, 'æ— æ•°æ®', transform=ax2.transAxes, ha='center', va='center', fontsize=14, color='red')
        except Exception as e:
            logger.error(f"ç»˜åˆ¶å›¾2å¤±è´¥: {e}")
            ax2.text(0.5, 0.5, f'å›¾2å¤±è´¥: {str(e)}', transform=ax2.transAxes, ha='center', va='center', fontsize=12, color='red')

        # å›¾3ï¼šæ–¹æ³•ä¸€è‡´æ€§ç»Ÿè®¡ï¼ˆä¸ç»¼åˆç»“æœä¸€è‡´çš„æ¯”ä¾‹ï¼‰
        ax3 = plt.subplot(2, 1, 2)
        ax3.set_facecolor('white')
        try:
            final_cat = df['ç»¼åˆå±‚å‹']
            # TGä¸€è‡´ï¼šä½¿ç”¨è¿ç»­æ€§æ ¡æ­£åå±‚å‹
            tg_cat = df.get('è¿ç»­æ€§æ ¡æ­£åå±‚å‹', df.get('å±‚å‹'))
            tri_nature = df.get('å«æ²¹æ°”æ€§è´¨')
            h3_res = df.get('3Hè§£é‡Šç»“æœ')

            def tri_to_simple(s):
                d = _map_tri_nature(s or '')
                if not d:
                    return None
                # å–æƒé‡æœ€å¤§è€…
                return max(d.items(), key=lambda x: x[1])[0]

            agree_tg = (tg_cat == final_cat).mean() if tg_cat is not None else 0.0
            tri_simple = tri_nature.apply(tri_to_simple) if tri_nature is not None else None
            agree_tri = (tri_simple == final_cat).mean() if tri_simple is not None else 0.0
            agree_h3 = (_map_series(h3_res, _map_3h_result) == final_cat).mean() if h3_res is not None else 0.0

            methods = ['TG', 'ä¸‰è§’å›¾', '3H']
            rates = [agree_tg*100, agree_tri*100, agree_h3*100]
            bars = ax3.bar(methods, rates, color=['#1f77b4','#ff7f0e','#2ca02c'], edgecolor='black')
            for b, r in zip(bars, rates):
                ax3.text(b.get_x()+b.get_width()/2, b.get_height()+1, f"{r:.1f}%", ha='center', va='bottom', fontsize=10, color='black')
            ax3.set_ylim(0, 100)
            ax3.set_ylabel('ä¸€è‡´ç‡ (%)', fontsize=12)
            ax3.set_title('æ–¹æ³•ä¸ç»¼åˆç»“æœä¸€è‡´ç‡', fontsize=14, fontweight='bold', color='black')
            ax3.grid(axis='y', alpha=0.3)
        except Exception as e:
            logger.error(f"ç»˜åˆ¶å›¾3å¤±è´¥: {e}")
            ax3.text(0.5, 0.5, f'å›¾3å¤±è´¥: {str(e)}', transform=ax3.transAxes, ha='center', va='center', fontsize=12, color='red')

        plt.tight_layout(rect=[0, 0.02, 1, 0.95])
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none', format='png', transparent=False)
        plt.close('all')
        return output_path
    except Exception as e:
        logger.error(f"åˆ›å»ºå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
        plt.close('all')
        return ""


def _map_series(series: pd.Series, fn) -> pd.Series:
    return series.apply(lambda x: fn(x) if pd.notna(x) else x)


@register_tool(category="gas_logging")
def comprehensive_layer_decision(file_id: str) -> str:
    """æ°”æµ‹å½•äº•ç»¼åˆåˆ†æåˆ¤å®šå·¥å…·

    èåˆå…¨çƒƒTGã€ä¸‰è§’å›¾ç‰ˆæ³•ã€3Hæ¯”å€¼æ³•çš„è§£é‡Šç»“æœï¼Œç”Ÿæˆæ¯è¡Œæ ·å“çš„ç»¼åˆå±‚å‹ä¸ç»¼åˆç½®ä¿¡åº¦ï¼Œ
    å¹¶åœ¨åŸæœ‰ï¼ˆæˆ–å·²è§£é‡Šï¼‰æ–‡ä»¶åŸºç¡€ä¸Šè¿½åŠ åˆ—ä¿å­˜ã€‚è¿”å›ç®€è¦ç»“æœå¹¶æ¨é€å›¾ç‰‡ä¸æ–‡ä»¶ã€‚

    ä½¿ç”¨è¯´æ˜ï¼š
    - è¾“å…¥åº”ä¸ºå‰åºå·¥å…·ç”Ÿæˆçš„è§£é‡Šæ–‡ä»¶IDï¼ˆNEXT_FILE_IDï¼‰ã€‚
    - æœ¬å·¥å…·ä¼šåœ¨æ–‡ä»¶å°¾éƒ¨è¿½åŠ åˆ—ï¼šFinal_layer/ç»¼åˆå±‚å‹ã€Final_confidence/ç»¼åˆç½®ä¿¡åº¦ã€Final_reason/ç»¼åˆåˆ¤æ®ã€‚
    - ç»“æœå›¾ç‰‡å°†ä»¥â€œç»¼åˆè§£é‡Šç»“æœ_æ–‡ä»¶å.pngâ€å½¢å¼ç”Ÿæˆå¹¶æ¨é€ã€‚
    """
    writer = get_stream_writer()
    try:
        if writer:
            writer({"custom_step": "å¼€å§‹ç»¼åˆåˆ†æåˆ¤å®š..."})

        file_info = file_manager.get_file_info(file_id)
        if not file_info:
            return f"æ‰¾ä¸åˆ°IDä¸º {file_id} çš„æ–‡ä»¶"

        file_path = file_info.get("file_path")
        file_name = file_info.get("file_name", "")
        if writer:
            writer({"custom_step": f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_name}"})

        # è¯»å–è¡¨å¤´åˆ¤æ–­è·³è¡Œ
        header_df = pd.read_excel(file_path, nrows=2)
        first_row = header_df.iloc[0].tolist()
        second_row = header_df.iloc[1].tolist() if len(header_df) > 1 else []

        chinese_headers = ['äº•å', 'äº•æ·±', 'é’»æ—¶', 'å…¨é‡', 'ç”²çƒ·', 'ä¹™çƒ·', 'ä¸™çƒ·', 'å¼‚ä¸çƒ·', 'æ­£ä¸çƒ·', 'å¼‚æˆŠçƒ·', 'æ­£æˆŠçƒ·', 'äºŒæ°§åŒ–ç¢³', 'å…¶å®ƒéçƒƒ']
        is_chinese_header = any(str(c) in chinese_headers for c in first_row if not pd.isna(c))
        second_is_data = len(second_row) > 0 and sum(1 for cell in second_row if isinstance(cell, (int, float)) and not pd.isna(cell)) > len(second_row)/2
        skip_rows = 1 if (is_chinese_header and second_is_data) else 2

        data_df = pd.read_excel(file_path, skiprows=skip_rows)

        # åˆ—åæ˜ å°„
        chinese_to_english = {
            'äº•å': 'Well', 'äº•æ·±': 'Depth', 'é’»æ—¶': 'Rop', 'å…¨é‡': 'Tg',
            'ç”²çƒ·': 'C1', 'ä¹™çƒ·': 'C2', 'ä¸™çƒ·': 'C3', 'å¼‚ä¸çƒ·': 'iC4', 'æ­£ä¸çƒ·': 'nC4',
            'å¼‚æˆŠçƒ·': 'iC5', 'æ­£æˆŠçƒ·': 'nC5', 'äºŒæ°§åŒ–ç¢³': 'CO2', 'å…¶å®ƒéçƒƒ': 'Other'
        }
        is_chinese_header_for_columns = any(str(cell) in chinese_to_english for cell in first_row if not pd.isna(cell))

        if is_chinese_header_for_columns:
            english_headers = []
            chinese_headers_list = []
            for i, cell in enumerate(first_row):
                if pd.isna(cell) or str(cell).strip() == '':
                    english_headers.append(f"Col{i}")
                    chinese_headers_list.append(f"åˆ—{i}")
                else:
                    cell_str = str(cell).strip()
                    if cell_str in chinese_to_english:
                        english_headers.append(chinese_to_english[cell_str])
                        chinese_headers_list.append(cell_str)
                    else:
                        english_headers.append(cell_str)
                        chinese_headers_list.append(cell_str)
            if len(english_headers) >= len(data_df.columns):
                data_df.columns = english_headers[:len(data_df.columns)]
            else:
                data_df.columns = english_headers + [f"Col{i}" for i in range(len(english_headers), len(data_df.columns))]
            original_english_headers = list(data_df.columns)
            original_chinese_headers = chinese_headers_list[:len(data_df.columns)]
        else:
            original_english_headers = list(data_df.columns)
            # å°è¯•ä»ç¬¬äºŒè¡Œä½œä¸ºä¸­æ–‡æ ‡é¢˜
            original_chinese_headers = second_row[:len(data_df.columns)] if second_row else [""]*len(data_df.columns)

        # è®¡ç®—ç»¼åˆåˆ¤å®š
        tg_layer_series = data_df.get('è¿ç»­æ€§æ ¡æ­£åå±‚å‹', data_df.get('å±‚å‹'))
        tg_conf_series = data_df.get('å¯ä¿¡åº¦')  # TGå·¥å…·ä¸­çš„å¯ä¿¡åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰
        tri_nature_series = data_df.get('å«æ²¹æ°”æ€§è´¨')
        h3_res_series = data_df.get('3Hè§£é‡Šç»“æœ')
        h3_conf_series = data_df.get('ç½®ä¿¡åº¦')  # 3Hä¸­çš„æ•°å€¼ç½®ä¿¡åº¦

        # ç¼ºåˆ—å…¼å®¹
        if tg_layer_series is None: tg_layer_series = pd.Series([np.nan]*len(data_df))
        if tg_conf_series is None: tg_conf_series = pd.Series([np.nan]*len(data_df))
        if tri_nature_series is None: tri_nature_series = pd.Series([np.nan]*len(data_df))
        if h3_res_series is None: h3_res_series = pd.Series([np.nan]*len(data_df))
        if h3_conf_series is None: h3_conf_series = pd.Series([70]*len(data_df))

        finals = []
        confs = []
        reasons = []
        for i in range(len(data_df)):
            final_cat, final_conf, reason = _decide_row(
                tg_layer=str(tg_layer_series.iloc[i]) if pd.notna(tg_layer_series.iloc[i]) else '',
                tg_conf_str=str(tg_conf_series.iloc[i]) if pd.notna(tg_conf_series.iloc[i]) else 'ä¸­',
                tri_nature=str(tri_nature_series.iloc[i]) if pd.notna(tri_nature_series.iloc[i]) else '',
                res_3h=str(h3_res_series.iloc[i]) if pd.notna(h3_res_series.iloc[i]) else '',
                res_3h_conf=float(h3_conf_series.iloc[i]) if pd.notna(h3_conf_series.iloc[i]) else 70.0,
            )
            finals.append(final_cat)
            confs.append(final_conf)
            reasons.append(reason)

        data_df['ç»¼åˆå±‚å‹'] = finals
        data_df['ç»¼åˆç½®ä¿¡åº¦'] = confs
        data_df['ç»¼åˆåˆ¤æ®'] = reasons

        # é‡å»ºä¸¤è¡Œè¡¨å¤´
        original_data_columns = len(original_english_headers)
        clean_en = original_english_headers[:original_data_columns]
        clean_zh = original_chinese_headers[:original_data_columns]
        while len(clean_en) < original_data_columns: clean_en.append(f"Col{len(clean_en)+1}")
        while len(clean_zh) < original_data_columns: clean_zh.append(f"åˆ—{len(clean_zh)+1}")

        new_en = ['Final_layer', 'Final_confidence', 'Final_reason']
        new_zh = ['ç»¼åˆå±‚å‹', 'ç»¼åˆç½®ä¿¡åº¦', 'ç»¼åˆåˆ¤æ®']

        full_en = clean_en + new_en
        full_zh = clean_zh + new_zh

        row1 = [full_en[i] if i < len(full_en) else '' for i in range(len(data_df.columns))]
        row2 = [full_zh[i] if i < len(full_zh) else '' for i in range(len(data_df.columns))]

        all_data = [row1, row2]
        for _, r in data_df.iterrows():
            all_data.append([str(v) if not pd.isna(v) else '' for v in r])
        final_df = pd.DataFrame(all_data)

        # ä¿å­˜Excel
        if is_interpreted_file(file_name):
            output_excel_path = file_path
            with pd.ExcelWriter(output_excel_path, engine='openpyxl') as excel_writer:
                final_df.to_excel(excel_writer, sheet_name='Sheet1', index=False, header=False)
            new_file_id = file_id
        else:
            base_name = remove_file_id_prefix(file_name)
            if base_name.endswith('.xls'):
                base_name = base_name[:-4] + '.xlsx'
            elif base_name.endswith('.xlsx'):
                base_name = base_name[:-5] + '.xlsx'
            if not base_name.endswith('_interpreted.xlsx'):
                new_filename = base_name[:-5] + '_interpreted.xlsx' if base_name.endswith('.xlsx') else base_name + '_interpreted.xlsx'
            else:
                new_filename = base_name
            excel_buffer = BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as excel_writer:
                final_df.to_excel(excel_writer, sheet_name='Sheet1', index=False, header=False)
            excel_data = excel_buffer.getvalue()
            new_file_id = file_manager.save_file(
                file_data=excel_data,
                file_name=new_filename,
                file_type="xlsx",
                source="generated",
            )
            new_file_info = file_manager.get_file_info(new_file_id)
            output_excel_path = new_file_info.get("file_path")

        if writer:
            writer({"custom_step": f"ç»¼åˆç»“æœå·²å†™å…¥: {Path(output_excel_path).name}"})

        # ç”Ÿæˆå¯è§†åŒ–
        base_name = remove_file_id_prefix(Path(file_name).name)
        base_stem = Path(base_name).stem
        image_filename = f"ç»¼åˆè§£é‡Šç»“æœ_{base_stem}.png"
        temp_image_path = os.path.join(file_manager.temp_path, f"temp_{image_filename}")
        chart_path = _create_visualization(data_df, temp_image_path)

        final_image_path = None
        if chart_path and os.path.exists(chart_path):
            with open(chart_path, 'rb') as f:
                image_data = f.read()
            image_file_id = file_manager.save_file(
                file_data=image_data,
                file_name=image_filename,
                file_type="png",
                source="generated",
            )
            image_info = file_manager.get_file_info(image_file_id)
            final_image_path = image_info.get("file_path")
            try:
                os.remove(temp_image_path)
            except Exception:
                pass

        # æ¨é€å›¾ç‰‡ä¸æ–‡ä»¶
        if writer and final_image_path and os.path.exists(final_image_path):
            writer({"image_message": {"image_path": final_image_path, "title": "ç»¼åˆè§£é‡Šç»“æœå›¾è¡¨"}})

        if writer:
            writer({"file_message": {"file_path": output_excel_path, "file_name": Path(output_excel_path).name, "file_type": "xlsx"}})

        # ç»“æœæ‘˜è¦
        total = len(data_df)
        dist = data_df['ç»¼åˆå±‚å‹'].value_counts()
        main_cat = dist.index[0] if len(dist) else 'æ— '
        main_pct = (dist.iloc[0] / total * 100) if len(dist) else 0

        result_message = f"""âœ… ç»¼åˆåˆ†æåˆ¤å®šå®Œæˆ
ğŸ†” **NEXT_FILE_ID: {new_file_id}** (åç»­å·¥å…·è¯·ä½¿ç”¨æ­¤file_id)
ğŸ“ æ ·å“æ•°: {total}
ğŸ¯ ä¸»å¯¼å±‚å‹: {main_cat}({main_pct:.1f}%)
ğŸ“ ç»“æœæ–‡ä»¶: {Path(output_excel_path).name}
ğŸ“ˆ å›¾è¡¨: {image_filename}

âš ï¸ é‡è¦: åç»­å·¥å…·å¿…é¡»ä½¿ç”¨file_id: {new_file_id} ä»¥åœ¨æ­¤ç»“æœåŸºç¡€ä¸Šç»§ç»­åˆ†æ"""

        if writer:
            writer({"custom_step": result_message})

        return result_message

    except Exception as e:
        logger.error("ç»¼åˆåˆ†æåˆ¤å®šå¤±è´¥", exc_info=True)
        if writer:
            writer({"custom_step": f"âŒ ç»¼åˆåˆ†æåˆ¤å®šå¤±è´¥: {str(e)}"})
        return f"ç»¼åˆåˆ†æåˆ¤å®šå¤±è´¥: {str(e)}"


