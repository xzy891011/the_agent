"""
å¢å¼ºç‰ˆå›¾æ„å»ºå™¨ - é˜¶æ®µ1ï¼šä»»åŠ¡-å­å›¾æ¡†æ¶

å®ç°åˆ†å±‚æ™ºèƒ½ä½“æ¶æ„ï¼š
1. Meta-Supervisorï¼ˆå…ƒç›‘ç£è€…ï¼‰ï¼šè´Ÿè´£ä»»åŠ¡åˆ†è§£å’Œé«˜å±‚å†³ç­–
2. Task-Plannerï¼ˆä»»åŠ¡è§„åˆ’å™¨ï¼‰ï¼šè´Ÿè´£å…·ä½“ä»»åŠ¡è§„åˆ’
3. Runtime-Supervisorï¼ˆè¿è¡Œæ—¶ç›‘ç£è€…ï¼‰ï¼šè´Ÿè´£æ‰§è¡Œè¿‡ç¨‹ç›‘æ§
4. Domain-Expert-Subgraphï¼ˆé¢†åŸŸä¸“å®¶å­å›¾ï¼‰ï¼šä¸“é—¨çš„é¢†åŸŸå¤„ç†å­å›¾
"""

import logging
import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Callable, Union, Literal, Set, Tuple
from enum import Enum
import uuid

from langchain_core.language_models import BaseChatModel
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph.message import add_messages
from langgraph.constants import Send
from langgraph.types import Command

from app.core.state import IsotopeSystemState, StateManager, TaskStatus
from app.core.config import ConfigManager
from app.core.postgres_checkpoint import get_postgres_checkpoint_manager, PostgreSQLCheckpointManager
from app.core.task_decorator import task_registry, get_task_by_name, apply_langgraph_decorator
from app.core.critic_node import create_critic_node, CriticResult

logger = logging.getLogger(__name__)

class TaskType(str, Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    CONSULTATION = "consultation"  # å’¨è¯¢ç±»ä»»åŠ¡
    DATA_ANALYSIS = "data_analysis"  # æ•°æ®åˆ†æä»»åŠ¡
    EXPERT_ANALYSIS = "expert_analysis"  # ä¸“å®¶åˆ†æä»»åŠ¡
    MULTI_STEP = "multi_step"  # å¤šæ­¥éª¤å¤åˆä»»åŠ¡
    TOOL_EXECUTION = "tool_execution"  # å·¥å…·æ‰§è¡Œä»»åŠ¡

class TaskPriority(str, Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§æšä¸¾"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    URGENT = "urgent"

class SubgraphType(str, Enum):
    """å­å›¾ç±»å‹æšä¸¾"""
    DATA_PROCESSING = "data_processing"  # æ•°æ®å¤„ç†å­å›¾
    ISOTOPE_ANALYSIS = "isotope_analysis"  # åŒä½ç´ åˆ†æå­å›¾
    VISUALIZATION = "visualization"  # å¯è§†åŒ–å­å›¾
    REPORT_GENERATION = "report_generation"  # æŠ¥å‘Šç”Ÿæˆå­å›¾

class TaskPlan:
    """ä»»åŠ¡è®¡åˆ’ç±»"""
    
    def __init__(
        self,
        task_id: str,
        task_type: TaskType,
        description: str,
        priority: TaskPriority = TaskPriority.MEDIUM,
        steps: Optional[List[Dict[str, Any]]] = None,
        subgraphs: Optional[List[SubgraphType]] = None,
        estimated_duration: Optional[int] = None,
        dependencies: Optional[List[str]] = None
    ):
        self.task_id = task_id
        self.task_type = task_type
        self.description = description
        self.priority = priority
        self.steps = steps or []
        self.subgraphs = subgraphs or []
        self.estimated_duration = estimated_duration
        self.dependencies = dependencies or []
        self.created_at = datetime.now()
        self.status = TaskStatus.NOT_STARTED
        self.current_step = 0
        
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "task_id": self.task_id,
            "task_type": self.task_type.value,
            "description": self.description,
            "priority": self.priority.value,
            "steps": self.steps,
            "subgraphs": [sg.value for sg in self.subgraphs],
            "estimated_duration": self.estimated_duration,
            "dependencies": self.dependencies,
            "created_at": self.created_at.isoformat(),
            "status": self.status.value,
            "current_step": self.current_step
        }

class MetaSupervisor:
    """å…ƒç›‘ç£è€… - è´Ÿè´£èº«ä»½æ ¡éªŒã€éœ€æ±‚åˆ†æå’Œå¼‚å¸¸å…œåº•"""
    
    def __init__(self, llm: BaseChatModel, config: Optional[Dict[str, Any]] = None):
        self.llm = llm
        self.config = config or {}
        # è·å–ç³»ç»Ÿèƒ½åŠ›
        from app.core.system_capability_registry import get_system_capabilities, system_capability_registry
        self.system_capabilities = get_system_capabilities()
        self.capability_registry = system_capability_registry
    
    def analyze_user_request(self, state: IsotopeSystemState) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œç¡®å®šä»»åŠ¡ç±»å‹å’Œæ‰§è¡Œç­–ç•¥"""
        logger.info("MetaSupervisorå¼€å§‹åˆ†æç”¨æˆ·è¯·æ±‚")
        
        # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        last_human_msg = StateManager.get_last_human_message(state)
        if not last_human_msg:
            return self._fallback_analysis("æ— ç”¨æˆ·è¾“å…¥")
        
        user_input = last_human_msg.content
        
        # å¿«é€Ÿè¯†åˆ«ç®€å•èº«ä»½ç¡®è®¤é—®é¢˜
        simple_identity_keywords = ["ä½ æ˜¯è°", "ä½ å¥½", "ä»‹ç»ä¸€ä¸‹", "ä»€ä¹ˆæ˜¯", "ç³»ç»Ÿ", "èº«ä»½", "åŠŸèƒ½"]
        user_lower = user_input.lower()
        
        # å¦‚æœæ˜¯ç®€å•çš„èº«ä»½ç¡®è®¤æˆ–é—®å€™ï¼Œç›´æ¥æ ‡è®°ä¸ºconsultation
        if any(keyword in user_lower for keyword in simple_identity_keywords) and len(user_input) < 20:
            logger.info(f"è¯†åˆ«ä¸ºç®€å•èº«ä»½ç¡®è®¤é—®é¢˜: {user_input}")
            return {
                "task_type": TaskType.CONSULTATION,
                "complexity": "simple",
                "confidence": 0.95,
                "required_capabilities": [],
                "need_human_interaction": False,
                "reasoning": "ç®€å•èº«ä»½ç¡®è®¤é—®é¢˜ï¼Œæ— éœ€å¤æ‚å¤„ç†"
            }
        
        # æœç´¢ç›¸å…³èƒ½åŠ›
        from app.core.system_capability_registry import search_capabilities
        relevant_capabilities = search_capabilities(user_input)
        
        # æ„å»ºåˆ†ææç¤ºè¯
        capability_info = "\n".join([
            f"- {cap.name}: {cap.description}" 
            for cap in relevant_capabilities[:5]  # é™åˆ¶æ˜¾ç¤ºå‰5ä¸ªæœ€ç›¸å…³çš„
        ])
        
        prompt = f"""
        åˆ†æç”¨æˆ·è¯·æ±‚å¹¶ç¡®å®šä»»åŠ¡ç±»å‹å’Œæ‰€éœ€èƒ½åŠ›ã€‚
        
        ç”¨æˆ·è¯·æ±‚: {user_input}
        
        ç³»ç»Ÿå½“å‰å¯ç”¨çš„ç›¸å…³èƒ½åŠ›:
        {capability_info}
        
        ç³»ç»Ÿèƒ½åŠ›æ‘˜è¦:
        - æ€»èƒ½åŠ›æ•°: {len(self.system_capabilities)}
        - å·¥å…·æ•°: {len([c for c in self.system_capabilities.values() if c.metadata.get('is_tool')])}
        - ä»»åŠ¡æ•°: {len([c for c in self.system_capabilities.values() if c.type.value == 'task'])}
        
        è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼:
        {{
            "task_type": "consultation/data_analysis/expert_analysis/multi_step/tool_execution",
            "confidence": 0.0-1.0,
            "required_capabilities": ["èƒ½åŠ›1", "èƒ½åŠ›2"],
            "complexity": "simple/medium/complex",
            "need_human_interaction": true/false,
            "reasoning": "åˆ†æç†ç”±"
        }}
        """
        
        try:
            response = self.llm.invoke(prompt)
            content = response.content if hasattr(response, 'content') else str(response)
            
            # è§£æJSON
            import json
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group())
                
                # éªŒè¯æ‰€éœ€èƒ½åŠ›æ˜¯å¦çœŸå®å­˜åœ¨
                validated_capabilities = []
                for cap_name in analysis.get("required_capabilities", []):
                    if self.capability_registry.get_capability(cap_name):
                        validated_capabilities.append(cap_name)
                    else:
                        # å°è¯•æ¨¡ç³ŠåŒ¹é…
                        matches = search_capabilities(cap_name)
                        if matches:
                            validated_capabilities.append(matches[0].name)
                
                analysis["required_capabilities"] = validated_capabilities
                analysis["available_capabilities"] = [cap.name for cap in relevant_capabilities]
                
                return analysis
            else:
                logger.warning("MetaSupervisoræ— æ³•è§£æLLMå“åº”ä¸ºJSON")
                return self._fallback_analysis(user_input)
        
        except Exception as e:
            logger.error(f"MetaSupervisoråˆ†æå¤±è´¥: {str(e)}")
            return self._fallback_analysis(user_input)
    
    def _fallback_analysis(self, user_input: str) -> Dict[str, Any]:
        """å›é€€åˆ†ææ–¹æ³•"""
        # åŸºäºå…³é”®è¯çš„ç®€å•åˆ†æ
        data_keywords = ["æ•°æ®", "åˆ†æ", "å›¾è¡¨", "å¯è§†åŒ–", "æ–‡ä»¶"]
        expert_keywords = ["åŒä½ç´ ", "ç¢³", "æ°”ä½“", "æˆç†Ÿåº¦", "æ¥æº"]
        tool_keywords = ["ç”Ÿæˆ", "è®¡ç®—", "å¤„ç†", "è½¬æ¢"]
        
        user_lower = user_input.lower()
        
        if any(keyword in user_lower for keyword in expert_keywords):
            return {
                "task_type": TaskType.EXPERT_ANALYSIS,
                "complexity": "medium",
                "reasoning": "åŒ…å«ä¸“ä¸šé¢†åŸŸå…³é”®è¯",
                "requires_tools": ["isotope_analysis"],
                "estimated_steps": 3
            }
        elif any(keyword in user_lower for keyword in data_keywords):
            return {
                "task_type": TaskType.DATA_ANALYSIS,
                "complexity": "medium",
                "reasoning": "åŒ…å«æ•°æ®åˆ†æå…³é”®è¯",
                "requires_tools": ["data_processing"],
                "estimated_steps": 2
            }
        elif any(keyword in user_lower for keyword in tool_keywords):
            return {
                "task_type": TaskType.TOOL_EXECUTION,
                "complexity": "low",
                "reasoning": "åŒ…å«å·¥å…·æ‰§è¡Œå…³é”®è¯",
                "requires_tools": ["general"],
                "estimated_steps": 1
            }
        else:
            return {
                "task_type": TaskType.CONSULTATION,
                "complexity": "low",
                "reasoning": "ç®€å•å’¨è¯¢é—®é¢˜",
                "requires_tools": [],
                "estimated_steps": 1
            }
    
    def decide_execution_strategy(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®åˆ†æç»“æœå†³å®šæ‰§è¡Œç­–ç•¥"""
        # å®‰å…¨è§£æä»»åŠ¡ç±»å‹ï¼Œå¤„ç†LLMå¯èƒ½è¿”å›çš„å¤åˆå€¼
        task_type_str = analysis.get("task_type", "consultation")
        
        # å¦‚æœLLMè¿”å›äº†å¤åˆç±»å‹ï¼Œå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„ç±»å‹
        if "/" in task_type_str:
            task_type_str = task_type_str.split("/")[0]
        
        # æ˜ å°„åˆ°æœ‰æ•ˆçš„TaskTypeæšä¸¾å€¼
        task_type_mapping = {
            "consultation": TaskType.CONSULTATION,
            "data_analysis": TaskType.DATA_ANALYSIS,
            "expert_analysis": TaskType.EXPERT_ANALYSIS,
            "multi_step": TaskType.MULTI_STEP,
            "tool_execution": TaskType.TOOL_EXECUTION
        }
        
        task_type = task_type_mapping.get(task_type_str.lower(), TaskType.CONSULTATION)
        complexity = analysis.get("complexity", "low")
        
        strategy = {
            "use_task_planner": complexity in ["medium", "high"],
            "use_subgraphs": task_type in [TaskType.DATA_ANALYSIS, TaskType.EXPERT_ANALYSIS, TaskType.MULTI_STEP],
            "requires_human_approval": complexity == "high",
            "parallel_execution": len(analysis.get("requires_tools", [])) > 1,
            "monitoring_level": "high" if complexity == "high" else "medium"
        }
        
        logger.info(f"Meta-Supervisorå†³ç­–: {strategy}")
        return strategy

class TaskPlanner:
    """ä»»åŠ¡è§„åˆ’å™¨ - å°†ç”¨æˆ·éœ€æ±‚æ‹†è§£ä¸ºå¯æ‰§è¡Œçš„DAGå­å›¾"""
    
    def __init__(self, llm: BaseChatModel, config: Optional[Dict[str, Any]] = None):
        self.llm = llm
        self.config = config or {}
        # è·å–ç³»ç»Ÿèƒ½åŠ›å’Œä»»åŠ¡æ³¨å†Œè¡¨
        from app.core.system_capability_registry import get_system_capabilities, system_capability_registry
        from app.core.task_decorator import task_registry
        self.system_capabilities = get_system_capabilities()
        self.capability_registry = system_capability_registry
        self.task_registry = task_registry
    
    def create_task_plan(
        self, 
        analysis: Dict[str, Any], 
        strategy: Dict[str, Any],
        state: IsotopeSystemState
    ) -> TaskPlan:
        """åŸºäºåˆ†æç»“æœåˆ›å»ºä»»åŠ¡æ‰§è¡Œè®¡åˆ’"""
        logger.info("TaskPlannerå¼€å§‹åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®¡åˆ’")
        
        task_type = analysis.get("task_type", "consultation")
        task_id = f"task_{datetime.now().strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:8]}"
        
        # è·å–æ‰€éœ€èƒ½åŠ›çš„è¯¦ç»†ä¿¡æ¯
        required_capabilities = []
        for cap_name in analysis.get("required_capabilities", []):
            cap = self.capability_registry.get_capability(cap_name)
            if cap:
                required_capabilities.append(cap)
        
        # åŸºäºä»»åŠ¡ç±»å‹å’Œå¯ç”¨èƒ½åŠ›åˆ›å»ºè®¡åˆ’
        if task_type == "consultation":
            return self._create_consultation_plan(task_id, analysis, state)
        elif task_type == "data_analysis":
            return self._create_data_analysis_plan(task_id, analysis, state, required_capabilities)
        elif task_type == "expert_analysis":
            return self._create_expert_analysis_plan(task_id, analysis, state, required_capabilities)
        elif task_type == "multi_step":
            return self._create_multi_step_plan(task_id, analysis, state, required_capabilities)
        elif task_type == "tool_execution":
            return self._create_tool_execution_plan(task_id, analysis, state, required_capabilities)
        else:
            return self._create_default_plan(task_id, analysis, state)
    
    def _create_consultation_plan(self, task_id: str, analysis: Dict[str, Any], state: IsotopeSystemState) -> TaskPlan:
        """åˆ›å»ºå’¨è¯¢ç±»ä»»åŠ¡è®¡åˆ’"""
        steps = [
            {
                "step_id": 1,
                "name": "ç†è§£é—®é¢˜",
                "description": "åˆ†æç”¨æˆ·é—®é¢˜å¹¶æä¾›å›ç­”",
                "agent": "supervisor",
                "tools": [],
                "expected_output": "ç›´æ¥å›ç­”"
            }
        ]
        
        return TaskPlan(
            task_id=task_id,
            task_type=TaskType.CONSULTATION,
            description=analysis.get("reasoning", "å’¨è¯¢ç±»ä»»åŠ¡"),
            priority=TaskPriority.MEDIUM,
            steps=steps,
            estimated_duration=30  # 30ç§’
        )
    
    def _create_data_analysis_plan(self, task_id: str, analysis: Dict[str, Any], state: IsotopeSystemState, required_capabilities: List[Any]) -> TaskPlan:
        """åˆ›å»ºæ•°æ®åˆ†æä»»åŠ¡è®¡åˆ’"""
        steps = [
            {
                "step_id": 1,
                "name": "æ•°æ®é¢„å¤„ç†",
                "description": "æ£€æŸ¥å’Œé¢„å¤„ç†ä¸Šä¼ çš„æ•°æ®æ–‡ä»¶",
                "agent": "data_agent",
                "tools": ["preview_file_content", "search_documents_rag"],
                "expected_output": "æ•°æ®æ¦‚è§ˆ"
            },
            {
                "step_id": 2,
                "name": "æ•°æ®åˆ†æ",
                "description": "æ‰§è¡Œå…·ä½“çš„æ•°æ®åˆ†æä»»åŠ¡",
                "agent": "expert_agent",
                "tools": ["enhanced_analyze_isotope_depth_trends"],
                "expected_output": "åˆ†æç»“æœ"
            }
        ]
        
        # ç¡®å®šéœ€è¦çš„å­å›¾ç±»å‹
        subgraphs = [
            SubgraphType.DATA_PROCESSING,
            SubgraphType.ISOTOPE_ANALYSIS,
            SubgraphType.VISUALIZATION
        ]
        
        # ä¸ºæ¯ä¸ªæ­¥éª¤åˆ†é…å­å›¾
        for i, step in enumerate(steps):
            if "æ•°æ®é¢„å¤„ç†" in step.get("description", ""):
                step["subgraph"] = SubgraphType.DATA_PROCESSING.value
            elif "æ•°æ®åˆ†æ" in step.get("description", ""):
                step["subgraph"] = SubgraphType.ISOTOPE_ANALYSIS.value
            else:
                step["subgraph"] = SubgraphType.DATA_PROCESSING.value
        
        return TaskPlan(
            task_id=task_id,
            task_type=TaskType.DATA_ANALYSIS,
            description=analysis.get("reasoning", "æ•°æ®åˆ†æä»»åŠ¡"),
            priority=TaskPriority.MEDIUM,
            steps=steps,
            subgraphs=subgraphs,
            estimated_duration=300  # 5åˆ†é’Ÿ
        )
    
    def _create_expert_analysis_plan(self, task_id: str, analysis: Dict[str, Any], state: IsotopeSystemState, required_capabilities: List[Any]) -> TaskPlan:
        """åˆ›å»ºä¸“å®¶åˆ†æä»»åŠ¡è®¡åˆ’"""
        steps = [
            {
                "step_id": 1,
                "name": "ä¸“ä¸šåˆ†æ",
                "description": "ä½¿ç”¨ä¸“ä¸šå·¥å…·è¿›è¡ŒåŒä½ç´ åˆ†æ",
                "agent": "expert_agent",
                "tools": ["enhanced_classify_gas_source", "enhanced_analyze_gas_maturity"],
                "expected_output": "ä¸“ä¸šåˆ†æç»“æœ"
            },
            {
                "step_id": 2,
                "name": "ç»“æœå¯è§†åŒ–",
                "description": "ç”Ÿæˆåˆ†æå›¾è¡¨å’Œå¯è§†åŒ–",
                "agent": "expert_agent",
                "tools": ["enhanced_plot_bernard_diagram", "enhanced_plot_whiticar_diagram"],
                "expected_output": "å¯è§†åŒ–å›¾è¡¨"
            },
            {
                "step_id": 3,
                "name": "æŠ¥å‘Šç”Ÿæˆ",
                "description": "ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š",
                "agent": "expert_agent",
                "tools": ["generate_isotope_report"],
                "expected_output": "åˆ†ææŠ¥å‘Š"
            }
        ]
        
        return TaskPlan(
            task_id=task_id,
            task_type=TaskType.EXPERT_ANALYSIS,
            description=analysis.get("reasoning", "ä¸“å®¶åˆ†æä»»åŠ¡"),
            priority=TaskPriority.HIGH,
            steps=steps,
            subgraphs=[SubgraphType.ISOTOPE_ANALYSIS, SubgraphType.VISUALIZATION, SubgraphType.REPORT_GENERATION],
            estimated_duration=600  # 10åˆ†é’Ÿ
        )
    
    def _create_multi_step_plan(self, task_id: str, analysis: Dict[str, Any], state: IsotopeSystemState, required_capabilities: List[Any]) -> TaskPlan:
        """åˆ›å»ºå¤šæ­¥éª¤ä»»åŠ¡è®¡åˆ’"""
        # è¿™é‡Œå¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚å®ç°æ›´å¤æ‚çš„å¤šæ­¥éª¤è§„åˆ’
        return self._create_expert_analysis_plan(task_id, analysis, state, required_capabilities)
    
    def _create_tool_execution_plan(self, task_id: str, analysis: Dict[str, Any], state: IsotopeSystemState, required_capabilities: List[Any]) -> TaskPlan:
        """åˆ›å»ºå·¥å…·æ‰§è¡Œä»»åŠ¡è®¡åˆ’"""
        steps = [
            {
                "step_id": 1,
                "name": "å·¥å…·æ‰§è¡Œ",
                "description": "æ‰§è¡ŒæŒ‡å®šçš„å·¥å…·",
                "agent": "supervisor",
                "tools": required_capabilities,
                "expected_output": "å·¥å…·æ‰§è¡Œç»“æœ"
            }
        ]
        
        return TaskPlan(
            task_id=task_id,
            task_type=TaskType.TOOL_EXECUTION,
            description=analysis.get("reasoning", "å·¥å…·æ‰§è¡Œä»»åŠ¡"),
            priority=TaskPriority.MEDIUM,
            steps=steps,
            estimated_duration=120  # 2åˆ†é’Ÿ
        )
    
    def _create_default_plan(self, task_id: str, analysis: Dict[str, Any], state: IsotopeSystemState) -> TaskPlan:
        """åˆ›å»ºé»˜è®¤ä»»åŠ¡è®¡åˆ’"""
        return self._create_consultation_plan(task_id, analysis, state)

class RuntimeSupervisor:
    """è¿è¡Œæ—¶ç›‘ç£è€… - è´Ÿè´£æ‰§è¡Œè¿‡ç¨‹ç›‘æ§"""
    
    def __init__(self, llm: BaseChatModel, config: Optional[Dict[str, Any]] = None):
        self.llm = llm
        self.config = config or {}
        self.execution_history = []
    
    def monitor_execution(self, state: IsotopeSystemState, current_step: Dict[str, Any]) -> Dict[str, Any]:
        """ç›‘æ§å½“å‰æ‰§è¡Œæ­¥éª¤"""
        logger.info(f"Runtime-Supervisor: ç›‘æ§æ‰§è¡Œæ­¥éª¤ {current_step.get('step_id')}")
        
        monitoring_result = {
            "step_status": "in_progress",
            "issues_detected": [],
            "recommendations": [],
            "should_continue": True,
            "requires_intervention": False
        }
        
        # æ£€æŸ¥æ‰§è¡Œæ—¶é—´
        step_start_time = current_step.get("start_time")
        if step_start_time:
            elapsed_time = time.time() - step_start_time
            expected_duration = current_step.get("expected_duration", 60)
            
            if elapsed_time > expected_duration * 1.5:
                monitoring_result["issues_detected"].append("æ‰§è¡Œæ—¶é—´è¶…å‡ºé¢„æœŸ")
                monitoring_result["recommendations"].append("è€ƒè™‘ä¼˜åŒ–æˆ–ä¸­æ–­å½“å‰æ­¥éª¤")
        
        # æ£€æŸ¥é”™è¯¯å†å²
        recent_errors = [action for action in state.get("action_history", []) 
                        if action.get("status") == "error"]
        
        if len(recent_errors) > 2:
            monitoring_result["issues_detected"].append("é¢‘ç¹å‡ºç°é”™è¯¯")
            monitoring_result["requires_intervention"] = True
        
        return monitoring_result
    
    def decide_next_action(self, state: IsotopeSystemState, task_plan: TaskPlan) -> str:
        """å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        current_step = task_plan.current_step
        
        if current_step >= len(task_plan.steps):
            return "complete"
        
        next_step = task_plan.steps[current_step]
        agent_type = next_step.get("agent", "supervisor")
        
        # æ ¹æ®æ™ºèƒ½ä½“ç±»å‹å†³å®šè·¯ç”±
        if agent_type == "data_agent":
            return "data_processing_subgraph"
        elif agent_type == "expert_agent":
            return "expert_analysis_subgraph"
        else:
            return "supervisor"

class EnhancedGraphBuilder:
    """å¢å¼ºç‰ˆå›¾æ„å»ºå™¨ - é˜¶æ®µ2ç‰ˆæœ¬
    
    æ–°å¢åŠŸèƒ½ï¼š
    1. MySQL checkpointé›†æˆ
    2. @taskæ”¯æŒå’Œç®¡ç†
    3. å¤±è´¥èŠ‚ç‚¹é‡æ’­
    4. å­å›¾çº§åˆ«æ£€æŸ¥ç‚¹
    5. Taskçº§åˆ«çš„é”™è¯¯æ¢å¤
    """
    
    def __init__(
        self,
        agents: Optional[Dict[str, Any]] = None,
        config: Optional[Union[ConfigManager, Dict[str, Any]]] = None,  # ä¿®æ”¹ç±»å‹æç¤ºï¼Œæ”¯æŒå­—å…¸å’ŒConfigManager
        enable_postgres_checkpoint: bool = True,
        enable_mysql_checkpoint: bool = False,  # æ–°å¢MySQLé€‰é¡¹
        checkpoint_backend: str = "postgres",  # é»˜è®¤ä½¿ç”¨postgresï¼Œå¯é€‰ "mysql", "postgres", "memory"
        enable_task_support: bool = True,
        # é˜¶æ®µ1å…¼å®¹å‚æ•°
        llm: Optional[BaseChatModel] = None,
        supervisor_agent: Optional[Any] = None,
        specialized_agents: Optional[Dict[str, Any]] = None,  # æ–°å¢ä¸“ä¸šæ™ºèƒ½ä½“å‚æ•°
        checkpointer: Optional[Any] = None
    ):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆå›¾æ„å»ºå™¨
        
        Args:
            agents: æ™ºèƒ½ä½“å­—å…¸ {agent_name: agent_instance}
            config: é…ç½®ç®¡ç†å™¨å®ä¾‹æˆ–é…ç½®å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºé»˜è®¤å®ä¾‹
            enable_postgres_checkpoint: æ˜¯å¦å¯ç”¨PostgreSQLæ£€æŸ¥ç‚¹ï¼ˆå‘åå…¼å®¹ï¼‰
            enable_mysql_checkpoint: æ˜¯å¦å¯ç”¨MySQLæ£€æŸ¥ç‚¹
            checkpoint_backend: æ£€æŸ¥ç‚¹åç«¯ç±»å‹ ("postgres", "mysql", "memory")
            enable_task_support: æ˜¯å¦å¯ç”¨Taskæ”¯æŒ
            # ä»¥ä¸‹ä¸ºé˜¶æ®µ1å…¼å®¹å‚æ•°ï¼Œä¼šé€æ­¥åºŸå¼ƒ
            llm: LLMå®ä¾‹ï¼ˆå…¼å®¹ï¼‰
            supervisor_agent: ç›‘ç£è€…æ™ºèƒ½ä½“ï¼ˆå…¼å®¹ï¼‰
            data_agent: æ•°æ®æ™ºèƒ½ä½“ï¼ˆå…¼å®¹ï¼‰
            expert_agent: ä¸“å®¶æ™ºèƒ½ä½“ï¼ˆå…¼å®¹ï¼‰
            checkpointer: æ£€æŸ¥ç‚¹å™¨ï¼ˆå…¼å®¹ï¼‰
        """
        # å…¼å®¹é˜¶æ®µ1å‚æ•°ï¼šå¦‚æœä¼ å…¥äº†llmç­‰å‚æ•°ï¼Œæ„å»ºagentså­—å…¸
        if llm and (supervisor_agent or specialized_agents):
            self.agents = {
                "llm": llm,
                "supervisor_agent": supervisor_agent,
            }
            # æ·»åŠ ä¸“ä¸šæ™ºèƒ½ä½“åˆ°agentså­—å…¸
            if specialized_agents:
                self.agents.update(specialized_agents)
            
            # åˆ›å»ºé˜¶æ®µ1éœ€è¦çš„ç»„ä»¶
            self.llm = llm
            # å®‰å…¨åœ°è·å–é…ç½®
            config_dict = self._safe_get_config(config)
            self.meta_supervisor = MetaSupervisor(llm, config_dict)
            self.task_planner = TaskPlanner(llm, config_dict)
            self.runtime_supervisor = RuntimeSupervisor(llm, config_dict)
            
            logger.info("ä½¿ç”¨é˜¶æ®µ1å…¼å®¹æ¨¡å¼åˆå§‹åŒ–å¢å¼ºç‰ˆå›¾æ„å»ºå™¨ï¼ˆä¸“ä¸šæ™ºèƒ½ä½“æ¶æ„ï¼‰")
        else:
            # é˜¶æ®µ2æ¨¡å¼
            self.agents = agents or {}
            # å³ä½¿åœ¨é˜¶æ®µ2æ¨¡å¼ï¼Œä¹Ÿå°è¯•è·å–æˆ–åˆ›å»ºLLMé…ç½®
            if llm:
                self.llm = llm
            else:
                # å°è¯•åˆ›å»ºé»˜è®¤LLM
                try:
                    from app.utils.qwen_chat import SFChatOpenAI
                    self.llm = SFChatOpenAI(
                        model="Qwen/Qwen2.5-72B-Instruct",
                        temperature=0.1,
                    )
                    logger.info("é˜¶æ®µ2æ¨¡å¼åˆ›å»ºé»˜è®¤LLMæˆåŠŸ")
                except Exception as e:
                    logger.warning(f"é˜¶æ®µ2æ¨¡å¼åˆ›å»ºé»˜è®¤LLMå¤±è´¥: {str(e)}")
                    self.llm = None
                    
            self.meta_supervisor = None
            self.task_planner = None
            self.runtime_supervisor = None
            
            logger.info("ä½¿ç”¨é˜¶æ®µ2æ¨¡å¼åˆå§‹åŒ–å¢å¼ºç‰ˆå›¾æ„å»ºå™¨")
        
        # å¤„ç†é…ç½®å‚æ•°ï¼šç¡®ä¿self.configå§‹ç»ˆæ˜¯ConfigManagerå¯¹è±¡
        if isinstance(config, ConfigManager):
            # å¦‚æœå·²ç»æ˜¯ConfigManagerå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
            self.config = config
        elif isinstance(config, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œåˆ›å»ºConfigManagerå¹¶åˆå¹¶é…ç½®
            self.config = ConfigManager()
            try:
                # åŠ è½½é»˜è®¤é…ç½®
                self.config.load_config()
                # åˆå¹¶ä¼ å…¥çš„é…ç½®å­—å…¸
                for key, value in config.items():
                    self.config.update_config(key, value)
                logger.debug(f"å·²åˆå¹¶å­—å…¸é…ç½®åˆ°ConfigManagerä¸­")
            except Exception as e:
                logger.warning(f"åˆå¹¶é…ç½®å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            # å¦‚æœä¸ºNoneæˆ–å…¶ä»–ç±»å‹ï¼Œåˆ›å»ºé»˜è®¤ConfigManager
            self.config = ConfigManager()
            try:
                self.config.load_config()
                logger.debug("ä½¿ç”¨é»˜è®¤ConfigManageré…ç½®")
            except Exception as e:
                logger.warning(f"åŠ è½½é»˜è®¤é…ç½®å¤±è´¥: {str(e)}")
        
        self.enable_postgres_checkpoint = enable_postgres_checkpoint
        self.enable_mysql_checkpoint = enable_mysql_checkpoint
        self.checkpoint_backend = checkpoint_backend
        self.enable_task_support = enable_task_support
        self.checkpointer = checkpointer  # ä¿å­˜å¤–éƒ¨ä¼ å…¥çš„æ£€æŸ¥ç‚¹å™¨
        
        # æ£€æŸ¥ç‚¹ç®¡ç†å™¨åˆå§‹åŒ– - æ”¯æŒå¤šç§åç«¯
        self.postgres_checkpoint_manager: Optional[PostgreSQLCheckpointManager] = None
        self.mysql_checkpoint_manager: Optional[Any] = None  # å°†åœ¨éœ€è¦æ—¶å¯¼å…¥
        
        # æ ¹æ®é…ç½®ç¡®å®šå®é™…ä½¿ç”¨çš„åç«¯
        actual_backend = self._determine_checkpoint_backend()
        
        if actual_backend == "postgres":
            self._init_postgres_checkpoint()
        elif actual_backend == "mysql":
            self._init_mysql_checkpoint()
        else:
            logger.info("ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å™¨")
        
        # Taskæ³¨å†Œè¡¨
        self.task_registry = task_registry if enable_task_support else None
        
        # åˆå§‹åŒ–ä¸­æ–­ç®¡ç†å™¨
        self.enable_interrupt = self.config.get_config_value("system.enable_interrupt", True)
        self.interrupt_manager = None
        if self.enable_interrupt:
            try:
                from app.core.interrupt_manager import create_default_interrupt_manager
                self.interrupt_manager = create_default_interrupt_manager(self._safe_get_config(config))
                logger.info("ä¸­æ–­ç®¡ç†å™¨å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"åˆå§‹åŒ–ä¸­æ–­ç®¡ç†å™¨å¤±è´¥: {str(e)}")
                self.enable_interrupt = False
        
        logger.info(f"æ£€æŸ¥ç‚¹åç«¯: {actual_backend}, ä¸­æ–­æœºåˆ¶: {'å¯ç”¨' if self.enable_interrupt else 'ç¦ç”¨'}")
    
    def _determine_checkpoint_backend(self) -> str:
        """ç¡®å®šå®é™…ä½¿ç”¨çš„æ£€æŸ¥ç‚¹åç«¯
        
        Returns:
            å®é™…ä½¿ç”¨çš„åç«¯ç±»å‹ ("postgres", "mysql", "memory")
        """
        # å¦‚æœæ˜¾å¼æŒ‡å®šäº†åç«¯
        if self.checkpoint_backend in ["postgres", "mysql", "memory"]:
            return self.checkpoint_backend
        
        # åŸºäºæ—§å‚æ•°çš„å…¼å®¹æ€§æ£€æŸ¥
        if self.enable_postgres_checkpoint:
            return "postgres"
        elif self.enable_mysql_checkpoint:
            return "mysql"
        else:
            return "memory"
    
    def _init_postgres_checkpoint(self):
        """åˆå§‹åŒ–PostgreSQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨"""
        try:
            logger.info("æ­£åœ¨å¯ç”¨PostgreSQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨...")
            self.postgres_checkpoint_manager = get_postgres_checkpoint_manager(self.config)
            
            if self.postgres_checkpoint_manager:
                # æµ‹è¯•è¿æ¥
                postgres_available = self.postgres_checkpoint_manager.test_connection()
                if postgres_available:
                    logger.info("PostgreSQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨è¿æ¥æµ‹è¯•æˆåŠŸ")
                else:
                    logger.warning("PostgreSQLè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œä½†æ£€æŸ¥ç‚¹ç®¡ç†å™¨å·²åˆ›å»º")
            else:
                logger.warning("PostgreSQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨åˆ›å»ºå¤±è´¥")
                self.postgres_checkpoint_manager = None
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–PostgreSQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨å¤±è´¥: {str(e)}")
            self.postgres_checkpoint_manager = None
    
    def _init_mysql_checkpoint(self):
        """åˆå§‹åŒ–MySQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨"""
        try:
            logger.info("æ­£åœ¨å¯ç”¨MySQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨...")
            # åŠ¨æ€å¯¼å…¥MySQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨
            from app.core.mysql_checkpoint import get_mysql_checkpoint_manager
            self.mysql_checkpoint_manager = get_mysql_checkpoint_manager(self.config)
            
            if self.mysql_checkpoint_manager:
                # æµ‹è¯•è¿æ¥
                mysql_available = self.mysql_checkpoint_manager.test_connection()
                if mysql_available:
                    logger.info("MySQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨è¿æ¥æµ‹è¯•æˆåŠŸ")
                else:
                    logger.warning("MySQLè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œä½†æ£€æŸ¥ç‚¹ç®¡ç†å™¨å·²åˆ›å»º")
            else:
                logger.warning("MySQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨åˆ›å»ºå¤±è´¥")
                self.mysql_checkpoint_manager = None
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–MySQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨å¤±è´¥: {str(e)}")
            self.mysql_checkpoint_manager = None
    
    def _safe_get_config(self, config: Any) -> Dict[str, Any]:
        """å®‰å…¨åœ°è·å–é…ç½®å­—å…¸
        
        Args:
            config: é…ç½®å¯¹è±¡æˆ–å­—å…¸
            
        Returns:
            é…ç½®å­—å…¸
        """
        try:
            if config is None:
                return {}
            elif hasattr(config, 'config'):
                # ConfigManagerå¯¹è±¡
                return config.config
            elif isinstance(config, dict):
                # æ™®é€šå­—å…¸
                return config
            else:
                # å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—å…¸
                return dict(config) if config else {}
        except Exception as e:
            logger.warning(f"è·å–é…ç½®å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ç©ºé…ç½®")
            return {}
    
    def build_enhanced_graph(self, session_id: Optional[str] = None) -> StateGraph:
        """æ„å»ºå¢å¼ºç‰ˆå›¾ - é˜¶æ®µ1ç‰ˆæœ¬ï¼Œé›†æˆCriticèŠ‚ç‚¹
        
        é›†æˆPostgreSQL checkpointã€@taskæ”¯æŒå’ŒCriticå®¡æŸ¥èŠ‚ç‚¹
        
        Args:
            session_id: ä¼šè¯IDï¼Œå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ç”Ÿæˆä¸€ä¸ªéšæœºID
            
        Returns:
            å¢å¼ºç‰ˆçŠ¶æ€å›¾
        """
        # å¦‚æœæ²¡æœ‰æä¾›session_idï¼Œç”Ÿæˆä¸€ä¸ªéšæœºID
        if session_id is None:
            import uuid
            session_id = str(uuid.uuid4())
            
        logger.info(f"å¼€å§‹æ„å»ºé˜¶æ®µ1å¢å¼ºç‰ˆå›¾ï¼ˆå«CriticèŠ‚ç‚¹ï¼‰ï¼Œä¼šè¯ID: {session_id}")
        
        try:
            # å¯¼å…¥çŠ¶æ€ç±»å‹
            from app.core.state import IsotopeSystemState
            
            # åˆ›å»ºçŠ¶æ€å›¾ - ä½¿ç”¨æ­£ç¡®çš„çŠ¶æ€ç±»å‹
            graph = StateGraph(IsotopeSystemState)
            
            # åˆ›å»ºMeta-Supervisorå’ŒTaskPlanner
            config_dict = self._safe_get_config(self.config)
            llm_for_components = self.llm or self._get_default_llm()
            meta_supervisor = MetaSupervisor(llm_for_components, config_dict)
            task_planner = TaskPlanner(llm_for_components, config_dict)
            runtime_supervisor = RuntimeSupervisor(llm_for_components, config_dict)
            
            # åˆ›å»ºCriticèŠ‚ç‚¹ï¼ˆç°åœ¨å…·æœ‰å¥å£®çš„RAGå®¡æŸ¥ï¼‰
            llm_for_critic = self.llm or self._get_default_llm()
            critic_node_func = create_critic_node(
                llm_for_critic, 
                config_dict,
                enable_rag_review=True,  # é‡æ–°å¯ç”¨RAGå®¡æŸ¥ï¼Œç°åœ¨æœ‰å¥å£®çš„é”™è¯¯å¤„ç†
                enable_capability_check=True
            )
            
            # åˆ›å»ºæ”¯æŒtaskçš„å¢å¼ºèŠ‚ç‚¹
            enhanced_nodes = self.create_task_enhanced_nodes()
            
            # æ·»åŠ Meta-SupervisorèŠ‚ç‚¹
            def meta_supervisor_node(state: IsotopeSystemState) -> IsotopeSystemState:
                """Meta-SupervisorèŠ‚ç‚¹ï¼šåˆ†æç”¨æˆ·è¯·æ±‚"""
                # æ¨é€èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œä¿¡æ¯
                from app.core.stream_writer_helper import (
                    push_node_start, push_node_complete, push_thinking, push_error
                )
                push_node_start("meta_supervisor", "å¼€å§‹åˆ†æç”¨æˆ·è¯·æ±‚")
                
                logger.info("æ‰§è¡ŒMeta-SupervisorèŠ‚ç‚¹")
                
                try:
                    # æ¨é€æ€è€ƒè¿‡ç¨‹
                    push_thinking("meta_supervisor", "æ­£åœ¨åˆ†æç”¨æˆ·è¯·æ±‚çš„æ„å›¾å’Œå¤æ‚åº¦", "request_analysis")
                    
                    # åˆ†æç”¨æˆ·è¯·æ±‚
                    analysis = meta_supervisor.analyze_user_request(state)
                    
                    # æ¨é€åˆ†æè¿›åº¦
                    push_thinking("meta_supervisor", f"è¯·æ±‚åˆ†æå®Œæˆï¼š{analysis.get('task_type', 'æœªçŸ¥')}ç±»å‹ï¼Œå¤æ‚åº¦{analysis.get('complexity', 'æœªçŸ¥')}", "strategy_planning")
                    
                    # å†³ç­–æ‰§è¡Œç­–ç•¥
                    strategy = meta_supervisor.decide_execution_strategy(analysis)
                    
                    # æ›´æ–°çŠ¶æ€
                    updated_state = state.copy()
                    if "metadata" not in updated_state:
                        updated_state["metadata"] = {}
                    
                    updated_state["metadata"]["task_analysis"] = analysis
                    updated_state["metadata"]["execution_strategy"] = strategy
                    
                    # æ·»åŠ åˆ†ææ¶ˆæ¯
                    from langchain_core.messages import AIMessage
                    analysis_msg = AIMessage(
                        content=f"ğŸ“‹ ä»»åŠ¡åˆ†æå®Œæˆï¼š{analysis.get('task_type', 'æœªçŸ¥')} "
                                f"(å¤æ‚åº¦: {analysis.get('complexity', 'æœªçŸ¥')})"
                    )
                    updated_state = StateManager.update_messages(updated_state, analysis_msg)
                    
                    # æ¨é€èŠ‚ç‚¹å®Œæˆä¿¡æ¯
                    push_node_complete("meta_supervisor", f"ç”¨æˆ·è¯·æ±‚åˆ†æå®Œæˆï¼Œä»»åŠ¡ç±»å‹ï¼š{analysis.get('task_type', 'æœªçŸ¥')}")
                    
                    return updated_state
                    
                except Exception as e:
                    logger.error(f"Meta-Supervisoræ‰§è¡Œå¤±è´¥: {str(e)}")
                    
                    # æ¨é€é”™è¯¯ä¿¡æ¯
                    push_error(f"Meta-Supervisoråˆ†æå¤±è´¥: {str(e)}", "meta_supervisor")
                    
                    error_msg = AIMessage(content=f"âŒ Meta-Supervisoråˆ†æå¤±è´¥: {str(e)}")
                    return StateManager.update_messages(state, error_msg)
            
            # æ·»åŠ Task-PlannerèŠ‚ç‚¹
            def task_planner_node(state: IsotopeSystemState) -> IsotopeSystemState:
                """Task-PlannerèŠ‚ç‚¹ï¼šåˆ›å»ºä»»åŠ¡è®¡åˆ’å¹¶ç”ŸæˆåŠ¨æ€å­å›¾"""
                # æ¨é€èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œä¿¡æ¯
                from app.core.stream_writer_helper import (
                    push_node_start, push_node_complete, push_thinking, push_error, push_progress
                )
                push_node_start("task_planner", "å¼€å§‹åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®¡åˆ’")
                
                logger.info("æ‰§è¡ŒTask-PlannerèŠ‚ç‚¹")
                
                try:
                    # æ¨é€æ€è€ƒè¿‡ç¨‹
                    push_thinking("task_planner", "æ­£åœ¨è·å–åˆ†æç»“æœå¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’", "plan_creation")
                    
                    # è·å–åˆ†æç»“æœ
                    analysis = state.get("metadata", {}).get("task_analysis", {})
                    strategy = state.get("metadata", {}).get("execution_strategy", {})
                    
                    if not analysis:
                        logger.warning("ç¼ºå°‘ä»»åŠ¡åˆ†æç»“æœï¼Œä½¿ç”¨é»˜è®¤åˆ†æ")
                        push_thinking("task_planner", "æœªæ‰¾åˆ°åˆ†æç»“æœï¼Œä½¿ç”¨é»˜è®¤åˆ†æç­–ç•¥", "fallback_planning")
                        analysis = {"task_type": "consultation", "complexity": "low"}
                    
                    # æ¨é€è®¡åˆ’åˆ›å»ºè¿›åº¦
                    push_progress("task_planning", 0.3, f"å¼€å§‹åˆ›å»º{analysis.get('task_type', 'æœªçŸ¥')}ç±»å‹çš„ä»»åŠ¡è®¡åˆ’")
                    
                    # åˆ›å»ºä»»åŠ¡è®¡åˆ’
                    task_plan = task_planner.create_task_plan(analysis, strategy, state)
                    
                    # æ›´æ–°çŠ¶æ€
                    updated_state = state.copy()
                    updated_state["metadata"]["task_plan"] = task_plan.to_dict()
                    
                    # â­ é˜¶æ®µ5æ ¸å¿ƒåŠŸèƒ½ï¼šåŠ¨æ€å­å›¾ç”Ÿæˆ
                    if task_plan.subgraphs:
                        # æ¨é€å­å›¾ç”Ÿæˆå¼€å§‹ä¿¡æ¯
                        subgraph_names = [sg.value for sg in task_plan.subgraphs]
                        push_thinking("task_planner", f"ä»»åŠ¡éœ€è¦ç”Ÿæˆ{len(subgraph_names)}ä¸ªåŠ¨æ€å­å›¾ï¼š{', '.join(subgraph_names)}", "subgraph_generation")
                        push_progress("subgraph_generation", 0.5, f"å¼€å§‹ç”Ÿæˆ{len(subgraph_names)}ä¸ªåŠ¨æ€å­å›¾")
                        
                        logger.info(f"ğŸ”§ TaskPlannerå¼€å§‹ç”ŸæˆåŠ¨æ€å­å›¾ï¼š{subgraph_names}")
                        
                        try:
                            # å¯¼å…¥å­å›¾ç”Ÿæˆå™¨
                            from app.core.subgraph_generator import get_subgraph_generator
                            subgraph_generator = get_subgraph_generator(self._safe_get_config(self.config))
                            
                            # ä¸ºæ¯ä¸ªå­å›¾ç±»å‹ç”Ÿæˆå¯¹åº”çš„åŠ¨æ€å­å›¾
                            generated_subgraphs = {}
                            total_subgraphs = len(task_plan.subgraphs)
                            
                            for i, subgraph_type in enumerate(task_plan.subgraphs):
                                # æ¨é€å½“å‰å­å›¾ç”Ÿæˆè¿›åº¦
                                current_progress = 0.5 + (i / total_subgraphs) * 0.4  # 0.5-0.9ä¹‹é—´
                                push_progress("subgraph_generation", current_progress, f"æ­£åœ¨ç”Ÿæˆå­å›¾: {subgraph_type.value} ({i+1}/{total_subgraphs})")
                                
                                logger.info(f"ğŸ“Š ç”Ÿæˆå­å›¾: {subgraph_type.value}")
                                
                                # ç”ŸæˆåŠ¨æ€å­å›¾
                                subgraph = subgraph_generator.generate_subgraph(
                                    subgraph_type=subgraph_type,
                                    task_plan=task_plan.to_dict(),
                                    context={"state": updated_state, "session_id": session_id}
                                )
                                
                                if subgraph:
                                    # ç¼–è¯‘å­å›¾
                                    compiled_subgraph = subgraph_generator.compile_subgraph(
                                        subgraph=subgraph,
                                        session_id=session_id,
                                        subgraph_name=f"{subgraph_type.value}_subgraph"
                                    )
                                    generated_subgraphs[subgraph_type.value] = compiled_subgraph
                                    logger.info(f"âœ… å­å›¾ {subgraph_type.value} ç”Ÿæˆå¹¶ç¼–è¯‘æˆåŠŸ")
                                    
                                    # æ¨é€å­å›¾å®Œæˆä¿¡æ¯
                                    push_thinking("task_planner", f"å­å›¾ {subgraph_type.value} ç”Ÿæˆå¹¶ç¼–è¯‘æˆåŠŸ", "subgraph_complete")
                                else:
                                    logger.warning(f"âš ï¸ å­å›¾ {subgraph_type.value} ç”Ÿæˆå¤±è´¥")
                                    push_error(f"å­å›¾ {subgraph_type.value} ç”Ÿæˆå¤±è´¥", "task_planner")
                            
                            # å°†ç”Ÿæˆçš„å­å›¾ä¿å­˜åˆ°çŠ¶æ€ä¸­
                            updated_state["metadata"]["generated_subgraphs"] = generated_subgraphs
                            updated_state["metadata"]["subgraph_execution_plan"] = {
                                "subgraphs": list(generated_subgraphs.keys()),
                                "current_subgraph_index": 0,
                                "execution_mode": "sequential"  # é»˜è®¤é¡ºåºæ‰§è¡Œå­å›¾
                            }
                            
                            # æ¨é€æœ€ç»ˆè¿›åº¦
                            push_progress("subgraph_generation", 1.0, f"æ‰€æœ‰å­å›¾ç”Ÿæˆå®Œæˆï¼š{len(generated_subgraphs)}/{total_subgraphs}")
                            
                            # æ·»åŠ æˆåŠŸæ¶ˆæ¯
                            plan_msg = AIMessage(
                                content=f"ğŸ“ ä»»åŠ¡è§„åˆ’å®Œæˆï¼š{task_plan.description}\n"
                                        f"ğŸ”§ åŠ¨æ€å­å›¾å·²ç”Ÿæˆï¼š{len(generated_subgraphs)} ä¸ªå­å›¾\n"
                                        f"ğŸ“Š å­å›¾ç±»å‹ï¼š{', '.join(generated_subgraphs.keys())}"
                            )
                            updated_state = StateManager.update_messages(updated_state, plan_msg)
                            
                        except Exception as subgraph_error:
                            logger.error(f"åŠ¨æ€å­å›¾ç”Ÿæˆå¤±è´¥: {str(subgraph_error)}")
                            
                            # æ¨é€å­å›¾ç”Ÿæˆå¤±è´¥ä¿¡æ¯
                            push_error(f"åŠ¨æ€å­å›¾ç”Ÿæˆå¤±è´¥: {str(subgraph_error)}", "task_planner")
                            push_thinking("task_planner", "å­å›¾ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿå¤„ç†æ¨¡å¼", "fallback_mode")
                            
                            # å­å›¾ç”Ÿæˆå¤±è´¥æ—¶ï¼Œå›é€€åˆ°ä¼ ç»Ÿè·¯ç”±
                            error_msg = AIMessage(
                                content=f"âš ï¸ åŠ¨æ€å­å›¾ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿå¤„ç†æ¨¡å¼: {str(subgraph_error)}"
                            )
                            updated_state = StateManager.update_messages(updated_state, error_msg)
                    else:
                        # æ²¡æœ‰å­å›¾éœ€æ±‚çš„ç®€å•ä»»åŠ¡
                        push_thinking("task_planner", "ä»»åŠ¡æ— éœ€å¤æ‚å­å›¾ï¼Œä½¿ç”¨ç®€å•æ‰§è¡Œè®¡åˆ’", "simple_plan")
                        push_progress("task_planning", 0.8, f"åˆ›å»ºç®€å•ä»»åŠ¡è®¡åˆ’ï¼Œé¢„è®¡{len(task_plan.steps)}ä¸ªæ­¥éª¤")
                        
                        plan_msg = AIMessage(
                            content=f"ğŸ“ ä»»åŠ¡è§„åˆ’å®Œæˆï¼š{task_plan.description} "
                                    f"(é¢„è®¡ {len(task_plan.steps)} ä¸ªæ­¥éª¤)"
                        )
                        updated_state = StateManager.update_messages(updated_state, plan_msg)
                    
                    # æ›´æ–°å½“å‰ä»»åŠ¡
                    task_info = {
                        "task_id": task_plan.task_id,
                        "task_type": task_plan.task_type.value,
                        "description": task_plan.description,
                        "status": "in_progress",
                        "created_at": task_plan.created_at.isoformat(),
                        "updated_at": task_plan.created_at.isoformat(),
                        "steps": task_plan.steps,
                        "current_step": 0
                    }
                    updated_state = StateManager.update_current_task(updated_state, task_info)
                    
                    # æ¨é€èŠ‚ç‚¹å®Œæˆä¿¡æ¯
                    push_progress("task_planning", 1.0, "ä»»åŠ¡è§„åˆ’å®Œæˆ")
                    push_node_complete("task_planner", f"ä»»åŠ¡è§„åˆ’å®Œæˆï¼š{task_plan.task_type.value}ç±»å‹ï¼Œ{len(task_plan.steps)}ä¸ªæ­¥éª¤")
                    
                    return updated_state
                    
                except Exception as e:
                    logger.error(f"Task-Planneræ‰§è¡Œå¤±è´¥: {str(e)}")
                    
                    # æ¨é€é”™è¯¯ä¿¡æ¯
                    push_error(f"Task-Plannerè§„åˆ’å¤±è´¥: {str(e)}", "task_planner")
                    
                    error_msg = AIMessage(content=f"âŒ Task-Plannerè§„åˆ’å¤±è´¥: {str(e)}")
                    return StateManager.update_messages(state, error_msg)
            
            # æ·»åŠ Runtime-SupervisorèŠ‚ç‚¹
            def runtime_supervisor_node(state: IsotopeSystemState) -> IsotopeSystemState:
                """Runtime-SupervisorèŠ‚ç‚¹ï¼šç›‘æ§æ‰§è¡Œè¿‡ç¨‹å¹¶æ‰§è¡ŒåŠ¨æ€å­å›¾"""
                # æ¨é€èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œä¿¡æ¯
                from app.core.stream_writer_helper import (
                    push_node_start, push_node_complete, push_thinking, push_error, push_progress
                )
                push_node_start("runtime_supervisor", "å¼€å§‹ç›‘æ§å’Œæ‰§è¡Œä»»åŠ¡")
                
                logger.info("æ‰§è¡ŒRuntime-SupervisorèŠ‚ç‚¹")
                
                try:
                    current_task = state.get("current_task")
                    if not current_task:
                        push_thinking("runtime_supervisor", "æ— å½“å‰ä»»åŠ¡ï¼Œè·³è¿‡æ‰§è¡Œ", "task_check")
                        push_node_complete("runtime_supervisor", "æ— ä»»åŠ¡éœ€è¦æ‰§è¡Œ")
                        return state
                    
                    # æ¨é€ç›‘æ§å¼€å§‹ä¿¡æ¯
                    push_thinking("runtime_supervisor", f"å¼€å§‹ç›‘æ§ä»»åŠ¡æ‰§è¡Œï¼š{current_task.get('description', 'æœªçŸ¥ä»»åŠ¡')}", "monitoring")
                    
                    # ç›‘æ§æ‰§è¡Œ
                    monitor_result = runtime_supervisor.monitor_execution(state, current_task)
                    
                    # â­ é˜¶æ®µ5æ ¸å¿ƒåŠŸèƒ½ï¼šæ‰§è¡ŒåŠ¨æ€å­å›¾
                    generated_subgraphs = state.get("metadata", {}).get("generated_subgraphs", {})
                    subgraph_plan = state.get("metadata", {}).get("subgraph_execution_plan", {})
                    
                    if generated_subgraphs and subgraph_plan:
                        # æ¨é€å­å›¾æ‰§è¡Œå¼€å§‹ä¿¡æ¯
                        push_thinking("runtime_supervisor", f"å‘ç°{len(generated_subgraphs)}ä¸ªåŠ¨æ€å­å›¾ï¼Œå¼€å§‹æ‰§è¡Œ", "subgraph_execution")
                        logger.info("ğŸš€ RuntimeSupervisorå¼€å§‹æ‰§è¡ŒåŠ¨æ€å­å›¾")
                        
                        current_index = subgraph_plan.get("current_subgraph_index", 0)
                        subgraph_list = subgraph_plan.get("subgraphs", [])
                        
                        if current_index < len(subgraph_list):
                            current_subgraph_name = subgraph_list[current_index]
                            current_subgraph = generated_subgraphs.get(current_subgraph_name)
                            
                            if current_subgraph:
                                # æ¨é€å­å›¾æ‰§è¡Œè¿›åº¦
                                execution_progress = current_index / len(subgraph_list)
                                push_progress("subgraph_execution", execution_progress, f"æ‰§è¡Œå­å›¾ {current_subgraph_name} ({current_index + 1}/{len(subgraph_list)})")
                                push_thinking("runtime_supervisor", f"å¼€å§‹æ‰§è¡Œå­å›¾: {current_subgraph_name}", "subgraph_run")
                                
                                logger.info(f"ğŸ“Š æ‰§è¡Œå­å›¾: {current_subgraph_name}")
                                
                                try:
                                    # æ‰§è¡Œå­å›¾
                                    subgraph_result = current_subgraph.invoke(
                                        state,
                                        config={"configurable": {"thread_id": f"{session_id}_{current_subgraph_name}"}}
                                    )
                                    
                                    # åˆå¹¶å­å›¾æ‰§è¡Œç»“æœ
                                    updated_state = state.copy()
                                    if isinstance(subgraph_result, dict):
                                        # æ›´æ–°æ¶ˆæ¯
                                        if "messages" in subgraph_result and subgraph_result["messages"]:
                                            if "messages" not in updated_state:
                                                updated_state["messages"] = []
                                            updated_state["messages"].extend(subgraph_result["messages"])
                                        
                                        # æ›´æ–°å…¶ä»–å­—æ®µ
                                        for key, value in subgraph_result.items():
                                            if key != "messages":
                                                updated_state[key] = value
                                    
                                    # æ›´æ–°å­å›¾æ‰§è¡Œè¿›åº¦
                                    updated_state["metadata"]["subgraph_execution_plan"]["current_subgraph_index"] = current_index + 1
                                    
                                    # æ¨é€å­å›¾æ‰§è¡ŒæˆåŠŸä¿¡æ¯
                                    completion_progress = (current_index + 1) / len(subgraph_list)
                                    push_progress("subgraph_execution", completion_progress, f"å­å›¾ {current_subgraph_name} æ‰§è¡Œå®Œæˆ")
                                    push_thinking("runtime_supervisor", f"å­å›¾ {current_subgraph_name} æ‰§è¡ŒæˆåŠŸï¼Œç»“æœå·²åˆå¹¶", "subgraph_complete")
                                    
                                    # æ·»åŠ æ‰§è¡ŒæˆåŠŸæ¶ˆæ¯
                                    exec_msg = AIMessage(
                                        content=f"âœ… å­å›¾ {current_subgraph_name} æ‰§è¡Œå®Œæˆ ({current_index + 1}/{len(subgraph_list)})"
                                    )
                                    updated_state = StateManager.update_messages(updated_state, exec_msg)
                                    
                                    logger.info(f"âœ… å­å›¾ {current_subgraph_name} æ‰§è¡ŒæˆåŠŸ")
                                    
                                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šå­å›¾éœ€è¦æ‰§è¡Œ
                                    if current_index + 1 < len(subgraph_list):
                                        # æ ‡è®°éœ€è¦ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªå­å›¾
                                        updated_state["metadata"]["next_action"] = "continue_subgraph"
                                    else:
                                        # æ‰€æœ‰å­å›¾æ‰§è¡Œå®Œæˆ
                                        updated_state["metadata"]["next_action"] = "all_subgraphs_complete"
                                        complete_msg = AIMessage(
                                            content="ğŸ‰ æ‰€æœ‰åŠ¨æ€å­å›¾æ‰§è¡Œå®Œæˆï¼"
                                        )
                                        updated_state = StateManager.update_messages(updated_state, complete_msg)
                                    
                                    return updated_state
                                    
                                except Exception as subgraph_exec_error:
                                    logger.error(f"å­å›¾ {current_subgraph_name} æ‰§è¡Œå¤±è´¥: {str(subgraph_exec_error)}")
                                    
                                    # æ¨é€å­å›¾æ‰§è¡Œå¤±è´¥ä¿¡æ¯
                                    push_error(f"å­å›¾ {current_subgraph_name} æ‰§è¡Œå¤±è´¥: {str(subgraph_exec_error)}", "runtime_supervisor")
                                    push_thinking("runtime_supervisor", f"å­å›¾ {current_subgraph_name} æ‰§è¡Œå¤±è´¥ï¼Œæ ‡è®°é”™è¯¯çŠ¶æ€", "error_handling")
                                    
                                    error_msg = AIMessage(
                                        content=f"âŒ å­å›¾ {current_subgraph_name} æ‰§è¡Œå¤±è´¥: {str(subgraph_exec_error)}"
                                    )
                                    updated_state = state.copy()
                                    updated_state = StateManager.update_messages(updated_state, error_msg)
                                    updated_state["metadata"]["next_action"] = "subgraph_error"
                                    return updated_state
                            else:
                                logger.warning(f"å­å›¾ {current_subgraph_name} ä¸å­˜åœ¨")
                        else:
                            # æ¨é€æ‰€æœ‰å­å›¾æ‰§è¡Œå®Œæˆä¿¡æ¯
                            push_progress("subgraph_execution", 1.0, "æ‰€æœ‰åŠ¨æ€å­å›¾æ‰§è¡Œå®Œæˆ")
                            push_thinking("runtime_supervisor", "æ‰€æœ‰åŠ¨æ€å­å›¾å·²æ‰§è¡Œå®Œæˆï¼Œå‡†å¤‡è¿›å…¥æœ€ç»ˆå®¡æŸ¥", "completion")
                            
                            logger.info("æ‰€æœ‰å­å›¾å·²æ‰§è¡Œå®Œæˆ")
                            updated_state = state.copy()
                            updated_state["metadata"]["next_action"] = "all_subgraphs_complete"
                            return updated_state
                    
                    # ä¼ ç»Ÿä»»åŠ¡ç›‘æ§é€»è¾‘ï¼ˆæ— å­å›¾æ—¶çš„å›é€€ï¼‰
                    task_plan_dict = state.get("metadata", {}).get("task_plan", {})
                    if task_plan_dict:
                        task_plan = TaskPlan(
                            task_id=task_plan_dict["task_id"],
                            task_type=TaskType(task_plan_dict["task_type"]),
                            description=task_plan_dict["description"]
                        )
                        next_action = runtime_supervisor.decide_next_action(state, task_plan)
                        
                        # æ›´æ–°çŠ¶æ€
                        updated_state = state.copy()
                        if "metadata" not in updated_state:
                            updated_state["metadata"] = {}
                        updated_state["metadata"]["runtime_monitor"] = monitor_result
                        updated_state["metadata"]["next_action"] = next_action
                        
                        # æ·»åŠ ç›‘æ§æ¶ˆæ¯
                        monitor_msg = AIMessage(content=f"ğŸ” Runtimeç›‘æ§ï¼š{next_action}")
                        updated_state = StateManager.update_messages(updated_state, monitor_msg)
                        
                        # æ¨é€èŠ‚ç‚¹å®Œæˆä¿¡æ¯
                        push_node_complete("runtime_supervisor", f"ä¼ ç»Ÿä»»åŠ¡ç›‘æ§å®Œæˆï¼Œä¸‹ä¸€æ­¥åŠ¨ä½œï¼š{next_action}")
                        
                        return updated_state
                    
                    # æ¨é€èŠ‚ç‚¹å®Œæˆä¿¡æ¯ï¼ˆæ— ä»»åŠ¡æˆ–å­å›¾çš„æƒ…å†µï¼‰
                    push_node_complete("runtime_supervisor", "æ— éœ€æ‰§è¡Œä»»åŠ¡æˆ–å­å›¾")
                    return state
                    
                except Exception as e:
                    logger.error(f"Runtime-Supervisoræ‰§è¡Œå¤±è´¥: {str(e)}")
                    
                    # æ¨é€é”™è¯¯ä¿¡æ¯
                    push_error(f"Runtime-Supervisorç›‘æ§å¤±è´¥: {str(e)}", "runtime_supervisor")
                    
                    error_msg = AIMessage(content=f"âŒ Runtime-Supervisorç›‘æ§å¤±è´¥: {str(e)}")
                    return StateManager.update_messages(state, error_msg)
            
            # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹åˆ°å›¾ä¸­
            graph.add_node("meta_supervisor", meta_supervisor_node)
            graph.add_node("task_planner", task_planner_node)
            graph.add_node("runtime_supervisor", runtime_supervisor_node)
            graph.add_node("critic", critic_node_func)
            
            # æ·»åŠ å¢å¼ºçš„æ™ºèƒ½ä½“èŠ‚ç‚¹
            for node_name, node_func in enhanced_nodes.items():
                graph.add_node(node_name, node_func)
                logger.info(f"æ·»åŠ å¢å¼ºèŠ‚ç‚¹: {node_name}")
            
            # åˆ›å»ºè·¯ç”±å‡½æ•°
            def route_after_meta_supervisor(state: IsotopeSystemState) -> str:
                """Meta-Supervisoråçš„è·¯ç”±"""
                analysis = state.get("metadata", {}).get("task_analysis", {})
                task_type = analysis.get("task_type", "consultation")
                
                if task_type == "consultation":
                    return "main_agent"
                else:
                    return "task_planner"
            
            def route_after_task_planner(state: IsotopeSystemState) -> str:
                """Task-Planneråçš„è·¯ç”± - ä½¿ç”¨ä¸“ä¸šæ™ºèƒ½ä½“æ¶æ„"""
                task_plan = state.get("metadata", {}).get("task_plan", {})
                task_type = task_plan.get("task_type", "consultation")
                
                # é˜¶æ®µ5æ¶æ„ï¼šæ‰€æœ‰ä»»åŠ¡éƒ½é€šè¿‡æ™ºèƒ½è·¯ç”±å™¨è¿›è¡Œæœ€ä½³æ™ºèƒ½ä½“é€‰æ‹©
                if "smart_router" in enhanced_nodes:
                    logger.info(f"ä»»åŠ¡ç±»å‹ {task_type} -> æ™ºèƒ½è·¯ç”±å™¨")
                    return "smart_router"
                else:
                    # å›é€€æ–¹æ¡ˆï¼šå¦‚æœæ²¡æœ‰æ™ºèƒ½è·¯ç”±å™¨ï¼Œä½¿ç”¨ä¼ ç»Ÿè·¯ç”±
                    if task_type == "data_analysis":
                        return "quality_control_agent" if "quality_control_agent" in enhanced_nodes else "main_agent"
                    elif task_type == "expert_analysis":
                        return "general_analysis_agent" if "general_analysis_agent" in enhanced_nodes else "main_agent"
                    else:
                        return "main_agent"
            
            def route_after_agent_execution(state: IsotopeSystemState) -> str:
                """æ™ºèƒ½ä½“æ‰§è¡Œåçš„è·¯ç”±"""
                # å…ˆè¿›è¡ŒCriticå®¡æŸ¥
                return "critic"
            
            def route_after_critic(state: IsotopeSystemState) -> str:
                """Criticå®¡æŸ¥åçš„è·¯ç”±"""
                critic_result = state.get("metadata", {}).get("critic_result", {})
                next_action = critic_result.get("next_action", "continue")
                
                logger.info(f"Criticå†³ç­–: {next_action}")
                
                if next_action == "continue":
                    return "runtime_supervisor"
                elif next_action == "replan":
                    return "task_planner"
                elif next_action == "interrupt":
                    # å¤„ç†ä¸­æ–­
                    if self.interrupt_manager:
                        interrupt_reason = self.interrupt_manager.create_interrupt_for_critic(critic_result)
                        if interrupt_reason:
                            # å°†ä¸­æ–­ä¿¡æ¯æ·»åŠ åˆ°çŠ¶æ€ä¸­
                            updated_state = state.copy()
                            if "metadata" not in updated_state:
                                updated_state["metadata"] = {}
                            updated_state["metadata"]["interrupt_reason"] = interrupt_reason.dict()
                            
                            # å‘é€ä¸­æ–­ä¿¡å·
                            interrupt_msg = AIMessage(
                                content=f"â¸ï¸ æ‰§è¡Œä¸­æ–­: {interrupt_reason.reason}",
                                additional_kwargs={
                                    "__interrupt__": interrupt_reason.dict()
                                }
                            )
                            StateManager.update_messages(updated_state, interrupt_msg)
                            
                            logger.info(f"è§¦å‘ä¸­æ–­: {interrupt_reason.reason}")
                    
                    # æ ¹æ®é…ç½®å†³å®šåç»­è·¯ç”±
                    return "runtime_supervisor"  # æš‚æ—¶å…ˆåˆ°runtime_supervisor
                else:  # abort
                    return "__end__"
            
            def route_after_runtime_supervisor(state: IsotopeSystemState) -> str:
                """Runtime-Supervisoråçš„è·¯ç”± - æ”¯æŒåŠ¨æ€å­å›¾å¾ªç¯æ‰§è¡Œ"""
                next_action = state.get("metadata", {}).get("next_action", "complete")
                logger.info(f"Runtime-Supervisorè·¯ç”±å†³ç­–: {next_action}")
                
                # åŠ¨æ€å­å›¾æ‰§è¡Œé€»è¾‘
                if next_action == "continue_subgraph":
                    # ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªå­å›¾ï¼Œå›åˆ°runtime_supervisor
                    logger.info("ğŸ”„ ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªåŠ¨æ€å­å›¾")
                    return "runtime_supervisor"
                elif next_action == "all_subgraphs_complete":
                    # æ‰€æœ‰å­å›¾æ‰§è¡Œå®Œæˆï¼Œè¿›è¡Œæœ€ç»ˆå®¡æŸ¥
                    logger.info("âœ… æ‰€æœ‰å­å›¾æ‰§è¡Œå®Œæˆï¼Œè¿›å…¥Criticå®¡æŸ¥")
                    return "critic"
                elif next_action == "subgraph_error":
                    # å­å›¾æ‰§è¡Œå‡ºé”™ï¼Œè¿›è¡Œå®¡æŸ¥å’Œå†³ç­–
                    logger.info("âŒ å­å›¾æ‰§è¡Œå‡ºé”™ï¼Œè¿›å…¥Criticå®¡æŸ¥")
                    return "critic"
                elif next_action == "replan":
                    # éœ€è¦é‡æ–°è§„åˆ’
                    logger.info("ğŸ”„ éœ€è¦é‡æ–°è§„åˆ’ï¼Œè¿”å›TaskPlanner")
                    return "task_planner"
                elif next_action == "interrupt":
                    # éœ€è¦ä¸­æ–­
                    logger.info("â¸ï¸ éœ€è¦ä¸­æ–­ï¼Œç›´æ¥ç»“æŸ")
                    return "__end__"
                else:
                    # é»˜è®¤å®Œæˆæµç¨‹
                    logger.info("ğŸ æµç¨‹å®Œæˆï¼Œç›´æ¥ç»“æŸ")
                    return "__end__"
            
            # è®¾ç½®å›¾çš„æµç¨‹
            graph.set_entry_point("meta_supervisor")
            
            # æ·»åŠ æ¡ä»¶è¾¹
            graph.add_conditional_edges(
                "meta_supervisor",
                route_after_meta_supervisor,
                {
                    "main_agent": "main_agent",
                    "task_planner": "task_planner"
                }
            )
            
            graph.add_conditional_edges(
                "task_planner", 
                route_after_task_planner,
                {
                    "main_agent": "main_agent",
                    "smart_router": "smart_router" if "smart_router" in enhanced_nodes else "main_agent",
                    "general_analysis_agent": "general_analysis_agent" if "general_analysis_agent" in enhanced_nodes else "main_agent"
                }
            )
            
            # æ·»åŠ æ™ºèƒ½è·¯ç”±å™¨çš„æ¡ä»¶è¾¹
            def route_after_smart_router(state: IsotopeSystemState) -> str:
                """æ™ºèƒ½è·¯ç”±å™¨åçš„è·¯ç”±"""
                route_to = state.get("metadata", {}).get("route_to", "general_analysis_agent")
                logger.info(f"æ™ºèƒ½è·¯ç”±å™¨å†³ç­–: è·¯ç”±åˆ° {route_to}")
                return route_to
            
            if "smart_router" in enhanced_nodes:
                graph.add_conditional_edges(
                    "smart_router",
                    route_after_smart_router,
                    {
                        "geophysics_agent": "geophysics_agent" if "geophysics_agent" in enhanced_nodes else "general_analysis_agent",
                        "reservoir_agent": "reservoir_agent" if "reservoir_agent" in enhanced_nodes else "general_analysis_agent",
                        "economics_agent": "economics_agent" if "economics_agent" in enhanced_nodes else "general_analysis_agent",
                        "quality_control_agent": "quality_control_agent" if "quality_control_agent" in enhanced_nodes else "general_analysis_agent",
                        "logging_agent": "logging_agent" if "logging_agent" in enhanced_nodes else "general_analysis_agent",  # å½•äº•æ™ºèƒ½ä½“
                        "seismic_agent": "seismic_agent" if "seismic_agent" in enhanced_nodes else "general_analysis_agent",  # åœ°éœ‡æ™ºèƒ½ä½“
                        "general_analysis_agent": "general_analysis_agent" if "general_analysis_agent" in enhanced_nodes else "main_agent",
                        "critic": "critic"  # æ”¯æŒç›´æ¥åˆ°criticçš„èº«ä»½ç¡®è®¤å“åº”
                    }
                )
            
            # åªæœ‰å®é™…æ‰§è¡Œä»»åŠ¡çš„æ™ºèƒ½ä½“æ‰éœ€è¦ç»è¿‡Criticå®¡æŸ¥ï¼ˆæ™ºèƒ½è·¯ç”±å™¨ä¸éœ€è¦ï¼‰
            for agent_name in ["main_agent", "general_analysis_agent", 
                             "geophysics_agent", "reservoir_agent", "economics_agent", 
                             "quality_control_agent", "logging_agent", "seismic_agent"]:
                if agent_name in enhanced_nodes:
                    graph.add_edge(agent_name, "critic")
            
            # Criticå®¡æŸ¥åçš„è·¯ç”±
            graph.add_conditional_edges(
                "critic",
                route_after_critic,
                {
                    "runtime_supervisor": "runtime_supervisor",
                    "task_planner": "task_planner",
                    "__end__": "__end__"
                }
            )
            
            # Runtime-Supervisoråçš„è·¯ç”±
            graph.add_conditional_edges(
                "runtime_supervisor",
                route_after_runtime_supervisor,
                {
                    "task_planner": "task_planner",
                    "__end__": "__end__"
                }
            )
            
            logger.info("é˜¶æ®µ1å¢å¼ºç‰ˆå›¾ï¼ˆå«CriticèŠ‚ç‚¹ï¼‰æ„å»ºå®Œæˆ")
            return graph
            
        except Exception as e:
            logger.error(f"æ„å»ºå¢å¼ºç‰ˆå›¾å¤±è´¥: {str(e)}")
            raise
    
    def create_graph_with_checkpoint(
        self,
        session_id: str,
        enable_subgraph_checkpoint: bool = True
    ) -> StateGraph:
        """åˆ›å»ºå¸¦æ£€æŸ¥ç‚¹çš„å›¾
        
        Args:
            session_id: ä¼šè¯ID
            enable_subgraph_checkpoint: æ˜¯å¦å¯ç”¨å­å›¾æ£€æŸ¥ç‚¹
            
        Returns:
            é…ç½®äº†æ£€æŸ¥ç‚¹çš„çŠ¶æ€å›¾
        """
        logger.info(f"å¼€å§‹åˆ›å»ºå¸¦æ£€æŸ¥ç‚¹çš„å›¾ï¼Œä¼šè¯ID: {session_id}")
        
        try:
            # åˆ›å»ºå¢å¼ºç‰ˆå›¾ï¼ˆä½¿ç”¨MetaSupervisoræ¶æ„ï¼‰
            graph = self.build_enhanced_graph(session_id)
            
            # è·å–æ£€æŸ¥ç‚¹å™¨
            checkpointer = self.get_active_checkpointer()
            
            if checkpointer:
                # è·å–æ£€æŸ¥ç‚¹ç³»ç»ŸçŠ¶æ€
                checkpoint_status = self.get_checkpoint_status()
                logger.info(f"ä½¿ç”¨æ£€æŸ¥ç‚¹åç«¯: {checkpoint_status['active_backend']}")
                
                # å°è¯•è®¾ç½®thread_idå±æ€§ï¼ˆå¦‚æœæ”¯æŒï¼‰
                try:
                    if hasattr(checkpointer, 'thread_id'):
                        checkpointer.thread_id = session_id
                except Exception as e:
                    logger.warning(f"æ— æ³•è®¾ç½®æ£€æŸ¥ç‚¹å™¨thread_id: {str(e)}")
            else:
                logger.warning("æ‰€æœ‰æ£€æŸ¥ç‚¹å™¨éƒ½ä¸å¯ç”¨ï¼Œå›¾å°†æ— æ³•æŒä¹…åŒ–")
            
            # å¦‚æœPostgreSQLæ£€æŸ¥ç‚¹ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹
            if not checkpointer:
                try:
                    from langgraph.checkpoint.memory import MemorySaver
                    checkpointer = MemorySaver()
                    logger.info("ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å™¨ä½œä¸ºå›é€€")
                except Exception as memory_error:
                    logger.warning(f"å†…å­˜æ£€æŸ¥ç‚¹å™¨ä¹Ÿä¸å¯ç”¨: {str(memory_error)}")
                    logger.warning("å›¾å°†æ— æ³•æŒä¹…åŒ–")
            
            # ç¼–è¯‘å›¾å¹¶é…ç½®æ£€æŸ¥ç‚¹
            if checkpointer:
                # å®šä¹‰ä¸­æ–­ç‚¹ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦é…ç½®ï¼‰
                interrupt_before = []
                interrupt_after = []
                
                # ç¼–è¯‘å›¾
                compiled_graph = graph.compile(
                    checkpointer=checkpointer,
                    # å¯ç”¨ä¸­æ–­å’Œæ¢å¤
                    interrupt_before=interrupt_before,  # å¯ä»¥é…ç½®åœ¨å“ªäº›èŠ‚ç‚¹å‰ä¸­æ–­
                    interrupt_after=interrupt_after     # å¯ä»¥é…ç½®åœ¨å“ªäº›èŠ‚ç‚¹åä¸­æ–­
                )
                logger.info("å›¾å·²ç¼–è¯‘å¹¶é…ç½®äº†æ£€æŸ¥ç‚¹")
            else:
                compiled_graph = graph.compile()
                logger.warning("å›¾å·²ç¼–è¯‘ä½†æœªé…ç½®æ£€æŸ¥ç‚¹")
            
            return compiled_graph
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå¸¦æ£€æŸ¥ç‚¹çš„å›¾å¤±è´¥: {str(e)}")
            # å›é€€åˆ°æ— æ£€æŸ¥ç‚¹ç‰ˆæœ¬ï¼ˆä½¿ç”¨å¢å¼ºå›¾ï¼‰
            try:
                fallback_graph = self.build_enhanced_graph(session_id)
                return fallback_graph.compile()
            except Exception as compile_error:
                logger.error(f"å›é€€ç¼–è¯‘ä¹Ÿå¤±è´¥: {str(compile_error)}")
                # åˆ›å»ºæœ€å°åŒ–çš„å›¾
                minimal_graph = StateGraph(dict)
                minimal_graph.add_node("default", lambda state: state)
                minimal_graph.set_entry_point("default")
                return minimal_graph.compile()
    
    def create_task_enhanced_nodes(self) -> Dict[str, Callable]:
        """åˆ›å»ºæ”¯æŒ@taskçš„å¢å¼ºèŠ‚ç‚¹
        
        Returns:
            å¢å¼ºèŠ‚ç‚¹å­—å…¸
        """
        enhanced_nodes = {}
        
        if not self.enable_task_support:
            logger.info("Taskæ”¯æŒæœªå¯ç”¨ï¼Œä½†ä»ä½¿ç”¨æ–°æ¶æ„èŠ‚ç‚¹")
        
        logger.info("åˆ›å»ºæ”¯æŒ@taskçš„å¢å¼ºèŠ‚ç‚¹")
        
        # ä½¿ç”¨æ–°çš„LangGraphæ¶æ„åˆ›å»ºæ™ºèƒ½ä½“èŠ‚ç‚¹
        logger.info("ä½¿ç”¨æ–°çš„LangGraphæ¶æ„åˆ›å»ºæ™ºèƒ½ä½“èŠ‚ç‚¹")
        
        # å¯¼å…¥æ³¨å†Œè¡¨
        from app.agents.registry import agent_registry
        
        # åˆ›å»ºç»Ÿä¸€æ™ºèƒ½ä½“èŠ‚ç‚¹ç”Ÿæˆå™¨
        def create_agent_node(agent_name: str, role: str) -> Callable:
            """åˆ›å»ºä½¿ç”¨æ³¨å…¥æ™ºèƒ½ä½“çš„èŠ‚ç‚¹"""
            def agent_node(state: IsotopeSystemState) -> IsotopeSystemState:
                try:
                    logger.info(f"{agent_name}èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ")
                    
                    # ç¡®ä¿stateæ˜¯å­—å…¸æ ¼å¼
                    if not isinstance(state, dict):
                        state = {}
                    
                    # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                    state = self._ensure_state_fields(state)
                    
                    # ä»æ³¨å…¥çš„æ™ºèƒ½ä½“ä¸­è·å–
                    agent = None
                    
                    # é¦–å…ˆå°è¯•ä»ä¼ å…¥çš„supervisor_agentè·å–
                    if agent_name == "main_agent" and self.supervisor_agent:
                        agent = self.supervisor_agent
                        logger.info(f"ä½¿ç”¨æ³¨å…¥çš„supervisor_agentä½œä¸º{agent_name}")
                    # å¦åˆ™ä»æ³¨å†Œè¡¨è·å–
                    elif agent_registry.has_agent(role):
                        agent = agent_registry.get(role)
                        logger.info(f"ä»æ³¨å†Œè¡¨è·å–æ™ºèƒ½ä½“: {role}")
                    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•é€šè¿‡åç§°è·å–
                    elif agent_registry.has_agent(agent_name):
                        agent = agent_registry.get(agent_name)
                        logger.info(f"ä»æ³¨å†Œè¡¨è·å–æ™ºèƒ½ä½“: {agent_name}")
                    else:
                        raise ValueError(f"æœªæ‰¾åˆ°æ™ºèƒ½ä½“: {agent_name} (role: {role})")
                    
                    # è¿è¡Œæ™ºèƒ½ä½“
                    result_state = agent.run(state)
                    
                    logger.info(f"{agent_name}èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ")
                    return result_state
                    
                except Exception as e:
                    logger.error(f"{agent_name}èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
                    state = self._ensure_state_fields(state)
                    state["messages"].append({
                        "role": "assistant", 
                        "content": f"{agent_name}å¤„ç†å‡ºé”™: {str(e)}"
                    })
                    return state
            
            return agent_node
        
        # åˆ›å»ºä¸“ä¸šæ™ºèƒ½ä½“èŠ‚ç‚¹ç”Ÿæˆå™¨
        def create_specialized_agent_node(agent_type: str) -> Callable:
            """åˆ›å»ºä¸“ä¸šæ™ºèƒ½ä½“èŠ‚ç‚¹"""
            
            def specialized_agent_node(state: IsotopeSystemState) -> IsotopeSystemState:
                try:
                    # æ¨é€èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œä¿¡æ¯
                    from app.core.stream_writer_helper import (
                        push_node_start, push_node_complete, push_thinking, push_error
                    )
                    push_node_start(f"{agent_type}_agent", f"å¼€å§‹æ‰§è¡Œä¸“ä¸šæ™ºèƒ½ä½“ï¼š{agent_type}")
                    
                    logger.info(f"{agent_type}ä¸“ä¸šæ™ºèƒ½ä½“èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ")
                    
                    # ç¡®ä¿stateæ˜¯å­—å…¸æ ¼å¼
                    if not isinstance(state, dict):
                        state = {}
                    
                    # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                    state = self._ensure_state_fields(state)
                    
                    # ä»æ³¨å†Œè¡¨æˆ–æ³¨å…¥çš„æ™ºèƒ½ä½“ä¸­è·å–
                    agent = None
                    
                    # é¦–å…ˆå°è¯•ä»specialized_agentsä¸­è·å–
                    if self.specialized_agents and agent_type in self.specialized_agents:
                        agent = self.specialized_agents[agent_type]
                        logger.info(f"ä½¿ç”¨æ³¨å…¥çš„ä¸“ä¸šæ™ºèƒ½ä½“: {agent_type}")
                    # å¦åˆ™ä»æ³¨å†Œè¡¨è·å–
                    elif agent_registry.has_agent(agent_type):
                        agent = agent_registry.get(agent_type)
                        logger.info(f"ä»æ³¨å†Œè¡¨è·å–ä¸“ä¸šæ™ºèƒ½ä½“: {agent_type}")
                    else:
                        error_msg = f"æœªæ‰¾åˆ°ä¸“ä¸šæ™ºèƒ½ä½“: {agent_type}"
                        push_error(error_msg, f"{agent_type}_agent")
                        raise ValueError(error_msg)
                    
                    # æ¨é€Agentå¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚
                    push_thinking(f"{agent_type}_agent", f"å¼€å§‹ä½¿ç”¨{agent_type}ä¸“ä¸šæ™ºèƒ½ä½“å¤„ç†ç”¨æˆ·è¯·æ±‚", "processing")
                    
                    # è¿è¡Œæ™ºèƒ½ä½“
                    result_state = agent.run(state)
                    
                    # æ¨é€èŠ‚ç‚¹å®Œæˆä¿¡æ¯
                    push_node_complete(f"{agent_type}_agent", f"{agent_type}ä¸“ä¸šæ™ºèƒ½ä½“å¤„ç†å®Œæˆ")
                    
                    logger.info(f"{agent_type}ä¸“ä¸šæ™ºèƒ½ä½“èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ")
                    return result_state
                    
                except Exception as e:
                    logger.error(f"{agent_type}ä¸“ä¸šæ™ºèƒ½ä½“èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
                    
                    # æ¨é€é”™è¯¯ä¿¡æ¯
                    push_error(f"{agent_type}ä¸“ä¸šæ™ºèƒ½ä½“å¤„ç†å¤±è´¥: {str(e)}", f"{agent_type}_agent")
                    
                    state = self._ensure_state_fields(state)
                    state["messages"].append({
                        "role": "assistant", 
                        "content": f"{agent_type}ä¸“ä¸šæ™ºèƒ½ä½“å¤„ç†å‡ºé”™: {str(e)}"
                    })
                    return state
            
            return specialized_agent_node
        
        # åˆ›å»ºæ™ºèƒ½è·¯ç”±èŠ‚ç‚¹
        def create_smart_router_node() -> Callable:
            """åˆ›å»ºæ™ºèƒ½è·¯ç”±èŠ‚ç‚¹ï¼Œä½¿ç”¨LLMæ™ºèƒ½æ¨èåˆé€‚çš„ä¸“ä¸šæ™ºèƒ½ä½“"""
            def smart_router_node(state: IsotopeSystemState) -> IsotopeSystemState:
                try:
                    # æ¨é€èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œä¿¡æ¯
                    from app.core.stream_writer_helper import push_node_start, push_thinking
                    push_node_start("smart_router", "å¼€å§‹æ™ºèƒ½è·¯ç”±åˆ†æ")
                    
                    logger.info("æ™ºèƒ½è·¯ç”±èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ")
                    
                    # ç¡®ä¿stateæ˜¯å­—å…¸æ ¼å¼
                    if not isinstance(state, dict):
                        state = {}
                    
                    # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                    state = self._ensure_state_fields(state)
                    
                    # å¯¼å…¥æ¨èå‡½æ•°
                    from app.agents.specialized_agents import recommend_agent_for_request
                    
                    # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
                    from app.core.state import StateManager
                    last_msg = StateManager.get_last_human_message(state)
                    if not last_msg:
                        raise ValueError("æœªæ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯")
                    
                    # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½æ„å›¾è¯†åˆ«å’Œæ™ºèƒ½ä½“æ¨è
                    llm = self.llm or self._get_default_llm()
                    recommended_agent = recommend_agent_for_request(last_msg.content, llm)
                    
                    # å¤„ç†ç‰¹æ®Šçš„èº«ä»½ç¡®è®¤å“åº”
                    if recommended_agent == "identity_response":
                        # ä½¿ç”¨æµå¼LLMç”Ÿæˆèº«ä»½ç¡®è®¤å›ç­”ï¼Œé¿å…é‡å¤è¾“å‡ºé—®é¢˜
                        from langchain_core.messages import AIMessage
                        
                        # è·å–ç”¨æˆ·çš„å…·ä½“é—®é¢˜å†…å®¹
                        user_question = last_msg.content if last_msg else "ä½ æ˜¯è°"
                        
                        # æ„å»ºèº«ä»½ç¡®è®¤çš„æç¤ºè¯
                        identity_prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{user_question}
 
 è¯·ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„å¤©ç„¶æ°”ç¢³åŒä½ç´ æ•°æ®è§£é‡Šæ™ºèƒ½åŠ©æ‰‹æ¥å›ç­”è¿™ä¸ªèº«ä»½ç¡®è®¤é—®é¢˜ã€‚
 
 ä½ çš„å›ç­”åº”è¯¥ï¼š
 1. ç®€æ´æ˜äº†åœ°ä»‹ç»è‡ªå·±çš„èº«ä»½å’Œä¸“ä¸šé¢†åŸŸ
 2. çªå‡ºä½ åœ¨å¤©ç„¶æ°”ç¢³åŒä½ç´ æ•°æ®è§£é‡Šæ–¹é¢çš„ä¸“ä¸šèƒ½åŠ›
 3. æåŠä½ èƒ½å¤ŸååŠ©çš„ä¸»è¦æŠ€æœ¯é¢†åŸŸï¼ˆå¦‚åœ°çƒç‰©ç†åˆ†æã€æ²¹è—å·¥ç¨‹ã€ç»æµè¯„ä»·ç­‰ï¼‰
 4. è¯­æ°”ä¸“ä¸šä½†å‹å¥½ï¼Œå±•ç°å‡ºä¸“ä¸šæ€§å’Œå¯ä¿¡åº¦
 5. ç®€çŸ­åœ°è¯¢é—®ç”¨æˆ·æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©çš„
 
 è¯·ç›´æ¥å›ç­”ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–é¢å¤–è¯´æ˜ã€‚"""
                        
                        try:
                            # ä½¿ç”¨æµå¼å†™å…¥è¾…åŠ©å·¥å…·æ¨é€èŠ‚ç‚¹å¼€å§‹ä¿¡æ¯
                            from app.core.stream_writer_helper import push_node_start, push_thinking
                            push_node_start("smart_router", "å¼€å§‹ç”Ÿæˆèº«ä»½ç¡®è®¤å›å¤")
                            
                            # æ¨é€Agentæ€è€ƒè¿‡ç¨‹
                            push_thinking("smart_router", "æ£€æµ‹åˆ°èº«ä»½ç¡®è®¤é—®é¢˜ï¼Œæ­£åœ¨ç”Ÿæˆä¸“ä¸šå›å¤", "identity_response")
                            
                            # ä½¿ç”¨LLMæµå¼ç”Ÿæˆèº«ä»½ç¡®è®¤å“åº”
                            llm = self.llm or self._get_default_llm()
                            
                            # è·å–LangGraphåŸç”Ÿæµå†™å…¥å™¨ç”¨äºLLM tokenæµå¼è¾“å‡º
                            from langgraph.config import get_stream_writer
                            stream_writer = get_stream_writer()
                            
                            if stream_writer:
                                # å¦‚æœæœ‰æµå†™å…¥å™¨ï¼Œä½¿ç”¨æµå¼è¾“å‡º
                                response_content = ""
                                for chunk in llm.stream(identity_prompt):
                                    if hasattr(chunk, 'content') and chunk.content:
                                        chunk_content = chunk.content
                                        response_content += chunk_content
                                        # å®æ—¶æµå¼è¾“å‡º
                                        stream_writer({
                                            "role": "assistant",
                                            "content": chunk_content,
                                            "is_token": True,
                                            "source": "smart_router"
                                        })
                                
                                # åˆ›å»ºAIæ¶ˆæ¯å¹¶æ·»åŠ åˆ°çŠ¶æ€
                                ai_message = AIMessage(
                                    content=response_content,
                                    additional_kwargs={
                                        "source": "smart_router",
                                        "route_decision": "identity_response",
                                        "llm_generated": True,
                                        "streamed": True  # æ ‡è®°ä¸ºå·²æµå¼è¾“å‡º
                                    }
                                )
                            else:
                                # å¦‚æœæ²¡æœ‰æµå†™å…¥å™¨ï¼Œç›´æ¥ç”Ÿæˆå“åº”ï¼ˆä½†ä¸ä¼šæœ‰é‡å¤é—®é¢˜ï¼Œå› ä¸ºæ²¡æœ‰æµå¤„ç†ï¼‰
                                identity_response = llm.invoke(identity_prompt)
                                
                                # ç¡®ä¿å“åº”æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                                if hasattr(identity_response, 'content'):
                                    response_content = identity_response.content
                                else:
                                    response_content = str(identity_response)
                                
                                ai_message = AIMessage(
                                    content=response_content,
                                    additional_kwargs={
                                        "source": "smart_router",
                                        "route_decision": "identity_response",
                                        "llm_generated": True,
                                        "streamed": False  # æ ‡è®°ä¸ºéæµå¼è¾“å‡º
                                    }
                                )
                            
                            state = StateManager.update_messages(state, ai_message)
                            state["metadata"]["route_to"] = "critic"  # ç›´æ¥åˆ°criticç»“æŸ
                            
                            # æ¨é€èŠ‚ç‚¹å®Œæˆå’Œè·¯ç”±å†³ç­–ä¿¡æ¯
                            from app.core.stream_writer_helper import push_node_complete, push_route
                            push_node_complete("smart_router", "èº«ä»½ç¡®è®¤å›å¤ç”Ÿæˆå®Œæˆ")
                            push_route("smart_router", "critic", "èº«ä»½ç¡®è®¤é—®é¢˜ï¼Œç›´æ¥ç»“æŸå¯¹è¯")
                            
                            # æ¸…ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼Œé¿å…æ£€æŸ¥ç‚¹åºåˆ—åŒ–é”™è¯¯
                            if "memory_store" in state:
                                del state["memory_store"]
                            
                            logger.info("æ™ºèƒ½è·¯ç”±å™¨: èº«ä»½ç¡®è®¤é—®é¢˜ï¼Œå·²ä½¿ç”¨æµå¼LLMç”Ÿæˆå›ç­”")
                            return state
                            
                        except Exception as e:
                            logger.error(f"LLMç”Ÿæˆèº«ä»½ç¡®è®¤å“åº”å¤±è´¥: {str(e)}")
                            # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œè·¯ç”±åˆ°é€šç”¨åˆ†ææ™ºèƒ½ä½“
                            state["metadata"]["selected_agent"] = "general_analysis"
                            state["metadata"]["route_to"] = "general_analysis_agent"
                            logger.info("èº«ä»½ç¡®è®¤LLMè°ƒç”¨å¤±è´¥ï¼Œè·¯ç”±åˆ°é€šç”¨åˆ†ææ™ºèƒ½ä½“")
                            return state
                    
                    # åœ¨çŠ¶æ€ä¸­è®°å½•è·¯ç”±å†³ç­–
                    if "metadata" not in state:
                        state["metadata"] = {}
                    state["metadata"]["selected_agent"] = recommended_agent
                    state["metadata"]["route_to"] = f"{recommended_agent}_agent"  # è®¾ç½®è·¯ç”±ç›®æ ‡
                    
                    # æ¨é€è·¯ç”±å†³ç­–ä¿¡æ¯
                    from app.core.stream_writer_helper import push_node_complete, push_route
                    push_node_complete("smart_router", f"æ™ºèƒ½è·¯ç”±åˆ†æå®Œæˆï¼Œé€‰æ‹©{recommended_agent}æ™ºèƒ½ä½“")
                    push_route("smart_router", f"{recommended_agent}_agent", f"LLMæ¨èä½¿ç”¨{recommended_agent}æ™ºèƒ½ä½“å¤„ç†æ­¤è¯·æ±‚")
                    
                    logger.info(f"LLMæ™ºèƒ½è·¯ç”±å†³ç­–: é€‰æ‹© {recommended_agent} æ™ºèƒ½ä½“")
                    return state
                    
                except Exception as e:
                    logger.error(f"æ™ºèƒ½è·¯ç”±èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
                    
                    # æ¨é€é”™è¯¯ä¿¡æ¯
                    from app.core.stream_writer_helper import push_error, push_route
                    push_error(f"æ™ºèƒ½è·¯ç”±æ‰§è¡Œå¤±è´¥: {str(e)}", "smart_router")
                    
                    # é»˜è®¤è·¯ç”±åˆ°é€šç”¨åˆ†ææ™ºèƒ½ä½“
                    state = self._ensure_state_fields(state)
                    if "metadata" not in state:
                        state["metadata"] = {}
                    state["metadata"]["selected_agent"] = "general_analysis"
                    state["metadata"]["route_to"] = "general_analysis_agent"
                    
                    # æ¨é€å…œåº•è·¯ç”±å†³ç­–
                    push_route("smart_router", "general_analysis_agent", "æ™ºèƒ½è·¯ç”±å¤±è´¥ï¼Œä½¿ç”¨é€šç”¨åˆ†ææ™ºèƒ½ä½“ä½œä¸ºå…œåº•")
                    
                    logger.info("æ™ºèƒ½è·¯ç”±å¤±è´¥ï¼Œé»˜è®¤é€‰æ‹©é€šç”¨åˆ†ææ™ºèƒ½ä½“")
                    return state
            
            return smart_router_node
        
        # åˆ›å»ºæ–°æ¶æ„çš„èŠ‚ç‚¹ï¼ˆä¸“ä¸šæ™ºèƒ½ä½“æ¶æ„ï¼‰
        enhanced_nodes = {
            "smart_router": create_smart_router_node(),
            "geophysics_agent": create_specialized_agent_node("geophysics"),
            "reservoir_agent": create_specialized_agent_node("reservoir"),
            "economics_agent": create_specialized_agent_node("economics"),
            "quality_control_agent": create_specialized_agent_node("quality_control"),
            "general_analysis_agent": create_specialized_agent_node("general_analysis"),
            # æ–°å¢ä¸“ä¸šæ™ºèƒ½ä½“
            "logging_agent": create_specialized_agent_node("logging"),  # å½•äº•èµ„æ–™å¤„ç†
            "seismic_agent": create_specialized_agent_node("seismic"),  # åœ°éœ‡å¤„ç†
            # ä¿ç•™ä¼ ç»Ÿæ™ºèƒ½ä½“ä½œä¸ºå…œåº•ï¼ˆå‘åå…¼å®¹ï¼‰
            "main_agent": create_agent_node("main_agent", "supervisor"),
        }
        
        return enhanced_nodes
    
    def _default_agent_node(self, state: IsotopeSystemState, agent_type: str) -> IsotopeSystemState:
        """é»˜è®¤æ™ºèƒ½ä½“èŠ‚ç‚¹ï¼Œç”¨äºæœªé…ç½®ç‰¹å®šæ™ºèƒ½ä½“çš„æƒ…å†µ
        
        Args:
            state: ç³»ç»ŸçŠ¶æ€
            agent_type: æ™ºèƒ½ä½“ç±»å‹ï¼ˆdataã€expertç­‰ï¼‰
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        try:
            logger.info(f"æ‰§è¡Œé»˜è®¤{agent_type}æ™ºèƒ½ä½“èŠ‚ç‚¹")
            
            # ç¡®ä¿stateæ˜¯å­—å…¸æ ¼å¼
            if not isinstance(state, dict):
                state = {}
            
            # ç¡®ä¿messageså­—æ®µå­˜åœ¨
            if "messages" not in state or state["messages"] is None:
                state["messages"] = []
            
            # ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½å›å¤ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 
            try:
                # è·å–ç”¨æˆ·æœ€è¿‘çš„æ¶ˆæ¯
                user_content = ""
                if state["messages"]:
                    last_message = state["messages"][-1]
                    if hasattr(last_message, 'content'):
                        user_content = last_message.content
                    elif isinstance(last_message, dict):
                        user_content = last_message.get("content", "")
                    else:
                        user_content = str(last_message)
                
                # æ„å»ºä¸“ä¸šçš„LLMæç¤ºè¯
                agent_descriptions = {
                    "data": "æ•°æ®åˆ†æä¸“å®¶ï¼Œä¸“æ³¨äºå¤©ç„¶æ°”ç¢³åŒä½ç´ æ•°æ®çš„å¤„ç†ã€æ¸…æ´—å’Œåˆæ­¥åˆ†æ",
                    "expert": "åŒä½ç´ åœ°çƒåŒ–å­¦ä¸“å®¶ï¼Œä¸“é—¨è¿›è¡Œå¤©ç„¶æ°”æˆå› å’Œæ¥æºçš„æ·±åº¦åˆ†æ",
                    "quality_control": "æ•°æ®è´¨é‡æ§åˆ¶ä¸“å®¶ï¼Œè´Ÿè´£æ•°æ®éªŒè¯ã€å¼‚å¸¸æ£€æµ‹å’Œè´¨é‡è¯„ä¼°",
                    "general_analysis": "ç»¼åˆåˆ†æä¸“å®¶ï¼Œæä¾›è·¨é¢†åŸŸçš„ç»¼åˆæ€§åˆ†æå’Œå»ºè®®",
                    "geophysics": "åœ°çƒç‰©ç†åˆ†æä¸“å®¶ï¼Œä¸“æ³¨äºåœ°éœ‡ã€æµ‹äº•ç­‰åœ°çƒç‰©ç†æ•°æ®è§£é‡Š",
                    "reservoir": "æ²¹è—å·¥ç¨‹ä¸“å®¶ï¼Œä¸“é—¨åˆ†æå‚¨å±‚ç‰¹å¾å’Œå¼€å‘æ–¹æ¡ˆ",
                    "economics": "ç»æµè¯„ä»·ä¸“å®¶ï¼Œè¿›è¡Œé¡¹ç›®ç»æµæ€§åˆ†æå’Œé£é™©è¯„ä¼°"
                }
                
                agent_desc = agent_descriptions.get(agent_type, f"{agent_type}é¢†åŸŸä¸“å®¶")
                
                llm_prompt = f"""ä½œä¸º{agent_desc}ï¼Œè¯·å¯¹ç”¨æˆ·çš„è¯·æ±‚ç»™å‡ºä¸“ä¸šå›åº”ã€‚

ç”¨æˆ·è¾“å…¥ï¼š{user_content}

è¯·ä»¥ä¸“ä¸šã€è¯¦ç»†çš„æ–¹å¼å›ç­”ï¼Œä½“ç°å‡ºä½ åœ¨{agent_type}é¢†åŸŸçš„ä¸“ä¸šèƒ½åŠ›ã€‚å¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸åœ¨ä½ çš„ä¸“ä¸šèŒƒå›´å†…ï¼Œè¯·ç¤¼è²Œåœ°è¯´æ˜å¹¶æä¾›å¯èƒ½çš„å»ºè®®ã€‚"""
                
                # å°è¯•ä½¿ç”¨LLMç”Ÿæˆå›å¤
                llm = self.llm or self._get_default_llm()
                if llm:
                    llm_response = llm.invoke(llm_prompt)
                    if hasattr(llm_response, 'content'):
                        content = llm_response.content
                    else:
                        content = str(llm_response)
                    
                    logger.info(f"é»˜è®¤{agent_type}æ™ºèƒ½ä½“ä½¿ç”¨LLMç”Ÿæˆå›å¤")
                else:
                    # å¦‚æœæ²¡æœ‰LLMï¼Œç”Ÿæˆä¸€ä¸ªä¸“ä¸šçš„åå¤‡å›å¤
                    content = f"ä½œä¸º{agent_desc}ï¼Œæˆ‘å·²æ”¶åˆ°æ‚¨çš„è¯·æ±‚ã€‚è¯·æä¾›æ›´å¤šå…·ä½“ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘ä¸ºæ‚¨æä¾›æ›´å‡†ç¡®çš„ä¸“ä¸šåˆ†æã€‚"
                    
            except Exception as e:
                logger.error(f"LLMç”Ÿæˆ{agent_type}æ™ºèƒ½ä½“å›å¤å¤±è´¥: {str(e)}")
                # LLMå¤±è´¥æ—¶çš„æœ€ååå¤‡æ–¹æ¡ˆ
                content = f"æŠ±æ­‰ï¼Œ{agent_type}æ™ºèƒ½ä½“æš‚æ—¶é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
            
            # æ·»åŠ å“åº”æ¶ˆæ¯
            state["messages"].append({
                "role": "assistant",
                "content": content
            })
            
            logger.info(f"é»˜è®¤{agent_type}æ™ºèƒ½ä½“èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ")
            return state
            
        except Exception as e:
            logger.error(f"é»˜è®¤{agent_type}æ™ºèƒ½ä½“èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
            if not isinstance(state, dict):
                state = {}
            if "messages" not in state:
                state["messages"] = []
            state["messages"].append({
                "role": "assistant",
                "content": f"é»˜è®¤{agent_type}æ™ºèƒ½ä½“æ‰§è¡Œå‡ºé”™: {str(e)}"
            })
            return state
    
    def _find_suitable_task(self, user_input: str) -> Optional[str]:
        """æ ¹æ®ç”¨æˆ·è¾“å…¥æ‰¾åˆ°åˆé€‚çš„task
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            
        Returns:
            åˆé€‚çš„taskåç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        if not self.task_registry:
            return None
        
        all_tasks = self.task_registry.get_all_tasks()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„è¯­ä¹‰åŒ¹é…
        task_keywords = {
            "enhanced_classify_gas_source_task": ["æ°”æº", "åˆ†ç±»", "åŒä½ç´ ", "ç¢³åŒä½ç´ "],
            "load_and_preprocess_isotope_data": ["åŠ è½½", "é¢„å¤„ç†", "æ•°æ®"],
            "generate_gas_source_visualization": ["å¯è§†åŒ–", "å›¾è¡¨", "å›¾ç‰‡"],
        }
        
        user_input_lower = user_input.lower()
        
        for task_name, keywords in task_keywords.items():
            if task_name in all_tasks:
                for keyword in keywords:
                    if keyword in user_input_lower:
                        return task_name
        
        return None
    
    def _execute_task_safely(
        self, 
        task_func: Callable, 
        user_input: str, 
        state: IsotopeSystemState
    ) -> Optional[str]:
        """å®‰å…¨æ‰§è¡Œtask
        
        Args:
            task_func: taskå‡½æ•°
            user_input: ç”¨æˆ·è¾“å…¥
            state: ç³»ç»ŸçŠ¶æ€
            
        Returns:
            æ‰§è¡Œç»“æœæˆ–None
        """
        try:
            # ç¡®ä¿åº”ç”¨äº†LangGraphè£…é¥°å™¨
            from app.core.task_decorator import apply_langgraph_decorator
            task_func = apply_langgraph_decorator(task_func)
            
            # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„taskç­¾åæ¥æ„é€ å‚æ•°
            # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„å‚æ•°æ¨æ–­
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šä¸‹æ–‡
            if hasattr(state, 'current_file_id') and state.current_file_id:
                result = task_func(state.current_file_id)
            else:
                # å°è¯•å…¶ä»–å‚æ•°ç»„åˆ
                result = task_func(user_input)
            
            return str(result)
            
        except Exception as e:
            logger.error(f"å®‰å…¨æ‰§è¡Œtaskå¤±è´¥: {str(e)}")
            return None
    
    def _get_data_analysis_tasks(self) -> List[str]:
        """è·å–æ•°æ®åˆ†æç›¸å…³çš„taskåˆ—è¡¨"""
        if not self.task_registry:
            return []
        
        all_tasks = self.task_registry.get_all_tasks()
        
        # ç­›é€‰æ•°æ®åˆ†æç›¸å…³çš„task
        data_tasks = []
        for task_name in all_tasks.keys():
            if any(keyword in task_name.lower() for keyword in 
                   ["isotope", "data", "analysis", "classify", "visualiz"]):
                data_tasks.append(task_name)
        
        return data_tasks
    
    def _execute_data_analysis_task(
        self, 
        data_tasks: List[str], 
        state: IsotopeSystemState
    ) -> Optional[str]:
        """æ‰§è¡Œæ•°æ®åˆ†ætask"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„taské€‰æ‹©å’Œæ‰§è¡Œé€»è¾‘
        # ç®€åŒ–ç‰ˆæœ¬ï¼šé€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„task
        
        # å¯¼å…¥åº”ç”¨è£…é¥°å™¨å‡½æ•°
        from app.core.task_decorator import apply_langgraph_decorator
        
        for task_name in data_tasks:
            try:
                task_func = get_task_by_name(task_name)
                if task_func:
                    # åº”ç”¨LangGraphè£…é¥°å™¨
                    task_func = apply_langgraph_decorator(task_func)
                    
                    if hasattr(state, 'current_file_id') and state.current_file_id:
                        result = task_func(state.current_file_id)
                        return f"æ•°æ®åˆ†æTask '{task_name}' æ‰§è¡Œç»“æœï¼š\n{result}"
            except Exception as e:
                logger.warning(f"æ‰§è¡Œæ•°æ®åˆ†ætask {task_name} å¤±è´¥: {str(e)}")
                continue
        
        return None
    
    def create_subgraph_with_checkpoint(
        self, 
        subgraph_name: str,
        subgraph_nodes: Dict[str, Callable],
        session_id: Optional[str] = None
    ) -> StateGraph:
        """åˆ›å»ºå¸¦æ£€æŸ¥ç‚¹çš„å­å›¾
        
        Args:
            subgraph_name: å­å›¾åç§°
            subgraph_nodes: å­å›¾èŠ‚ç‚¹
            session_id: ä¼šè¯IDï¼Œå¦‚æœä¸ºNoneåˆ™ç”ŸæˆéšæœºID
            
        Returns:
            é…ç½®äº†æ£€æŸ¥ç‚¹çš„å­å›¾
        """
        # å¦‚æœæ²¡æœ‰æä¾›session_idï¼Œç”Ÿæˆä¸€ä¸ªéšæœºID
        if session_id is None:
            import uuid
            session_id = str(uuid.uuid4())
            
        logger.info(f"åˆ›å»ºå­å›¾ '{subgraph_name}' çš„æ£€æŸ¥ç‚¹é…ç½®ï¼Œä¼šè¯ID: {session_id}")
        
        try:
            # åˆ›å»ºå­å›¾
            subgraph = StateGraph(dict)
            
            # æ·»åŠ èŠ‚ç‚¹
            for node_name, node_func in subgraph_nodes.items():
                subgraph.add_node(node_name, node_func)
            
            # æ·»åŠ è¾¹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            node_names = list(subgraph_nodes.keys())
            for i in range(len(node_names) - 1):
                subgraph.add_edge(node_names[i], node_names[i + 1])
            
            # è®¾ç½®å…¥å£å’Œå‡ºå£
            if node_names:
                subgraph.set_entry_point(node_names[0])
                subgraph.set_finish_point(node_names[-1])
            
            # è·å–æ£€æŸ¥ç‚¹å™¨
            checkpointer = None
            # ä¸¥æ ¼æ£€æŸ¥MySQLæ£€æŸ¥ç‚¹å™¨å¯ç”¨æ€§
            postgres_available = (self.postgres_checkpoint_manager and 
                             self.postgres_checkpoint_manager.is_postgres_available() and 
                             self.postgres_checkpoint_manager.test_connection())
            
            if postgres_available:
                checkpointer = self.postgres_checkpoint_manager.get_checkpointer()
                if checkpointer:
                    logger.info(f"å­å›¾ '{subgraph_name}' ä½¿ç”¨PostgreSQLæ£€æŸ¥ç‚¹å™¨")
                    
                    # å°è¯•è®¾ç½®thread_idå±æ€§
                    try:
                        if hasattr(checkpointer, 'thread_id'):
                            checkpointer.thread_id = f"{session_id}_{subgraph_name}"
                    except Exception as e:
                        logger.warning(f"æ— æ³•è®¾ç½®å­å›¾æ£€æŸ¥ç‚¹å™¨thread_id: {str(e)}")
                else:
                    logger.warning(f"æ— æ³•è·å–PostgreSQLæ£€æŸ¥ç‚¹å™¨å®ä¾‹ï¼Œå°è¯•ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å™¨")
            else:
                # å°è¯•ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å™¨
                try:
                    from langgraph.checkpoint.memory import MemorySaver
                    checkpointer = MemorySaver()
                    logger.info(f"å­å›¾ '{subgraph_name}' ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å™¨")
                except Exception as memory_error:
                    logger.warning(f"åˆ›å»ºå†…å­˜æ£€æŸ¥ç‚¹å™¨å¤±è´¥: {str(memory_error)}")
                    checkpointer = None
            
            # ç¼–è¯‘å­å›¾
            if checkpointer:
                # å­å›¾çº§åˆ«çš„ä¸­æ–­ç‚¹é…ç½®
                interrupt_before = node_names[1:] if len(node_names) > 1 else []
                
                # ç¼–è¯‘å­å›¾
                compiled_subgraph = subgraph.compile(
                    checkpointer=checkpointer,
                    interrupt_before=interrupt_before  # åœ¨é™¤ç¬¬ä¸€ä¸ªèŠ‚ç‚¹å¤–çš„æ‰€æœ‰èŠ‚ç‚¹å‰ä¸­æ–­
                )
                logger.info(f"å­å›¾ '{subgraph_name}' å·²é…ç½®æ£€æŸ¥ç‚¹")
            else:
                compiled_subgraph = subgraph.compile()
                logger.warning(f"å­å›¾ '{subgraph_name}' æœªé…ç½®æ£€æŸ¥ç‚¹")
            
            return compiled_subgraph
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå­å›¾æ£€æŸ¥ç‚¹å¤±è´¥: {str(e)}")
            # è¿”å›ä¸€ä¸ªåŸºæœ¬çš„ç¼–è¯‘å­å›¾
            try:
                minimal_subgraph = StateGraph(dict)
                minimal_subgraph.add_node("default", lambda state: state)
                minimal_subgraph.set_entry_point("default")
                return minimal_subgraph.compile()
            except:
                # æœ€åçš„å›é€€
                raise
    
    def replay_from_checkpoint(
        self, 
        session_id: str, 
        checkpoint_id: Optional[str] = None,
        target_node: Optional[str] = None,
        is_test: bool = False
    ) -> Dict[str, Any]:
        """ä»æ£€æŸ¥ç‚¹é‡æ’­æ‰§è¡Œ
        
        Args:
            session_id: ä¼šè¯ID
            checkpoint_id: æ£€æŸ¥ç‚¹IDï¼ŒNoneè¡¨ç¤ºæœ€æ–°çš„
            target_node: ç›®æ ‡èŠ‚ç‚¹ï¼ŒNoneè¡¨ç¤ºé‡æ’­åˆ°ç»“æŸ
            is_test: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼Œæµ‹è¯•æ¨¡å¼ä¸‹å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹ä¼šåˆ›å»ºä¸€ä¸ªç©ºæ£€æŸ¥ç‚¹
            
        Returns:
            é‡æ’­ç»“æœ
        """
        logger.info(f"å¼€å§‹ä»æ£€æŸ¥ç‚¹é‡æ’­ï¼Œä¼šè¯ID: {session_id}, æ£€æŸ¥ç‚¹ID: {checkpoint_id}")
        
        try:
            # ä¸¥æ ¼æ£€æŸ¥MySQLæ£€æŸ¥ç‚¹å™¨å¯ç”¨æ€§
            postgres_available = (self.postgres_checkpoint_manager and 
                             self.postgres_checkpoint_manager.is_postgres_available() and 
                             self.postgres_checkpoint_manager.test_connection())
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ£€æŸ¥ç‚¹ç®¡ç†å™¨
            if postgres_available:
                # è·å–æ£€æŸ¥ç‚¹
                checkpoint_data = self.postgres_checkpoint_manager.get_checkpoint(
                    session_id, checkpoint_id
                )
                
                if not checkpoint_data:
                    logger.warning(f"æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹: {session_id}/{checkpoint_id}ï¼Œå°è¯•ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹")
                    
                    # å¦‚æœæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œåˆ™è‡ªåŠ¨åˆ›å»ºä¸€ä¸ªåˆå§‹æ£€æŸ¥ç‚¹
                    if is_test:
                        logger.info(f"æµ‹è¯•æ¨¡å¼: ä¸ºä¼šè¯ {session_id} åˆ›å»ºæµ‹è¯•æ£€æŸ¥ç‚¹")
                        
                        # åˆ›å»ºä¸€ä¸ªç©ºçš„åˆå§‹çŠ¶æ€
                        initial_state = {"messages": []}
                        
                        # åˆ›å»ºé…ç½®
                        config = {"configurable": {"thread_id": session_id}}
                        
                        # å°è¯•ä¿å­˜æ£€æŸ¥ç‚¹
                        try:
                            self.postgres_checkpoint_manager.put_checkpoint(
                                config, 
                                initial_state, 
                                {"created_for": "test", "created_at": time.time()}
                            )
                            logger.info(f"æˆåŠŸåˆ›å»ºæµ‹è¯•æ£€æŸ¥ç‚¹: {session_id}")
                            
                            # è¿”å›å†…å­˜æ£€æŸ¥ç‚¹
                            return {
                                "success": True,
                                "session_id": session_id,
                                "checkpoint_id": checkpoint_id,
                                "thread_id": session_id,
                                "note": "å·²åˆ›å»ºæµ‹è¯•æ£€æŸ¥ç‚¹",
                                "source": "postgres_test"
                            }
                        except Exception as create_error:
                            logger.warning(f"åˆ›å»ºæµ‹è¯•æ£€æŸ¥ç‚¹å¤±è´¥: {str(create_error)}")
                    
                    return self._fallback_to_memory_checkpoint(session_id, checkpoint_id)
                
                # åˆ›å»ºå›¾
                graph = self.create_graph_with_checkpoint(session_id)
                
                # ä»æ£€æŸ¥ç‚¹æ¢å¤çŠ¶æ€å¹¶é‡æ’­
                # æ³¨æ„ï¼šåœ¨æœ€æ–°ç‰ˆLangGraphä¸­ï¼Œä¸å†ä½¿ç”¨configï¼Œè€Œæ˜¯ç›´æ¥åœ¨checkpointerä¸­è®¾ç½®thread_id
                logger.info(f"æ£€æŸ¥ç‚¹é‡æ’­è®¾ç½®å®Œæˆ: {session_id}")
                return {
                    "success": True,
                    "session_id": session_id,
                    "checkpoint_id": checkpoint_id,
                    "thread_id": session_id,  # ç”¨äºé‡æ’­çš„çº¿ç¨‹ID
                    "source": "postgres"
                }
            else:
                # ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å›é€€
                return self._fallback_to_memory_checkpoint(session_id, checkpoint_id)
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç‚¹é‡æ’­å¤±è´¥: {str(e)}")
            return {"error": str(e)}
            
    def _fallback_to_memory_checkpoint(self, session_id: str, checkpoint_id: Optional[str] = None) -> Dict[str, Any]:
        """å›é€€åˆ°å†…å­˜æ£€æŸ¥ç‚¹é‡æ’­
        
        Args:
            session_id: ä¼šè¯ID
            checkpoint_id: æ£€æŸ¥ç‚¹ID
            
        Returns:
            é‡æ’­é…ç½®
        """
        try:
            # å°è¯•åˆ›å»ºå†…å­˜æ£€æŸ¥ç‚¹å›¾
            from langgraph.checkpoint.memory import MemorySaver
            logger.info("PostgreSQLæ£€æŸ¥ç‚¹ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹")
            
            return {
                "success": True,
                "session_id": session_id,
                "checkpoint_id": checkpoint_id,
                "thread_id": session_id,
                "note": "ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹ï¼Œå¯èƒ½æ— æ³•æ¢å¤ä¹‹å‰çš„çŠ¶æ€",
                "source": "memory"
            }
        except Exception as memory_error:
            logger.error(f"å†…å­˜æ£€æŸ¥ç‚¹åˆ›å»ºå¤±è´¥: {str(memory_error)}")
            return {"error": "æ£€æŸ¥ç‚¹ç³»ç»Ÿä¸å¯ç”¨", "reason": str(memory_error)}
    
    def get_checkpoint_statistics(self) -> Dict[str, Any]:
        """è·å–æ£€æŸ¥ç‚¹ç»Ÿè®¡ä¿¡æ¯"""
        if self.postgres_checkpoint_manager and self.postgres_checkpoint_manager.is_postgres_available():
            return self.postgres_checkpoint_manager.get_statistics()
        
        # å¦‚æœPostgreSQLä¸å¯ç”¨ï¼Œè¿”å›å†…å­˜æ£€æŸ¥ç‚¹çš„åŸºæœ¬ä¿¡æ¯
        try:
            # è·å–ä¸€ä¸ªå†…å­˜æ£€æŸ¥ç‚¹ç»Ÿè®¡
            from langgraph.checkpoint.memory import MemorySaver
            return {
                "checkpointer_type": "MemorySaver",
                "postgres_available": False,
                "connection_healthy": True,
                "total_checkpoints": 0,  # å†…å­˜æ£€æŸ¥ç‚¹ä¸è·Ÿè¸ªæ•°é‡
                "unique_threads": 0,
                "status": "å†…å­˜æ£€æŸ¥ç‚¹æ¨¡å¼"
            }
        except Exception as e:
            logger.error(f"æ— æ³•è·å–æ£€æŸ¥ç‚¹ç»Ÿè®¡ä¿¡æ¯: {str(e)}")
            return {"error": "æ— æ³•è·å–æ£€æŸ¥ç‚¹ç»Ÿè®¡ä¿¡æ¯", "reason": str(e)}
    
    def compile_enhanced_graph(self, graph: Optional[StateGraph] = None, session_id: Optional[str] = None) -> Any:
        """ç¼–è¯‘å¢å¼ºç‰ˆå›¾
        
        Args:
            graph: è¦ç¼–è¯‘çš„å›¾ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ„å»ºä¸€ä¸ªæ–°å›¾
            session_id: ä¼šè¯IDï¼Œå¦‚æœä¸ºNoneåˆ™ç”ŸæˆéšæœºID
            
        Returns:
            ç¼–è¯‘åçš„å›¾
        """
        try:
            # ç”Ÿæˆä¸€ä¸ªéšæœºçš„ä¼šè¯IDï¼ˆå¦‚æœæœªæä¾›ï¼‰
            if session_id is None:
                import uuid
                session_id = str(uuid.uuid4())
                
            if graph is None:
                # æ„å»ºå¢å¼ºç‰ˆå›¾ï¼ˆMetaSupervisoræ¶æ„ï¼‰
                graph = self.build_enhanced_graph(session_id)
            
            logger.info(f"ç¼–è¯‘å¢å¼ºç‰ˆå›¾ï¼Œä¼šè¯ID: {session_id}...")
            
            # å°è¯•è·å–æ£€æŸ¥ç‚¹å™¨
            checkpointer = None
            if self.postgres_checkpoint_manager:
                checkpointer = self.postgres_checkpoint_manager.get_checkpointer()
            
            # å‡†å¤‡é…ç½®çº¿ç¨‹ID
            thread_id = session_id
            
            # ç¼–è¯‘å›¾
            if checkpointer:
                # æ£€æŸ¥checkpointeræ˜¯å¦æ”¯æŒthread_idå‚æ•°
                try:
                    import inspect
                    if hasattr(checkpointer, 'get_checkpointer'):
                        # æŸäº›å°è£…ç±»å¯èƒ½æœ‰è¿™ä¸ªæ–¹æ³•
                        sig = inspect.signature(checkpointer.get_checkpointer)
                        if 'thread_id' in sig.parameters:
                            # å¦‚æœæ”¯æŒthread_idä½œä¸ºå‚æ•°
                            compiled_graph = graph.compile(
                                checkpointer=checkpointer,
                                thread_id=thread_id
                            )
                        else:
                            compiled_graph = graph.compile(checkpointer=checkpointer)
                    else:
                        # å°è¯•ç›´æ¥è®¾ç½®thread_idå±æ€§
                        if hasattr(checkpointer, 'thread_id'):
                            checkpointer.thread_id = thread_id
                        
                        compiled_graph = graph.compile(checkpointer=checkpointer)
                except Exception as e:
                    logger.warning(f"è®¾ç½®thread_idå¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†ç¼–è¯‘: {str(e)}")
                    compiled_graph = graph.compile(checkpointer=checkpointer)
                    
                logger.info("å¢å¼ºç‰ˆå›¾ä½¿ç”¨PostgreSQLæ£€æŸ¥ç‚¹å™¨ç¼–è¯‘å®Œæˆ")
            else:
                # å¦‚æœæ²¡æœ‰æ£€æŸ¥ç‚¹å™¨ï¼Œå°è¯•ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å™¨
                try:
                    from langgraph.checkpoint.memory import MemorySaver
                    memory_checkpointer = MemorySaver()
                    compiled_graph = graph.compile(checkpointer=memory_checkpointer)
                    logger.info("å¢å¼ºç‰ˆå›¾ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å™¨ç¼–è¯‘å®Œæˆ")
                except Exception as memory_error:
                    logger.warning(f"ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å™¨å¤±è´¥: {str(memory_error)}")
                    compiled_graph = graph.compile()
                    logger.info("å¢å¼ºç‰ˆå›¾ä¸ä½¿ç”¨æ£€æŸ¥ç‚¹å™¨ç¼–è¯‘å®Œæˆ")
            
            return compiled_graph
            
        except Exception as e:
            logger.error(f"ç¼–è¯‘å¢å¼ºç‰ˆå›¾å¤±è´¥: {str(e)}")
            # å°è¯•æœ€ç®€å•çš„ç¼–è¯‘æ–¹å¼
            if graph:
                return graph.compile()
            else:
                # åˆ›å»ºæœ€å°åŒ–çš„å›¾
                minimal_graph = StateGraph(dict)
                minimal_graph.add_node("default", lambda state: state)
                minimal_graph.set_entry_point("default")
                return minimal_graph.compile()
    
    def create_thread_config(self, thread_id: Optional[str] = None) -> Dict[str, Any]:
        """åˆ›å»ºçº¿ç¨‹é…ç½®"""
        if thread_id is None:
            import uuid
            thread_id = str(uuid.uuid4())
        
        return {
            "configurable": {
                "thread_id": thread_id
            }
        }
    
    def visualize_graph(self, compiled_graph: Optional[Any] = None) -> Tuple[str, Optional[bytes]]:
        """å¯è§†åŒ–å¢å¼ºç‰ˆå›¾ç»“æ„
        
        Args:
            compiled_graph: å·²ç¼–è¯‘çš„å›¾ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰å›¾
            
        Returns:
            (Mermaidæ–‡æœ¬è¡¨ç¤º, PNGå›¾åƒæ•°æ®)
        """
        try:
            if compiled_graph is None:
                # å¦‚æœæ²¡æœ‰æä¾›ç¼–è¯‘å›¾ï¼Œå…ˆç¼–è¯‘ä¸€ä¸ª
                graph = self.build_enhanced_graph()
                compiled_graph = self.compile_enhanced_graph(graph)
            
            # è·å–å›¾å¯¹è±¡
            graph_obj = compiled_graph.get_graph()
            
            # ç”ŸæˆMermaidæ–‡æœ¬
            mermaid_text = graph_obj.draw_mermaid()
            
            # å°è¯•ç”ŸæˆPNGå›¾åƒ
            png_data = None
            try:
                png_data = graph_obj.draw_png()
            except Exception as e:
                logger.warning(f"ç”ŸæˆPNGå›¾åƒå¤±è´¥: {str(e)}")
            
            return mermaid_text, png_data
            
        except Exception as e:
            logger.error(f"å¯è§†åŒ–å¢å¼ºç‰ˆå›¾å¤±è´¥: {str(e)}")
            return f"å¯è§†åŒ–å¤±è´¥: {str(e)}", None

    def _create_standard_nodes(self) -> Dict[str, Callable]:
        """åˆ›å»ºæ ‡å‡†èŠ‚ç‚¹
        
        Returns:
            æ ‡å‡†èŠ‚ç‚¹å­—å…¸
        """
        standard_nodes = {}
        
        # ä¸»æ™ºèƒ½ä½“èŠ‚ç‚¹
        def main_agent_node(state: IsotopeSystemState) -> IsotopeSystemState:
            """æ ‡å‡†ä¸»æ™ºèƒ½ä½“èŠ‚ç‚¹"""
            try:
                # å…¼å®¹é˜¶æ®µ1å’Œé˜¶æ®µ2çš„æ™ºèƒ½ä½“è·å–æ–¹å¼
                main_agent = self.agents.get("supervisor_agent") or self.agents.get("main_agent")
                if not main_agent:
                    # ç¡®ä¿messagesåˆ—è¡¨å­˜åœ¨
                    if "messages" not in state or state["messages"] is None:
                        state["messages"] = []
                    state["messages"].append({"role": "assistant", "content": "ä¸»æ™ºèƒ½ä½“ä¸å¯ç”¨"})
                    return state
                
                # ç¡®ä¿messagesåˆ—è¡¨å­˜åœ¨
                if "messages" not in state or state["messages"] is None:
                    state["messages"] = []
                
                if state["messages"] and len(state["messages"]) > 0:
                    last_message = state["messages"][-1]
                    if isinstance(last_message, dict) and last_message.get("role") == "user":
                        content = last_message.get("content", "")
                        
                        if hasattr(main_agent, "invoke"):
                            response = main_agent.invoke(content)
                        elif callable(main_agent):
                            # å¦‚æœæ˜¯å¯è°ƒç”¨å¯¹è±¡ï¼Œè°ƒç”¨å®ƒå¹¶ä¼ å…¥çŠ¶æ€
                            result_state = main_agent(state)
                            return result_state if result_state else state
                        else:
                            response = "ä¸»æ™ºèƒ½ä½“æœªå®ç°invokeæ–¹æ³•"
                            
                        state["messages"].append({"role": "assistant", "content": str(response)})
                return state
            except Exception as e:
                logger.error(f"ä¸»æ™ºèƒ½ä½“èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
                # ç¡®ä¿messagesåˆ—è¡¨å­˜åœ¨
                if "messages" not in state or state["messages"] is None:
                    state["messages"] = []
                state["messages"].append({"role": "assistant", "content": f"æ‰§è¡Œå‡ºé”™: {str(e)}"})
                return state
        
        # æ•°æ®æ™ºèƒ½ä½“èŠ‚ç‚¹
        def data_agent_node(state: IsotopeSystemState) -> IsotopeSystemState:
            """æ ‡å‡†æ•°æ®æ™ºèƒ½ä½“èŠ‚ç‚¹"""
            try:
                data_agent = self.agents.get("data_agent")
                if not data_agent:
                    # å¦‚æœæ²¡æœ‰æ•°æ®æ™ºèƒ½ä½“ï¼Œç›´æ¥è¿”å›çŠ¶æ€ä¸æŠ¥é”™
                    return state
                
                # ç¡®ä¿messagesåˆ—è¡¨å­˜åœ¨
                if "messages" not in state or state["messages"] is None:
                    state["messages"] = []
                
                if state["messages"] and len(state["messages"]) > 0:
                    last_message = state["messages"][-1]
                    if isinstance(last_message, dict) and last_message.get("role") == "user":
                        content = last_message.get("content", "")
                        
                        if hasattr(data_agent, "run"):
                            logger.info("è°ƒç”¨æ•°æ®æ™ºèƒ½ä½“çš„runæ–¹æ³•")
                            # DataAgentä½¿ç”¨runæ–¹æ³•ï¼Œä¼ å…¥å®Œæ•´çŠ¶æ€
                            result = data_agent.run(state)
                            
                            # runæ–¹æ³•è¿”å›çš„æ˜¯å®Œæ•´çš„æ›´æ–°åçš„çŠ¶æ€
                            if isinstance(result, dict):
                                # å¦‚æœè¿”å›çš„æ˜¯çŠ¶æ€å­—å…¸ï¼Œæ›´æ–°å½“å‰çŠ¶æ€
                                logger.info("æ•°æ®æ™ºèƒ½ä½“è¿”å›äº†çŠ¶æ€å­—å…¸")
                                for key, value in result.items():
                                    state[key] = value
                            else:
                                logger.warning(f"æ•°æ®æ™ºèƒ½ä½“è¿”å›äº†æ„å¤–çš„ç»“æœç±»å‹: {type(result)}")
                                
                        elif hasattr(data_agent, "invoke"):
                            logger.info("è°ƒç”¨æ•°æ®æ™ºèƒ½ä½“çš„invokeæ–¹æ³•")
                            response = data_agent.invoke(content)
                            
                            # ç¡®ä¿å“åº”æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                            if hasattr(response, 'content'):
                                response_content = response.content
                            else:
                                response_content = str(response)
                                
                            logger.info(f"æ•°æ®æ™ºèƒ½ä½“å›å¤: {response_content[:100]}...")
                            state["messages"].append({"role": "assistant", "content": response_content})
                            
                        elif callable(data_agent):
                            logger.info("æ•°æ®æ™ºèƒ½ä½“æ˜¯å¯è°ƒç”¨å¯¹è±¡ï¼Œç›´æ¥è°ƒç”¨")
                            # å¦‚æœæ˜¯å¯è°ƒç”¨å¯¹è±¡ï¼Œè°ƒç”¨å®ƒå¹¶ä¼ å…¥çŠ¶æ€
                            result_state = data_agent(state)
                            if result_state:
                                logger.info("æ•°æ®æ™ºèƒ½ä½“è¿”å›äº†æ–°çŠ¶æ€")
                                return result_state
                            else:
                                logger.warning("æ•°æ®æ™ºèƒ½ä½“è¿”å›ç©ºçŠ¶æ€ï¼Œä½¿ç”¨åŸçŠ¶æ€")
                                state["messages"].append({"role": "assistant", "content": "æ•°æ®æ™ºèƒ½ä½“å¤„ç†å®Œæˆ"})
                        else:
                            logger.warning("æ•°æ®æ™ºèƒ½ä½“æ—¢ä¸æ˜¯runä¹Ÿä¸æ˜¯invokeä¹Ÿä¸æ˜¯callableï¼Œç”Ÿæˆé»˜è®¤å›å¤")
                            response_content = f"æ•°æ®æ™ºèƒ½ä½“å·²å¤„ç†æ¶ˆæ¯: {content[:50]}..."
                            state["messages"].append({"role": "assistant", "content": response_content})
                            
                return state
            except Exception as e:
                logger.error(f"æ•°æ®æ™ºèƒ½ä½“èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
                # ç¡®ä¿messagesåˆ—è¡¨å­˜åœ¨
                if "messages" not in state or state["messages"] is None:
                    state["messages"] = []
                state["messages"].append({"role": "assistant", "content": f"æ•°æ®æ™ºèƒ½ä½“æ‰§è¡Œå‡ºé”™: {str(e)}"})
                return state
        
        standard_nodes["main_agent"] = main_agent_node
        
        # åªæœ‰åœ¨æœ‰æ•°æ®æ™ºèƒ½ä½“æ—¶æ‰æ·»åŠ æ•°æ®æ™ºèƒ½ä½“èŠ‚ç‚¹
        if self.agents.get("data_agent"):
            standard_nodes["data_agent"] = data_agent_node
        
        return standard_nodes 

    def get_active_checkpointer(self):
        """è·å–å½“å‰æ´»è·ƒçš„æ£€æŸ¥ç‚¹å™¨
        
        Returns:
            å½“å‰å¯ç”¨çš„æ£€æŸ¥ç‚¹å™¨å®ä¾‹ï¼Œå¦‚æœéƒ½ä¸å¯ç”¨åˆ™è¿”å›None
        """
        # ä¼˜å…ˆä½¿ç”¨PostgreSQLæ£€æŸ¥ç‚¹å™¨
        if (self.postgres_checkpoint_manager and 
            self.postgres_checkpoint_manager.is_postgres_available() and 
            self.postgres_checkpoint_manager.test_connection()):
            return self.postgres_checkpoint_manager.get_checkpointer()
        
        # ç„¶åå°è¯•MySQLæ£€æŸ¥ç‚¹å™¨
        if (self.mysql_checkpoint_manager and 
            hasattr(self.mysql_checkpoint_manager, 'test_connection') and
            self.mysql_checkpoint_manager.test_connection()):
            return self.mysql_checkpoint_manager.get_checkpointer()
        
        # æœ€åå›é€€åˆ°å†…å­˜æ£€æŸ¥ç‚¹å™¨
        try:
            from langgraph.checkpoint.memory import MemorySaver
            logger.info("å›é€€åˆ°å†…å­˜æ£€æŸ¥ç‚¹å™¨")
            return MemorySaver()
        except Exception as e:
            logger.error(f"åˆ›å»ºå†…å­˜æ£€æŸ¥ç‚¹å™¨å¤±è´¥: {str(e)}")
            return None
    
    def get_checkpoint_status(self) -> Dict[str, Any]:
        """è·å–æ£€æŸ¥ç‚¹ç³»ç»ŸçŠ¶æ€
        
        Returns:
            æ£€æŸ¥ç‚¹ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
        """
        status = {
            "postgres_available": False,
            "mysql_available": False,
            "active_backend": "none",
            "fallback_to_memory": False
        }
        
        # æ£€æŸ¥PostgreSQLçŠ¶æ€
        if self.postgres_checkpoint_manager:
            try:
                status["postgres_available"] = (
                    self.postgres_checkpoint_manager.is_postgres_available() and
                    self.postgres_checkpoint_manager.test_connection()
                )
                if status["postgres_available"]:
                    status["active_backend"] = "postgres"
            except Exception as e:
                logger.warning(f"æ£€æŸ¥PostgreSQLçŠ¶æ€å¤±è´¥: {str(e)}")
        
        # æ£€æŸ¥MySQLçŠ¶æ€
        if self.mysql_checkpoint_manager:
            try:
                mysql_available = (
                    hasattr(self.mysql_checkpoint_manager, 'test_connection') and
                    self.mysql_checkpoint_manager.test_connection()
                )
                status["mysql_available"] = mysql_available
                if mysql_available and status["active_backend"] == "none":
                    status["active_backend"] = "mysql"
            except Exception as e:
                logger.warning(f"æ£€æŸ¥MySQLçŠ¶æ€å¤±è´¥: {str(e)}")
        
        # å¦‚æœéƒ½ä¸å¯ç”¨ï¼Œæ ‡è®°å›é€€åˆ°å†…å­˜
        if status["active_backend"] == "none":
            status["fallback_to_memory"] = True
            status["active_backend"] = "memory"
        
        return status
    
    def _ensure_state_fields(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ç¡®ä¿çŠ¶æ€åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µçš„çŠ¶æ€
        """
        if not isinstance(state, dict):
            state = {}
        
        # å®šä¹‰å¿…éœ€å­—æ®µåŠå…¶é»˜è®¤å€¼
        required_fields = {
            "messages": [],
            "action_history": [],
            "files": [],
            "current_task": None,
            "tool_results": [],
            "metadata": {},
            "task_results": [],
            "agent_analysis": {}
        }
        
        # ç¡®ä¿æ‰€æœ‰å­—æ®µå­˜åœ¨ä¸”ä¸ä¸ºNoneï¼ˆä¿®å¤çŠ¶æ€ä¼ é€’é—®é¢˜ï¼‰
        for field, default_value in required_fields.items():
            if field not in state or state[field] is None:
                state[field] = default_value
        
        return state
    
    def _get_default_llm(self):
        """è·å–é»˜è®¤çš„LLMå®ä¾‹"""
        try:
            from app.utils.qwen_chat import SFChatOpenAI
            return SFChatOpenAI(
                model="Qwen/Qwen2.5-72B-Instruct",
                temperature=0.1,
                max_tokens=4000  # ä¿®å¤ï¼šé€‚é…æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶
            )
        except Exception as e:
            logger.warning(f"æ— æ³•åˆ›å»ºé»˜è®¤LLM: {e}")
            try:
                # å›é€€åˆ°åŸºç¡€ChatOpenAIï¼Œä½†è¦ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹
                from langchain_openai import ChatOpenAI
                return ChatOpenAI(
                    model="Qwen/Qwen2.5-72B-Instruct",
                    temperature=0.1
                )
            except Exception as e2:
                logger.error(f"åˆ›å»ºå›é€€LLMä¹Ÿå¤±è´¥: {e2}")
                return None